{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b0094b",
   "metadata": {},
   "source": [
    "# üöÄ Complete Nanonets OCR Markdown Generator\n",
    "\n",
    "**Advanced Document Processing Pipeline with Nanonets AI OCR**\n",
    "\n",
    "This notebook provides a comprehensive solution for processing all cropped images from layout detection using Nanonets OCR model for high-quality text extraction and clean markdown generation.\n",
    "\n",
    "## Features:\n",
    "- ü§ñ **Nanonets AI OCR** - State-of-the-art OCR with contextual understanding\n",
    "- üñºÔ∏è **Smart Image Processing** - Handles all image sizes including small elements\n",
    "- üìù **Clean Text Extraction** - No extra metadata, only extracted content\n",
    "- üéØ **Element-Type Aware** - Optimized prompts for different content types\n",
    "- üìÑ **Structured Output** - Clean markdown with proper formatting\n",
    "- üíæ **Batch Processing** - Process all documents efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Imports and Configuration\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Core ML imports\n",
    "from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "# Configuration Constants\n",
    "NANONETS_MODEL = \"nanonets/Nanonets-OCR-s\"\n",
    "LAYOUT_RESULTS_DIR = Path(\"layout_results\")\n",
    "OUTPUT_DIR = Path(\"nanonets_clean_results\")\n",
    "MIN_IMAGE_SIZE = 32  # Minimum dimension for compatibility\n",
    "MAX_IMAGE_SIZE = 2048  # Maximum dimension to avoid memory issues\n",
    "MIN_TEXT_LENGTH = 2  # Minimum text length to consider valid\n",
    "\n",
    "# Processing Configuration\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "DEVICE = \"cuda\" if USE_GPU else \"cpu\"\n",
    "TORCH_DTYPE = torch.bfloat16 if USE_GPU else torch.float32\n",
    "\n",
    "print(\"üöÄ Nanonets OCR Markdown Generator\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ü§ñ Model: {NANONETS_MODEL}\")\n",
    "print(f\"üñ•Ô∏è Device: {DEVICE}\")\n",
    "print(f\"üìÅ Input Directory: {LAYOUT_RESULTS_DIR}\")\n",
    "print(f\"üíæ Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"üéØ GPU Available: {'‚úÖ' if USE_GPU else '‚ùå'}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0e25f",
   "metadata": {},
   "source": [
    "## 1. Nanonets OCR Engine Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d18fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanonetsOCREngine:\n",
    "    \"\"\"Advanced Nanonets OCR Engine with comprehensive image processing.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "        self.tokenizer = None\n",
    "        self.initialized = False\n",
    "        \n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize the Nanonets OCR model and components.\"\"\"\n",
    "        try:\n",
    "            print(\"üîÑ Initializing Nanonets OCR Engine...\")\n",
    "            \n",
    "            # Load tokenizer and processor\n",
    "            print(\"  üì• Loading tokenizer...\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                NANONETS_MODEL, \n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            \n",
    "            print(\"  üì• Loading processor...\")\n",
    "            self.processor = AutoProcessor.from_pretrained(\n",
    "                NANONETS_MODEL, \n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            \n",
    "            # Load model\n",
    "            print(\"  \udce5 Loading model...\")\n",
    "            self.model = AutoModelForImageTextToText.from_pretrained(\n",
    "                NANONETS_MODEL,\n",
    "                trust_remote_code=True,\n",
    "                torch_dtype=TORCH_DTYPE,\n",
    "                device_map=\"auto\" if USE_GPU else None\n",
    "            )\n",
    "            \n",
    "            self.initialized = True\n",
    "            print(\"‚úÖ Nanonets OCR Engine initialized successfully!\")\n",
    "            print(f\"üñ•Ô∏è Model loaded on: {next(self.model.parameters()).device}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to initialize OCR engine: {e}\")\n",
    "            self.initialized = False\n",
    "            raise\n",
    "    \n",
    "    def is_ready(self):\n",
    "        \"\"\"Check if the OCR engine is ready for use.\"\"\"\n",
    "        return self.initialized and self.model is not None\n",
    "\n",
    "# Initialize the OCR engine\n",
    "ocr_engine = NanonetsOCREngine()\n",
    "ocr_engine.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80cf840",
   "metadata": {},
   "source": [
    "## 2. Image Processing and OCR Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e11571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_prompt(element_type: str) -> str:\n",
    "    \"\"\"Create element-specific prompts for clean text extraction.\"\"\"\n",
    "    \n",
    "    base_prompt = (\n",
    "        \"Extract ONLY the text content from this image. \"\n",
    "        \"Return clean text without any explanations or extra information. \"\n",
    "    )\n",
    "    \n",
    "    element_prompts = {\n",
    "        \"table\": \"Format tables as clean HTML using <table>, <tr>, <td>, <th> tags only.\",\n",
    "        \"title\": \"Extract the title text only.\",\n",
    "        \"section_header\": \"Extract the header text only.\",\n",
    "        \"text\": \"Extract the text content preserving natural line breaks.\",\n",
    "        \"paragraph\": \"Extract the paragraph text maintaining structure.\",\n",
    "        \"key_value_region\": \"Extract key-value pairs as 'Key: Value' format.\",\n",
    "        \"list\": \"Extract list items with appropriate bullet points or numbers.\",\n",
    "        \"page_header\": \"Extract header text from top of page.\",\n",
    "        \"page_footer\": \"Extract footer text from bottom of page.\",\n",
    "        \"picture\": \"If text is visible, extract it. If no text, return [Image: brief description]\"\n",
    "    }\n",
    "    \n",
    "    specific_prompt = element_prompts.get(element_type, \"Extract the visible text content.\")\n",
    "    return base_prompt + specific_prompt\n",
    "\n",
    "\n",
    "def preprocess_image(image_path: Path) -> Optional[Image.Image]:\n",
    "    \"\"\"Preprocess image for optimal OCR results.\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        width, height = image.size\n",
    "        \n",
    "        # Handle small images - resize to meet minimum requirements\n",
    "        if width < MIN_IMAGE_SIZE or height < MIN_IMAGE_SIZE:\n",
    "            scale_factor = max(MIN_IMAGE_SIZE / width, MIN_IMAGE_SIZE / height)\n",
    "            new_width = max(MIN_IMAGE_SIZE, int(width * scale_factor * 1.2))  # Add 20% buffer\n",
    "            new_height = max(MIN_IMAGE_SIZE, int(height * scale_factor * 1.2))\n",
    "            \n",
    "            print(f\"    \udccf Resizing from {width}x{height} to {new_width}x{new_height}\")\n",
    "            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Handle large images - downscale to prevent memory issues\n",
    "        elif width > MAX_IMAGE_SIZE or height > MAX_IMAGE_SIZE:\n",
    "            scale_factor = min(MAX_IMAGE_SIZE / width, MAX_IMAGE_SIZE / height)\n",
    "            new_width = int(width * scale_factor)\n",
    "            new_height = int(height * scale_factor)\n",
    "            \n",
    "            print(f\"    üìê Downscaling from {width}x{height} to {new_width}x{new_height}\")\n",
    "            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        return image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå Image preprocessing failed: {str(e)[:50]}...\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_text_with_nanonets(image_path: Path, element_type: str = \"text\") -> Tuple[str, float]:\n",
    "    \"\"\"Extract text using Nanonets OCR with confidence scoring.\"\"\"\n",
    "    \n",
    "    if not ocr_engine.is_ready():\n",
    "        return \"\", 0.0\n",
    "    \n",
    "    try:\n",
    "        # Preprocess image\n",
    "        image = preprocess_image(image_path)\n",
    "        if image is None:\n",
    "            return \"\", 0.0\n",
    "        \n",
    "        # Create optimized prompt\n",
    "        prompt = create_optimized_prompt(element_type)\n",
    "        \n",
    "        # Prepare messages for the model\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"You are a precise text extraction assistant. Extract only visible text without commentary.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": f\"file://{image_path}\"},\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                ]\n",
    "            },\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template\n",
    "        try:\n",
    "            text = ocr_engine.processor.apply_chat_template(\n",
    "                messages, tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "        except AttributeError:\n",
    "            text = ocr_engine.tokenizer.apply_chat_template(\n",
    "                messages, tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "        \n",
    "        # Process inputs\n",
    "        inputs = ocr_engine.processor(\n",
    "            text=[text], images=[image], padding=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        if USE_GPU:\n",
    "            inputs = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate text\n",
    "        with torch.inference_mode():\n",
    "            output = ocr_engine.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1024,\n",
    "                do_sample=False,\n",
    "                num_beams=1,\n",
    "                temperature=0.1,\n",
    "                repetition_penalty=1.05,\n",
    "                early_stopping=True,\n",
    "                pad_token_id=ocr_engine.model.generation_config.pad_token_id,\n",
    "            )\n",
    "        \n",
    "        # Extract generated text\n",
    "        generated_ids = [o[i.shape[-1]:] for i, o in zip(inputs[\"input_ids\"], output)]\n",
    "        result = ocr_engine.processor.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )[0]\n",
    "        \n",
    "        # Clean result\n",
    "        result = result.strip()\n",
    "        \n",
    "        # Calculate confidence\n",
    "        confidence = calculate_confidence(result, image.size)\n",
    "        \n",
    "        # Cleanup memory\n",
    "        del image, inputs, output\n",
    "        if USE_GPU:\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return result, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå OCR failed: {str(e)[:50]}...\")\n",
    "        return \"\", 0.0\n",
    "\n",
    "\n",
    "def calculate_confidence(text: str, image_size: Tuple[int, int]) -> float:\n",
    "    \"\"\"Calculate confidence score based on extraction quality.\"\"\"\n",
    "    \n",
    "    if not text or len(text.strip()) < MIN_TEXT_LENGTH:\n",
    "        return 0.0\n",
    "    \n",
    "    confidence = 1.0\n",
    "    \n",
    "    # Reduce confidence for very short text\n",
    "    if len(text) < 5:\n",
    "        confidence *= 0.6\n",
    "    \n",
    "    # Check for error indicators\n",
    "    error_indicators = ['failed', 'error', 'unable', 'cannot', 'sorry']\n",
    "    if any(indicator in text.lower() for indicator in error_indicators):\n",
    "        confidence *= 0.2\n",
    "    \n",
    "    # Check for garbled text (too many special characters)\n",
    "    special_chars = sum(1 for c in text if not c.isalnum() and c not in ' .,!?-:;()[]{}')\n",
    "    if len(text) > 0:\n",
    "        special_ratio = special_chars / len(text)\n",
    "        if special_ratio > 0.3:\n",
    "            confidence *= 0.5\n",
    "    \n",
    "    # Boost for structured content\n",
    "    if any(tag in text for tag in ['<table>', '<tr>', '<td>']):\n",
    "        confidence *= 1.1\n",
    "    \n",
    "    # Consider image size\n",
    "    width, height = image_size\n",
    "    if width < 50 or height < 20:\n",
    "        confidence *= 0.7\n",
    "    \n",
    "    return min(1.0, max(0.0, confidence))\n",
    "\n",
    "print(\"‚úÖ OCR processing functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ed218",
   "metadata": {},
   "source": [
    "## 3. Document Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c913d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_element_info_from_filename(filename: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract element information from filename pattern.\"\"\"\n",
    "    # Pattern: p001_elem000_type_id.png\n",
    "    parts = filename.replace('.png', '').replace('.jpg', '').replace('.jpeg', '').split('_')\n",
    "    \n",
    "    info = {\n",
    "        'id': 'unknown',\n",
    "        'type': 'text',\n",
    "        'page': 1,\n",
    "        'element_id': 'unknown'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if len(parts) >= 3:\n",
    "            # Extract page number (p001 -> 1)\n",
    "            if parts[0].startswith('p'):\n",
    "                info['page'] = int(parts[0][1:])\n",
    "            \n",
    "            # Extract element ID (elem000)\n",
    "            if parts[1].startswith('elem'):\n",
    "                info['element_id'] = parts[1]\n",
    "                info['id'] = parts[1]\n",
    "            \n",
    "            # Extract element type\n",
    "            if len(parts) >= 4:\n",
    "                info['type'] = parts[2]\n",
    "            elif len(parts) == 3:\n",
    "                info['type'] = parts[2]\n",
    "        \n",
    "        # Extract layout element ID if present in filename\n",
    "        if len(parts) >= 5:\n",
    "            try:\n",
    "                # Last part might be the layout analysis ID\n",
    "                layout_id = int(parts[-1])\n",
    "                info['layout_id'] = layout_id\n",
    "            except ValueError:\n",
    "                pass\n",
    "                \n",
    "    except (ValueError, IndexError):\n",
    "        pass  # Use defaults\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def load_layout_metadata(doc_dir: Path) -> Tuple[Dict[str, Any], Dict[int, Dict]]:\n",
    "    \"\"\"Load layout metadata from JSON file and create element mapping.\"\"\"\n",
    "    \n",
    "    layout_json_path = doc_dir / \"layout_analysis.json\"\n",
    "    element_info_map = {}\n",
    "    layout_elements = {}\n",
    "    \n",
    "    if layout_json_path.exists():\n",
    "        try:\n",
    "            with open(layout_json_path, 'r', encoding='utf-8') as f:\n",
    "                layout_data = json.load(f)\n",
    "            \n",
    "            print(f\"  üìÑ Loaded layout analysis with {layout_data.get('element_statistics', {}).get('total_elements', 0)} elements\")\n",
    "            \n",
    "            # Create mapping of layout element IDs to their data\n",
    "            for page_data in layout_data.get('pages', []):\n",
    "                for element in page_data.get('elements', []):\n",
    "                    element_id = element.get('id')\n",
    "                    if element_id is not None:\n",
    "                        layout_elements[element_id] = element\n",
    "                        \n",
    "                        # Also create reverse mapping for cropped images\n",
    "                        # Look for corresponding cropped image files\n",
    "                        element_type = element.get('type', 'text')\n",
    "                        page_num = page_data.get('page_number', 1)\n",
    "                        \n",
    "                        # Try to match with filename patterns\n",
    "                        possible_filenames = [\n",
    "                            f\"p{page_num:03d}_elem{element_id:03d}_{element_type}_{element_id}.png\",\n",
    "                            f\"p{page_num:03d}_elem{element_id:03d}_{element_type}.png\",\n",
    "                            f\"p{page_num:03d}_elem000_{element_type}_{element_id}.png\"\n",
    "                        ]\n",
    "                        \n",
    "                        for filename in possible_filenames:\n",
    "                            element_info_map[filename] = element\n",
    "                            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Could not read layout JSON: {e}\")\n",
    "    \n",
    "    return element_info_map, layout_elements\n",
    "\n",
    "\n",
    "def calculate_reading_order(elements: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Calculate reading order based on spatial position from layout analysis.\"\"\"\n",
    "    \n",
    "    # Separate elements with and without layout info\n",
    "    elements_with_layout = []\n",
    "    elements_without_layout = []\n",
    "    \n",
    "    for element in elements:\n",
    "        layout_info = element.get('layout_info', {})\n",
    "        if layout_info and 'bounding_box' in layout_info:\n",
    "            elements_with_layout.append(element)\n",
    "        else:\n",
    "            elements_without_layout.append(element)\n",
    "    \n",
    "    # Sort elements with layout info by reading order (top to bottom, left to right)\n",
    "    def reading_order_key(element):\n",
    "        bbox = element['layout_info']['bounding_box']\n",
    "        top = bbox['top']\n",
    "        left = bbox['left']\n",
    "        \n",
    "        # Primary sort by vertical position (top)\n",
    "        # Secondary sort by horizontal position (left)\n",
    "        # Use a tolerance for \"same line\" elements\n",
    "        row_tolerance = 20  # pixels\n",
    "        row = int(top / row_tolerance)\n",
    "        \n",
    "        return (row, left)\n",
    "    \n",
    "    elements_with_layout.sort(key=reading_order_key)\n",
    "    \n",
    "    # Sort elements without layout info by type priority and filename\n",
    "    type_priority = {\n",
    "        'title': 1,\n",
    "        'section_header': 2,\n",
    "        'paragraph': 3,\n",
    "        'text': 4,\n",
    "        'table': 5,\n",
    "        'list': 6,\n",
    "        'key_value_region': 7,\n",
    "        'picture': 8,\n",
    "        'page_header': 9,\n",
    "        'page_footer': 10\n",
    "    }\n",
    "    \n",
    "    elements_without_layout.sort(\n",
    "        key=lambda x: (type_priority.get(x['element_type'], 5), x.get('filename', ''))\n",
    "    )\n",
    "    \n",
    "    # Combine: elements with layout info first (in reading order), then others\n",
    "    return elements_with_layout + elements_without_layout\n",
    "\n",
    "\n",
    "def process_single_document(doc_dir: Path) -> Dict[str, Any]:\n",
    "    \"\"\"Process all cropped images in a single document directory using layout analysis for reading order.\"\"\"\n",
    "    \n",
    "    doc_name = doc_dir.name\n",
    "    cropped_dir = doc_dir / \"cropped_images\"\n",
    "    \n",
    "    if not cropped_dir.exists():\n",
    "        print(f\"  ‚ö†Ô∏è No cropped_images directory found\")\n",
    "        return {\"elements\": [], \"stats\": {\"total\": 0, \"processed\": 0, \"failed\": 0}}\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = []\n",
    "    for ext in ['*.png', '*.jpg', '*.jpeg']:\n",
    "        image_files.extend(cropped_dir.glob(ext))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"  ‚ö†Ô∏è No image files found\")\n",
    "        return {\"elements\": [], \"stats\": {\"total\": 0, \"processed\": 0, \"failed\": 0}}\n",
    "    \n",
    "    print(f\"  üñºÔ∏è Found {len(image_files)} images\")\n",
    "    \n",
    "    # Load layout metadata and element mapping\n",
    "    element_info_map, layout_elements = load_layout_metadata(doc_dir)\n",
    "    \n",
    "    # Process each image\n",
    "    processed_elements = []\n",
    "    stats = {\"total\": len(image_files), \"processed\": 0, \"failed\": 0, \"small_images\": 0}\n",
    "    \n",
    "    for image_path in sorted(image_files):\n",
    "        image_name = image_path.name\n",
    "        \n",
    "        print(f\"    üîç Processing: {image_name}\")\n",
    "        \n",
    "        # Get element info from layout analysis or filename\n",
    "        element_info = element_info_map.get(image_name, {})\n",
    "        if not element_info:\n",
    "            # Try to extract layout ID from filename and match with layout elements\n",
    "            filename_info = extract_element_info_from_filename(image_name)\n",
    "            layout_id = filename_info.get('layout_id')\n",
    "            \n",
    "            if layout_id and layout_id in layout_elements:\n",
    "                element_info = layout_elements[layout_id]\n",
    "                print(f\"    üìç Matched with layout element ID {layout_id}\")\n",
    "            else:\n",
    "                element_info = filename_info\n",
    "                print(f\"    ‚ö†Ô∏è No layout info found, using filename-based info\")\n",
    "        else:\n",
    "            print(f\"    üìç Found layout analysis data\")\n",
    "        \n",
    "        element_type = element_info.get('type', 'text')\n",
    "        \n",
    "        # Extract text\n",
    "        start_time = time.time()\n",
    "        extracted_text, confidence = extract_text_with_nanonets(image_path, element_type)\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        # Check image size for small image tracking\n",
    "        try:\n",
    "            with Image.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                if width < MIN_IMAGE_SIZE or height < MIN_IMAGE_SIZE:\n",
    "                    stats[\"small_images\"] += 1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Create element record\n",
    "        element_record = {\n",
    "            'filename': image_name,\n",
    "            'image_path': str(image_path),\n",
    "            'element_type': element_type,\n",
    "            'extracted_text': extracted_text,\n",
    "            'confidence': confidence,\n",
    "            'processing_time': processing_time,\n",
    "            'success': confidence > 0.1,\n",
    "            'page': element_info.get('page', 1),\n",
    "            'element_id': element_info.get('id', 'unknown'),\n",
    "            'layout_info': element_info if 'bounding_box' in element_info else None\n",
    "        }\n",
    "        \n",
    "        processed_elements.append(element_record)\n",
    "        \n",
    "        # Update stats\n",
    "        if element_record['success']:\n",
    "            stats[\"processed\"] += 1\n",
    "            print(f\"    ‚úÖ Success: {len(extracted_text)} chars, confidence: {confidence:.2f}\")\n",
    "        else:\n",
    "            stats[\"failed\"] += 1\n",
    "            print(f\"    ‚ùå Failed: No text extracted\")\n",
    "    \n",
    "    # Sort elements by reading order using layout analysis\n",
    "    print(f\"  üìñ Calculating reading order from layout analysis...\")\n",
    "    ordered_elements = calculate_reading_order(processed_elements)\n",
    "    \n",
    "    # Show reading order summary\n",
    "    elements_with_layout = len([e for e in ordered_elements if e.get('layout_info')])\n",
    "    print(f\"  üìç Elements with layout info: {elements_with_layout}/{len(ordered_elements)}\")\n",
    "    \n",
    "    return {\"elements\": ordered_elements, \"stats\": stats}\n",
    "\n",
    "print(\"‚úÖ Document processing functions with layout-based reading order defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23b268",
   "metadata": {},
   "source": [
    "## 4. Markdown Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clean_markdown(elements: List[Dict], doc_name: str) -> str:\n",
    "    \"\"\"Generate clean markdown from processed elements using layout-based reading order.\"\"\"\n",
    "    \n",
    "    # Filter successful extractions\n",
    "    valid_elements = [elem for elem in elements if elem['success'] and elem['extracted_text'].strip()]\n",
    "    \n",
    "    if not valid_elements:\n",
    "        return f\"# {doc_name}\\n\\n*No text content extracted*\\n\"\n",
    "    \n",
    "    lines = [f\"# {doc_name}\\n\"]\n",
    "    \n",
    "    # Group elements by page\n",
    "    pages = defaultdict(list)\n",
    "    for element in valid_elements:\n",
    "        page_num = element.get('page', 1)\n",
    "        pages[page_num].append(element)\n",
    "    \n",
    "    # Process each page\n",
    "    for page_num in sorted(pages.keys()):\n",
    "        if len(pages) > 1:  # Only add page headers if multiple pages\n",
    "            lines.append(f\"\\n## Page {page_num}\\n\")\n",
    "        \n",
    "        page_elements = pages[page_num]\n",
    "        \n",
    "        # Elements should already be in reading order from process_single_document\n",
    "        # But we can group consecutive elements of same type for better formatting\n",
    "        \n",
    "        current_section = None\n",
    "        \n",
    "        for element in page_elements:\n",
    "            text = element['extracted_text'].strip()\n",
    "            element_type = element['element_type']\n",
    "            confidence = element['confidence']\n",
    "            layout_info = element.get('layout_info')\n",
    "            \n",
    "            if not text:\n",
    "                continue\n",
    "            \n",
    "            # Add some spacing between different sections\n",
    "            if current_section and current_section != element_type:\n",
    "                if element_type in ['title', 'section_header']:\n",
    "                    lines.append(\"\")  # Extra space before headers\n",
    "            \n",
    "            # Format based on element type following layout reading order\n",
    "            if element_type == 'title':\n",
    "                lines.append(f\"### {text}\\n\")\n",
    "                current_section = 'title'\n",
    "                \n",
    "            elif element_type == 'section_header':\n",
    "                lines.append(f\"#### {text}\\n\")\n",
    "                current_section = 'section_header'\n",
    "                \n",
    "            elif element_type == 'table':\n",
    "                # Add table with proper spacing\n",
    "                if '<table>' in text.lower():\n",
    "                    lines.append(f\"{text}\\n\")\n",
    "                else:\n",
    "                    lines.append(f\"**Table:**\\n\\n{text}\\n\")\n",
    "                current_section = 'table'\n",
    "                \n",
    "            elif element_type == 'list':\n",
    "                lines.append(f\"{text}\\n\")\n",
    "                current_section = 'list'\n",
    "                \n",
    "            elif element_type == 'key_value_region':\n",
    "                # Format key-value regions with emphasis\n",
    "                lines.append(f\"**{text}**\\n\")\n",
    "                current_section = 'key_value'\n",
    "                \n",
    "            elif element_type == 'picture':\n",
    "                # Handle image descriptions\n",
    "                if text.startswith('[Image:') or 'image:' in text.lower():\n",
    "                    lines.append(f\"{text}\\n\")\n",
    "                else:\n",
    "                    lines.append(f\"[Image: {text}]\\n\")\n",
    "                current_section = 'picture'\n",
    "                \n",
    "            elif element_type in ['page_header', 'page_footer']:\n",
    "                # Format headers/footers with italics\n",
    "                lines.append(f\"*{text}*\\n\")\n",
    "                current_section = element_type\n",
    "                \n",
    "            else:\n",
    "                # Regular text/paragraph - the most common case\n",
    "                # Check if this continues the previous text section\n",
    "                if current_section == 'text' and not text.endswith('.'):\n",
    "                    # Might be continuation of previous paragraph\n",
    "                    lines.append(f\"{text}\")\n",
    "                else:\n",
    "                    lines.append(f\"{text}\\n\")\n",
    "                current_section = 'text'\n",
    "            \n",
    "            # Add confidence indicator for low-confidence extractions (optional)\n",
    "            if confidence < 0.5:\n",
    "                lines.append(f\"*(confidence: {confidence:.2f})*\\n\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def save_results(doc_name: str, elements: List[Dict], stats: Dict, markdown_content: str) -> bool:\n",
    "    \"\"\"Save processing results with layout analysis information.\"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    doc_output_dir = OUTPUT_DIR / doc_name\n",
    "    doc_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Save markdown file\n",
    "        markdown_path = doc_output_dir / f\"{doc_name}_nanonets_clean.md\"\n",
    "        with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(markdown_content)\n",
    "        \n",
    "        # Count elements with layout info\n",
    "        elements_with_layout = len([e for e in elements if e.get('layout_info')])\n",
    "        \n",
    "        # Save detailed JSON with layout information\n",
    "        json_path = doc_output_dir / f\"{doc_name}_processing_results.json\"\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                'document_name': doc_name,\n",
    "                'processing_timestamp': datetime.now().isoformat(),\n",
    "                'processing_stats': stats,\n",
    "                'layout_analysis_used': elements_with_layout > 0,\n",
    "                'elements_with_layout_info': elements_with_layout,\n",
    "                'total_elements': len(elements),\n",
    "                'successful_elements': len([e for e in elements if e['success']]),\n",
    "                'average_confidence': sum(e['confidence'] for e in elements if e['success']) / max(1, len([e for e in elements if e['success']])),\n",
    "                'reading_order_method': 'layout_analysis_spatial' if elements_with_layout > 0 else 'filename_based',\n",
    "                'elements': elements\n",
    "            }, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"  ‚úÖ Saved: {markdown_path}\")\n",
    "        print(f\"  üìÑ JSON: {json_path}\")\n",
    "        print(f\"  üìç Layout-based reading order: {'‚úÖ' if elements_with_layout > 0 else '‚ùå'}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Failed to save results: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def analyze_layout_coverage(doc_dir: Path) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze how well the cropped images match with layout analysis.\"\"\"\n",
    "    \n",
    "    # Load layout analysis\n",
    "    layout_json_path = doc_dir / \"layout_analysis.json\"\n",
    "    if not layout_json_path.exists():\n",
    "        return {\"layout_file_exists\": False}\n",
    "    \n",
    "    try:\n",
    "        with open(layout_json_path, 'r', encoding='utf-8') as f:\n",
    "            layout_data = json.load(f)\n",
    "    except Exception:\n",
    "        return {\"layout_file_exists\": True, \"readable\": False}\n",
    "    \n",
    "    # Get cropped images\n",
    "    cropped_dir = doc_dir / \"cropped_images\"\n",
    "    if not cropped_dir.exists():\n",
    "        return {\"layout_file_exists\": True, \"readable\": True, \"cropped_dir_exists\": False}\n",
    "    \n",
    "    image_files = []\n",
    "    for ext in ['*.png', '*.jpg', '*.jpeg']:\n",
    "        image_files.extend(cropped_dir.glob(ext))\n",
    "    \n",
    "    # Analyze coverage\n",
    "    layout_elements = []\n",
    "    for page_data in layout_data.get('pages', []):\n",
    "        layout_elements.extend(page_data.get('elements', []))\n",
    "    \n",
    "    analysis = {\n",
    "        \"layout_file_exists\": True,\n",
    "        \"readable\": True,\n",
    "        \"cropped_dir_exists\": True,\n",
    "        \"layout_elements_count\": len(layout_elements),\n",
    "        \"cropped_images_count\": len(image_files),\n",
    "        \"element_types_in_layout\": {},\n",
    "        \"coverage_ratio\": len(image_files) / max(1, len(layout_elements))\n",
    "    }\n",
    "    \n",
    "    # Count element types\n",
    "    for element in layout_elements:\n",
    "        elem_type = element.get('type', 'unknown')\n",
    "        analysis[\"element_types_in_layout\"][elem_type] = analysis[\"element_types_in_layout\"].get(elem_type, 0) + 1\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "print(\"‚úÖ Enhanced markdown generation with layout-based reading order defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Complete Batch Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beead480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_documents():\n",
    "    \"\"\"Process all documents in the layout_results directory.\"\"\"\n",
    "    \n",
    "    if not LAYOUT_RESULTS_DIR.exists():\n",
    "        print(f\"‚ùå Layout results directory not found: {LAYOUT_RESULTS_DIR}\")\n",
    "        return\n",
    "    \n",
    "    # Get all document directories\n",
    "    doc_dirs = [d for d in LAYOUT_RESULTS_DIR.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not doc_dirs:\n",
    "        print(\"‚ùå No document directories found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üöÄ Starting batch processing for {len(doc_dirs)} documents...\")\n",
    "    print(f\"üìÅ Results will be saved to: {OUTPUT_DIR}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Processing statistics\n",
    "    overall_stats = {\n",
    "        'total_documents': len(doc_dirs),\n",
    "        'processed_documents': 0,\n",
    "        'successful_documents': 0,\n",
    "        'total_images': 0,\n",
    "        'successful_extractions': 0,\n",
    "        'failed_extractions': 0,\n",
    "        'small_images_handled': 0,\n",
    "        'total_processing_time': 0,\n",
    "        'average_confidence': 0.0\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    all_confidences = []\n",
    "    \n",
    "    # Process each document\n",
    "    for doc_dir in sorted(doc_dirs):\n",
    "        doc_name = doc_dir.name\n",
    "        print(f\"\\nüìÑ Processing: {doc_name}\")\n",
    "        \n",
    "        doc_start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Process the document\n",
    "            result = process_single_document(doc_dir)\n",
    "            elements = result['elements']\n",
    "            stats = result['stats']\n",
    "            \n",
    "            if not elements:\n",
    "                print(f\"  ‚ö†Ô∏è No elements processed for {doc_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Generate markdown\n",
    "            markdown_content = generate_clean_markdown(elements, doc_name)\n",
    "            \n",
    "            # Save results\n",
    "            if save_results(doc_name, elements, stats, markdown_content):\n",
    "                overall_stats['successful_documents'] += 1\n",
    "                \n",
    "                # Update statistics\n",
    "                overall_stats['total_images'] += stats['total']\n",
    "                overall_stats['successful_extractions'] += stats['processed']\n",
    "                overall_stats['failed_extractions'] += stats['failed']\n",
    "                overall_stats['small_images_handled'] += stats['small_images']\n",
    "                \n",
    "                # Collect confidences\n",
    "                confidences = [e['confidence'] for e in elements if e['success']]\n",
    "                all_confidences.extend(confidences)\n",
    "                \n",
    "                doc_time = time.time() - doc_start_time\n",
    "                avg_confidence = sum(confidences) / len(confidences) if confidences else 0\n",
    "                \n",
    "                print(f\"  üìä Document Summary:\")\n",
    "                print(f\"    üñºÔ∏è Images: {stats['total']}\")\n",
    "                print(f\"    ‚úÖ Processed: {stats['processed']}\")\n",
    "                print(f\"    üîç Small images: {stats['small_images']}\")\n",
    "                print(f\"    üéØ Avg confidence: {avg_confidence:.3f}\")\n",
    "                print(f\"    ‚è±Ô∏è Time: {doc_time:.2f}s\")\n",
    "            \n",
    "            overall_stats['processed_documents'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error processing {doc_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate final statistics\n",
    "    total_time = time.time() - start_time\n",
    "    overall_stats['total_processing_time'] = total_time\n",
    "    overall_stats['average_confidence'] = sum(all_confidences) / len(all_confidences) if all_confidences else 0\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üéâ BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìä Final Statistics:\")\n",
    "    print(f\"  üìÅ Documents processed: {overall_stats['processed_documents']}/{overall_stats['total_documents']}\")\n",
    "    print(f\"  ‚úÖ Successful documents: {overall_stats['successful_documents']}\")\n",
    "    print(f\"  \uddbcÔ∏è Total images: {overall_stats['total_images']}\")\n",
    "    print(f\"  ‚úÖ Successful extractions: {overall_stats['successful_extractions']}\")\n",
    "    print(f\"  ‚ùå Failed extractions: {overall_stats['failed_extractions']}\")\n",
    "    print(f\"  üîç Small images handled: {overall_stats['small_images_handled']}\")\n",
    "    print(f\"  üéØ Overall success rate: {(overall_stats['successful_extractions']/max(1,overall_stats['total_images'])*100):.1f}%\")\n",
    "    print(f\"  üéØ Average confidence: {overall_stats['average_confidence']:.3f}\")\n",
    "    print(f\"  ‚è±Ô∏è Total time: {total_time:.2f}s ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"  üöÄ Processing speed: {overall_stats['total_images']/max(1,total_time):.2f} images/second\")\n",
    "    print(f\"  üíæ Results saved to: {OUTPUT_DIR}\")\n",
    "    \n",
    "    # Save overall statistics\n",
    "    try:\n",
    "        stats_path = OUTPUT_DIR / \"batch_processing_summary.json\"\n",
    "        OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                'processing_completed': datetime.now().isoformat(),\n",
    "                'model_used': NANONETS_MODEL,\n",
    "                'device_used': DEVICE,\n",
    "                'overall_statistics': overall_stats\n",
    "            }, f, indent=2)\n",
    "        print(f\"  \udcca Summary saved: {stats_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Could not save summary: {e}\")\n",
    "    \n",
    "    return overall_stats\n",
    "\n",
    "print(\"‚úÖ Complete batch processing pipeline defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Execute Complete Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the complete Nanonets OCR processing pipeline\n",
    "\n",
    "print(\"üöÄ Starting Complete Nanonets OCR Processing\")\n",
    "print(\"=\" * 80)\n",
    "print(\"üéØ Features:\")\n",
    "print(\"  ‚Ä¢ Clean text extraction only\")\n",
    "print(\"  ‚Ä¢ Smart image preprocessing (handles all sizes)\")\n",
    "print(\"  ‚Ä¢ Element-type specific prompts\")\n",
    "print(\"  ‚Ä¢ Structured markdown output\")\n",
    "print(\"  ‚Ä¢ Comprehensive batch processing\")\n",
    "print(\"  ‚Ä¢ No extra commentary in output\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if OCR engine is ready\n",
    "if not ocr_engine.is_ready():\n",
    "    print(\"‚ùå OCR engine not initialized!\")\n",
    "    print(\"Please run the OCR engine initialization cell first.\")\n",
    "else:\n",
    "    # Execute the complete processing\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Show GPU memory if available\n",
    "        if USE_GPU:\n",
    "            print(f\"\\nüíæ GPU Memory before processing:\")\n",
    "            print(f\"  Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "            print(f\"  Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "        \n",
    "        # Run batch processing\n",
    "        results = process_all_documents()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        if USE_GPU:\n",
    "            print(f\"\\n\udcbe GPU Memory after processing:\")\n",
    "            print(f\"  Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "            print(f\"  Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "        \n",
    "        print(f\"\\nüéâ PROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"‚úÖ All documents processed with Nanonets OCR\")\n",
    "        print(f\"‚úÖ Clean markdown files generated\")\n",
    "        print(f\"‚úÖ Results saved to '{OUTPUT_DIR}' directory\")\n",
    "        print(f\"‚è±Ô∏è Total execution time: {total_time:.2f}s ({total_time/60:.1f} minutes)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during processing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69517d4",
   "metadata": {},
   "source": [
    "## 7. Test Single Document (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b423578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test processing on a single document (optional)\n",
    "\n",
    "def test_single_document():\n",
    "    \"\"\"Test processing on one document for validation.\"\"\"\n",
    "    \n",
    "    if not LAYOUT_RESULTS_DIR.exists():\n",
    "        print(\"‚ùå Layout results directory not found\")\n",
    "        return\n",
    "    \n",
    "    # Get first document\n",
    "    doc_dirs = [d for d in LAYOUT_RESULTS_DIR.iterdir() if d.is_dir()]\n",
    "    if not doc_dirs:\n",
    "        print(\"‚ùå No documents found\")\n",
    "        return\n",
    "    \n",
    "    test_doc = doc_dirs[0]\n",
    "    doc_name = test_doc.name\n",
    "    \n",
    "    print(f\"üß™ Testing single document: {doc_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Process the document\n",
    "    result = process_single_document(test_doc)\n",
    "    elements = result['elements']\n",
    "    stats = result['stats']\n",
    "    \n",
    "    # Show results\n",
    "    print(f\"\\nüìä Test Results:\")\n",
    "    print(f\"  üì∏ Total images: {stats['total']}\")\n",
    "    print(f\"  ‚úÖ Processed: {stats['processed']}\")\n",
    "    print(f\"  ‚ùå Failed: {stats['failed']}\")\n",
    "    print(f\"  üîç Small images: {stats['small_images']}\")\n",
    "    \n",
    "    if elements:\n",
    "        print(f\"\\nüìã Sample extracted content:\")\n",
    "        for i, element in enumerate(elements[:5]):  # Show first 5\n",
    "            if element['success']:\n",
    "                text_preview = element['extracted_text'][:100]\n",
    "                print(f\"  {i+1}. {element['element_type']}: {text_preview}...\")\n",
    "                print(f\"     Confidence: {element['confidence']:.3f}\")\n",
    "    \n",
    "    # Generate and show markdown preview\n",
    "    markdown_content = generate_clean_markdown(elements, doc_name)\n",
    "    print(f\"\\nüìÑ Markdown preview (first 500 chars):\")\n",
    "    print(\"-\" * 30)\n",
    "    print(markdown_content[:500])\n",
    "    if len(markdown_content) > 500:\n",
    "        print(\"...\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test completed successfully!\")\n",
    "    return result\n",
    "\n",
    "# Uncomment the line below to run the test\n",
    "# test_single_document()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18896d2a",
   "metadata": {},
   "source": [
    "## 8. Results Analysis and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ca45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results():\n",
    "    \"\"\"Analyze the generated results with layout analysis coverage.\"\"\"\n",
    "    \n",
    "    if not OUTPUT_DIR.exists():\n",
    "        print(f\"‚ùå Output directory not found: {OUTPUT_DIR}\")\n",
    "        return\n",
    "    \n",
    "    # Get all result directories\n",
    "    result_dirs = [d for d in OUTPUT_DIR.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not result_dirs:\n",
    "        print(\"‚ùå No results found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Results Analysis with Layout Analysis Coverage\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Documents processed: {len(result_dirs)}\")\n",
    "    \n",
    "    total_markdown_files = 0\n",
    "    total_json_files = 0\n",
    "    total_size = 0\n",
    "    all_stats = []\n",
    "    layout_usage_count = 0\n",
    "    \n",
    "    # Analyze each document\n",
    "    for doc_dir in result_dirs:\n",
    "        doc_name = doc_dir.name\n",
    "        \n",
    "        # Check for files\n",
    "        md_files = list(doc_dir.glob(\"*_nanonets_clean.md\"))\n",
    "        json_files = list(doc_dir.glob(\"*_processing_results.json\"))\n",
    "        \n",
    "        if md_files:\n",
    "            total_markdown_files += 1\n",
    "            md_size = md_files[0].stat().st_size\n",
    "            total_size += md_size\n",
    "            \n",
    "        if json_files:\n",
    "            total_json_files += 1\n",
    "            json_size = json_files[0].stat().st_size\n",
    "            total_size += json_size\n",
    "            \n",
    "            # Load statistics\n",
    "            try:\n",
    "                with open(json_files[0], 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    stats = data.get('processing_stats', {})\n",
    "                    all_stats.append(stats)\n",
    "                    \n",
    "                    # Check layout analysis usage\n",
    "                    if data.get('layout_analysis_used', False):\n",
    "                        layout_usage_count += 1\n",
    "                        elements_with_layout = data.get('elements_with_layout_info', 0)\n",
    "                        total_elements = data.get('total_elements', 0)\n",
    "                        print(f\"  üìç {doc_name}: {elements_with_layout}/{total_elements} elements with layout info\")\n",
    "                    \n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "    print(f\"\\nFile Statistics:\")\n",
    "    print(f\"  Markdown files: {total_markdown_files}\")\n",
    "    print(f\"  JSON files: {total_json_files}\")\n",
    "    print(f\"  Total size: {total_size / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    if all_stats:\n",
    "        total_images = sum(s.get('total', 0) for s in all_stats)\n",
    "        total_processed = sum(s.get('processed', 0) for s in all_stats)\n",
    "        total_failed = sum(s.get('failed', 0) for s in all_stats)\n",
    "        total_small = sum(s.get('small_images', 0) for s in all_stats)\n",
    "        \n",
    "        print(f\"\\nProcessing Statistics:\")\n",
    "        print(f\"  Total images: {total_images}\")\n",
    "        print(f\"  Successfully processed: {total_processed}\")\n",
    "        print(f\"  Failed: {total_failed}\")\n",
    "        print(f\"  Small images handled: {total_small}\")\n",
    "        print(f\"  Success rate: {(total_processed/max(1,total_images)*100):.1f}%\")\n",
    "    \n",
    "    print(f\"\\nLayout Analysis Usage:\")\n",
    "    print(f\"  Documents using layout analysis: {layout_usage_count}/{len(result_dirs)}\")\n",
    "    print(f\"  Layout coverage: {(layout_usage_count/max(1,len(result_dirs))*100):.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüíæ Results location: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "def analyze_layout_coverage_all():\n",
    "    \"\"\"Analyze layout analysis coverage for all documents.\"\"\"\n",
    "    \n",
    "    if not LAYOUT_RESULTS_DIR.exists():\n",
    "        print(f\"‚ùå Layout results directory not found: {LAYOUT_RESULTS_DIR}\")\n",
    "        return\n",
    "    \n",
    "    doc_dirs = [d for d in LAYOUT_RESULTS_DIR.iterdir() if d.is_dir()]\n",
    "    \n",
    "    print(f\"üìä Layout Analysis Coverage Report\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_docs = len(doc_dirs)\n",
    "    docs_with_layout = 0\n",
    "    docs_with_cropped = 0\n",
    "    docs_with_both = 0\n",
    "    \n",
    "    coverage_details = []\n",
    "    \n",
    "    for doc_dir in doc_dirs[:10]:  # Analyze first 10 for detailed view\n",
    "        doc_name = doc_dir.name\n",
    "        analysis = analyze_layout_coverage(doc_dir)\n",
    "        \n",
    "        has_layout = analysis.get('layout_file_exists', False) and analysis.get('readable', False)\n",
    "        has_cropped = analysis.get('cropped_dir_exists', False)\n",
    "        \n",
    "        if has_layout:\n",
    "            docs_with_layout += 1\n",
    "        if has_cropped:\n",
    "            docs_with_cropped += 1\n",
    "        if has_layout and has_cropped:\n",
    "            docs_with_both += 1\n",
    "            \n",
    "        if has_layout and has_cropped:\n",
    "            coverage_details.append({\n",
    "                'doc': doc_name,\n",
    "                'layout_elements': analysis.get('layout_elements_count', 0),\n",
    "                'cropped_images': analysis.get('cropped_images_count', 0),\n",
    "                'coverage_ratio': analysis.get('coverage_ratio', 0),\n",
    "                'element_types': analysis.get('element_types_in_layout', {})\n",
    "            })\n",
    "    \n",
    "    print(f\"Sample Analysis (first 10 documents):\")\n",
    "    print(f\"  Documents with layout analysis: {docs_with_layout}/10\")\n",
    "    print(f\"  Documents with cropped images: {docs_with_cropped}/10\")\n",
    "    print(f\"  Documents with both: {docs_with_both}/10\")\n",
    "    \n",
    "    if coverage_details:\n",
    "        print(f\"\\nDetailed Coverage:\")\n",
    "        for detail in coverage_details[:5]:\n",
    "            print(f\"  üìÑ {detail['doc']}:\")\n",
    "            print(f\"    Layout elements: {detail['layout_elements']}\")\n",
    "            print(f\"    Cropped images: {detail['cropped_images']}\")\n",
    "            print(f\"    Coverage ratio: {detail['coverage_ratio']:.2f}\")\n",
    "            print(f\"    Element types: {detail['element_types']}\")\n",
    "\n",
    "\n",
    "def show_reading_order_sample():\n",
    "    \"\"\"Show sample reading order from a processed document.\"\"\"\n",
    "    \n",
    "    if not OUTPUT_DIR.exists():\n",
    "        print(\"‚ùå No output directory found\")\n",
    "        return\n",
    "    \n",
    "    # Find first JSON file with results\n",
    "    json_files = list(OUTPUT_DIR.glob(\"**/*_processing_results.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(\"‚ùå No processing results found\")\n",
    "        return\n",
    "    \n",
    "    sample_file = json_files[0]\n",
    "    print(f\"üìÑ Reading Order Sample from: {sample_file.parent.name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        elements = data.get('elements', [])\n",
    "        layout_used = data.get('layout_analysis_used', False)\n",
    "        \n",
    "        print(f\"Layout analysis used: {'‚úÖ' if layout_used else '‚ùå'}\")\n",
    "        print(f\"Reading order method: {data.get('reading_order_method', 'unknown')}\")\n",
    "        print(f\"\\nElement order (first 10):\")\n",
    "        \n",
    "        for i, element in enumerate(elements[:10]):\n",
    "            element_type = element.get('element_type', 'unknown')\n",
    "            success = element.get('success', False)\n",
    "            has_layout = element.get('layout_info') is not None\n",
    "            \n",
    "            text_preview = \"\"\n",
    "            if success:\n",
    "                text = element.get('extracted_text', '')\n",
    "                text_preview = text[:50] + (\"...\" if len(text) > 50 else \"\")\n",
    "            \n",
    "            layout_indicator = \"\udccd\" if has_layout else \"üìù\"\n",
    "            status = \"‚úÖ\" if success else \"‚ùå\"\n",
    "            \n",
    "            print(f\"  {i+1:2d}. {layout_indicator} {status} {element_type:15s} - {text_preview}\")\n",
    "        \n",
    "        if len(elements) > 10:\n",
    "            print(f\"     ... and {len(elements) - 10} more elements\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not read file: {e}\")\n",
    "\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Clean up GPU memory.\"\"\"\n",
    "    if USE_GPU:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"üßπ GPU memory cleaned\")\n",
    "    else:\n",
    "        print(\"üßπ No GPU memory to clean\")\n",
    "\n",
    "\n",
    "def show_sample_output():\n",
    "    \"\"\"Show sample output from processed documents.\"\"\"\n",
    "    \n",
    "    if not OUTPUT_DIR.exists():\n",
    "        print(\"‚ùå No output directory found\")\n",
    "        return\n",
    "    \n",
    "    # Find first markdown file\n",
    "    md_files = list(OUTPUT_DIR.glob(\"**/*.md\"))\n",
    "    \n",
    "    if not md_files:\n",
    "        print(\"‚ùå No markdown files found\")\n",
    "        return\n",
    "    \n",
    "    sample_file = md_files[0]\n",
    "    print(f\"üìÑ Sample output from: {sample_file.name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Show first 1000 characters\n",
    "        print(content[:1000])\n",
    "        if len(content) > 1000:\n",
    "            print(f\"\\n... (showing first 1000 of {len(content)} characters)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not read file: {e}\")\n",
    "\n",
    "print(\"‚úÖ Enhanced analysis functions with layout coverage defined\")\n",
    "print(\"üìä Use analyze_results() to see processing statistics with layout coverage\")\n",
    "print(\"üìç Use analyze_layout_coverage_all() to check layout analysis availability\")\n",
    "print(\"üìñ Use show_reading_order_sample() to see reading order information\")\n",
    "print(\"üßπ Use cleanup_memory() to free GPU memory\")\n",
    "print(\"üìÑ Use show_sample_output() to see sample results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed91b11",
   "metadata": {},
   "source": [
    "## 9. Quick Analysis Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick analysis commands - run after processing\n",
    "\n",
    "print(\"\udcca Quick Analysis Options:\")\n",
    "print(\"=\"*40)\n",
    "print(\"1. analyze_results()     - Show processing statistics\")\n",
    "print(\"2. show_sample_output()  - Display sample markdown output\") \n",
    "print(\"3. test_single_document() - Test on one document\")\n",
    "print(\"4. cleanup_memory()      - Free GPU memory\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Uncomment any line below to run:\n",
    "# analyze_results()\n",
    "# show_sample_output()\n",
    "# cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f65ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Complete Nanonets OCR Processing Pipeline\n",
    "\n",
    "**Summary:** This notebook provides a complete, clean implementation for processing all cropped images using Nanonets OCR with optimized prompts and structured markdown output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c333ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"‚úÖ Nanonets OCR Markdown Generator - Complete Implementation\")\n",
    "print(\"üéØ Features: Smart image processing, clean text extraction, structured output\")\n",
    "print(\"üìÅ Input: layout_results/ directory with cropped images\")\n",
    "print(\"\udcbe Output: nanonets_clean_results/ directory with clean markdown files\")\n",
    "print(\"üöÄ Ready to process all your documents with state-of-the-art OCR!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d93138",
   "metadata": {},
   "source": [
    "## 10. Results Analysis and Validation\n",
    "\n",
    "Let's analyze the Nanonets OCR results and validate the generated markdown files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_nanonets_results():\n",
    "    \"\"\"\n",
    "    Analyze the generated Nanonets OCR results with detailed statistics\n",
    "    \"\"\"\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        print(f\"‚ùå Output directory '{OUTPUT_DIR}' not found\")\n",
    "        return\n",
    "    \n",
    "    result_dirs = [d for d in os.listdir(OUTPUT_DIR) \n",
    "                   if os.path.isdir(os.path.join(OUTPUT_DIR, d))]\n",
    "    \n",
    "    if not result_dirs:\n",
    "        print(\"‚ùå No result directories found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Nanonets OCR Results Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ü§ñ OCR Engine: Nanonets OCR ({NANONETS_MODEL})\")\n",
    "    print(f\"üìÑ Total documents processed: {len(result_dirs)}\")\n",
    "    \n",
    "    total_markdown_files = 0\n",
    "    total_json_files = 0\n",
    "    total_size = 0\n",
    "    total_elements_count = 0\n",
    "    element_types = {}\n",
    "    confidence_stats = {'high': 0, 'medium': 0, 'low': 0}\n",
    "    overall_confidences = []\n",
    "    feature_usage = {\n",
    "        'html_tables': 0,\n",
    "        'latex_equations': 0,\n",
    "        'image_descriptions': 0,\n",
    "        'watermarks': 0,\n",
    "        'special_elements': 0\n",
    "    }\n",
    "    \n",
    "    # Analyze each document\n",
    "    for doc_name in result_dirs:\n",
    "        doc_dir = os.path.join(OUTPUT_DIR, doc_name)\n",
    "        \n",
    "        # Check for markdown file\n",
    "        md_file = os.path.join(doc_dir, f\"{doc_name}_nanonets.md\")\n",
    "        json_file = os.path.join(doc_dir, f\"{doc_name}_nanonets_detailed.json\")\n",
    "        \n",
    "        if os.path.exists(md_file):\n",
    "            total_markdown_files += 1\n",
    "            md_size = os.path.getsize(md_file)\n",
    "            total_size += md_size\n",
    "            \n",
    "            # Analyze markdown content for advanced features\n",
    "            with open(md_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                if '<table>' in content.lower():\n",
    "                    feature_usage['html_tables'] += 1\n",
    "                if '$$' in content or '\\\\begin{' in content:\n",
    "                    feature_usage['latex_equations'] += 1\n",
    "                if '<img>' in content:\n",
    "                    feature_usage['image_descriptions'] += 1\n",
    "                if 'watermark' in content.lower():\n",
    "                    feature_usage['watermarks'] += 1\n",
    "                if any(marker in content for marker in ['‚òê', '‚òë', '<page_number>', '*[Page:']):\n",
    "                    feature_usage['special_elements'] += 1\n",
    "        \n",
    "        if os.path.exists(json_file):\n",
    "            total_json_files += 1\n",
    "            json_size = os.path.getsize(json_file)\n",
    "            total_size += json_size\n",
    "            \n",
    "            # Analyze detailed processing data\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    \n",
    "                    stats = data.get('processing_stats', {})\n",
    "                    total_elements_count += stats.get('total_elements', 0)\n",
    "                    \n",
    "                    # Track confidence distribution\n",
    "                    conf_dist = stats.get('confidence_distribution', {})\n",
    "                    confidence_stats['high'] += conf_dist.get('high', 0)\n",
    "                    confidence_stats['medium'] += conf_dist.get('medium', 0)\n",
    "                    confidence_stats['low'] += conf_dist.get('low', 0)\n",
    "                    \n",
    "                    # Overall confidence\n",
    "                    if stats.get('avg_confidence', 0) > 0:\n",
    "                        overall_confidences.append(stats['avg_confidence'])\n",
    "                    \n",
    "                    # Count element types\n",
    "                    elem_types = stats.get('element_types', {})\n",
    "                    for elem_type, count in elem_types.items():\n",
    "                        element_types[elem_type] = element_types.get(elem_type, 0) + count\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"üìù Markdown files generated: {total_markdown_files}\")\n",
    "    print(f\"üìÑ Detailed JSON files generated: {total_json_files}\")\n",
    "    print(f\"üî§ Total elements processed: {total_elements_count}\")\n",
    "    print(f\"üíæ Total output size: {total_size / 1024:.2f} KB\")\n",
    "    \n",
    "    # Advanced feature usage analysis\n",
    "    if any(feature_usage.values()):\n",
    "        print(f\"\\\\nüé® Advanced Features Usage:\")\n",
    "        print(f\"  üìä HTML Tables: {feature_usage['html_tables']} documents\")\n",
    "        print(f\"  üî¢ LaTeX Equations: {feature_usage['latex_equations']} documents\")\n",
    "        print(f\"  üñºÔ∏è Image Descriptions: {feature_usage['image_descriptions']} documents\")\n",
    "        print(f\"  üè∑Ô∏è Watermarks Detected: {feature_usage['watermarks']} documents\")\n",
    "        print(f\"  ‚≠ê Special Elements: {feature_usage['special_elements']} documents\")\n",
    "    \n",
    "    # Confidence analysis\n",
    "    if overall_confidences:\n",
    "        avg_confidence = sum(overall_confidences) / len(overall_confidences)\n",
    "        min_confidence = min(overall_confidences)\n",
    "        max_confidence = max(overall_confidences)\n",
    "        \n",
    "        print(f\"\\\\nüéØ Confidence Analysis:\")\n",
    "        print(f\"  üìä Average confidence: {avg_confidence:.3f}\")\n",
    "        print(f\"  üìà Confidence range: {min_confidence:.3f} - {max_confidence:.3f}\")\n",
    "        print(f\"  üü¢ High confidence (‚â•0.8): {confidence_stats['high']}\")\n",
    "        print(f\"  üü° Medium confidence (0.6-0.8): {confidence_stats['medium']}\")\n",
    "        print(f\"  üî¥ Low confidence (<0.6): {confidence_stats['low']}\")\n",
    "        \n",
    "        total_conf_elements = sum(confidence_stats.values())\n",
    "        if total_conf_elements > 0:\n",
    "            high_pct = (confidence_stats['high'] / total_conf_elements) * 100\n",
    "            print(f\"  ‚ú® High confidence percentage: {high_pct:.1f}%\")\n",
    "    \n",
    "    # Show element type distribution\n",
    "    if element_types:\n",
    "        print(f\"\\\\nüìä Element types distribution:\")\n",
    "        sorted_types = sorted(element_types.items(), key=lambda x: x[1], reverse=True)\n",
    "        for elem_type, count in sorted_types:\n",
    "            print(f\"  ‚Ä¢ {elem_type}: {count}\")\n",
    "    \n",
    "    # Performance insights\n",
    "    print(f\"\\\\n‚ö° Nanonets OCR Performance Insights:\")\n",
    "    if total_elements_count > 0:\n",
    "        avg_elements_per_doc = total_elements_count / len(result_dirs)\n",
    "        print(f\"  üìù Average elements per document: {avg_elements_per_doc:.1f}\")\n",
    "    \n",
    "    # Show sample of first few documents\n",
    "    print(f\"\\\\nüìÑ Sample Results (first 5 documents):\")\n",
    "    for i, doc_name in enumerate(result_dirs[:5]):\n",
    "        doc_dir = os.path.join(OUTPUT_DIR, doc_name)\n",
    "        md_file = os.path.join(doc_dir, f\"{doc_name}_nanonets.md\")\n",
    "        json_file = os.path.join(doc_dir, f\"{doc_name}_nanonets_detailed.json\")\n",
    "        \n",
    "        if os.path.exists(md_file):\n",
    "            md_size = os.path.getsize(md_file)\n",
    "            \n",
    "            # Get confidence info\n",
    "            conf_info = \"\"\n",
    "            if os.path.exists(json_file):\n",
    "                try:\n",
    "                    with open(json_file, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                        stats = data.get('processing_stats', {})\n",
    "                        avg_conf = stats.get('avg_confidence', 0)\n",
    "                        if avg_conf > 0:\n",
    "                            conf_info = f\" (conf: {avg_conf:.3f})\"\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            print(f\"  {i+1}. {doc_name}: {md_size / 1024:.2f} KB{conf_info}\")\n",
    "        else:\n",
    "            print(f\"  {i+1}. {doc_name}: ‚ùå No markdown file\")\n",
    "    \n",
    "    return len(result_dirs), total_elements_count\n",
    "\n",
    "def show_sample_nanonets_markdown():\n",
    "    \"\"\"\n",
    "    Show sample content from generated Nanonets markdown files\n",
    "    \"\"\"\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        return\n",
    "    \n",
    "    result_dirs = [d for d in os.listdir(OUTPUT_DIR) \n",
    "                   if os.path.isdir(os.path.join(OUTPUT_DIR, d))]\n",
    "    \n",
    "    if result_dirs:\n",
    "        # Show content from first document\n",
    "        sample_doc = result_dirs[0]\n",
    "        sample_md_path = os.path.join(OUTPUT_DIR, sample_doc, f\"{sample_doc}_nanonets.md\")\n",
    "        \n",
    "        if os.path.exists(sample_md_path):\n",
    "            print(f\"üìÑ Sample Nanonets Markdown Content ({sample_doc}):\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            with open(sample_md_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                # Show first 1500 characters to demonstrate quality\n",
    "                if len(content) > 1500:\n",
    "                    print(content[:1500] + \"\\\\n\\\\n... [Content truncated for display] ...\")\n",
    "                else:\n",
    "                    print(content)\n",
    "            \n",
    "            # Show advanced features detected\n",
    "            print(f\"\\\\nüé® Advanced Features Detected:\")\n",
    "            features_found = []\n",
    "            if '<table>' in content.lower():\n",
    "                features_found.append(\"üìä HTML Tables\")\n",
    "            if '$$' in content or '\\\\begin{' in content:\n",
    "                features_found.append(\"üî¢ LaTeX Equations\")\n",
    "            if '<img>' in content:\n",
    "                features_found.append(\"üñºÔ∏è Image Descriptions\")\n",
    "            if 'watermark' in content.lower():\n",
    "                features_found.append(\"üè∑Ô∏è Watermarks\")\n",
    "            if any(marker in content for marker in ['‚òê', '‚òë', '<page_number>', '*[Page:']):\n",
    "                features_found.append(\"‚≠ê Special Elements\")\n",
    "            \n",
    "            if features_found:\n",
    "                for feature in features_found:\n",
    "                    print(f\"   {feature}\")\n",
    "            else:\n",
    "                print(\"   Standard text extraction\")\n",
    "            \n",
    "            # Show statistics for this document\n",
    "            json_path = os.path.join(OUTPUT_DIR, sample_doc, f\"{sample_doc}_nanonets_detailed.json\")\n",
    "            if os.path.exists(json_path):\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    print(f\"\\\\nüìä Sample Document Statistics:\")\n",
    "                    print(f\"   ü§ñ OCR Engine: {data.get('ocr_engine', 'Nanonets OCR')}\")\n",
    "                    print(f\"   üî§ Elements processed: {data.get('processing_stats', {}).get('total_elements', 0)}\")\n",
    "                    print(f\"   üìÖ Processing date: {data.get('processed_at', 'Unknown')}\")\n",
    "                    \n",
    "                    config = data.get('configuration', {})\n",
    "                    print(f\"   ‚öôÔ∏è Configuration:\")\n",
    "                    print(f\"      Performance Mode: {'Fast' if config.get('fast_mode') else 'Quality'}\")\n",
    "                    print(f\"      Multi-GPU: {'Yes' if config.get('multi_gpu') else 'No'}\")\n",
    "                    print(f\"      Advanced Formatting: {'Yes' if config.get('advanced_formatting') else 'No'}\")\n",
    "                    \n",
    "                    # Show processing stats\n",
    "                    stats = data.get('processing_stats', {})\n",
    "                    print(f\"   üìä Processing Statistics:\")\n",
    "                    print(f\"      Elements with text: {stats.get('elements_with_text', 0)}\")\n",
    "                    print(f\"      Average confidence: {stats.get('avg_confidence', 0):.3f}\")\n",
    "                    print(f\"      High confidence elements: {stats.get('high_confidence_elements', 0)}\")\n",
    "                    \n",
    "                    # Show element types\n",
    "                    element_types = stats.get('element_types', {})\n",
    "                    if element_types:\n",
    "                        print(f\"      Element types found:\")\n",
    "                        for elem_type, count in sorted(element_types.items(), key=lambda x: x[1], reverse=True):\n",
    "                            print(f\"         ‚Ä¢ {elem_type}: {count}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Sample markdown file not found: {sample_md_path}\")\n",
    "    else:\n",
    "        print(\"‚ùå No processed documents found\")\n",
    "\n",
    "# Run analysis\n",
    "docs_processed, elements_processed = analyze_nanonets_results()\n",
    "\n",
    "# Show sample content\n",
    "print(\"\\\\n\" + \"=\" * 80)\n",
    "show_sample_nanonets_markdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25852e62",
   "metadata": {},
   "source": [
    "## 11. Final Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary and Completion\n",
    "print(\"üéâ Nanonets OCR Markdown Generator - Complete Summary\")\n",
    "print(\"=\" * 80)\n",
    "print(\"ü§ñ Features Implemented with Nanonets OCR:\")\n",
    "print(\"  ‚Ä¢ Advanced AI-powered text recognition\")\n",
    "print(\"  ‚Ä¢ Multi-GPU acceleration support\")\n",
    "print(\"  ‚Ä¢ HTML table extraction with proper formatting\")\n",
    "print(\"  ‚Ä¢ LaTeX equation recognition and formatting\")\n",
    "print(\"  ‚Ä¢ Intelligent image description generation\")\n",
    "print(\"  ‚Ä¢ Automatic watermark and page number detection\")\n",
    "print(\"  ‚Ä¢ Context-aware element processing\")\n",
    "print(\"  ‚Ä¢ Comprehensive confidence scoring\")\n",
    "print(\"  ‚Ä¢ Advanced markdown generation\")\n",
    "print(\"  ‚Ä¢ Robust error handling and retry logic\")\n",
    "print(\"\")\n",
    "print(\"üìÅ Output Structure:\")\n",
    "print(\"  nanonets_results/\")\n",
    "print(\"    ‚îú‚îÄ‚îÄ document_name_1/\")\n",
    "print(\"    ‚îÇ   ‚îú‚îÄ‚îÄ document_name_1_nanonets.md\")\n",
    "print(\"    ‚îÇ   ‚îî‚îÄ‚îÄ document_name_1_nanonets_detailed.json\")\n",
    "print(\"    ‚îú‚îÄ‚îÄ document_name_2/\")\n",
    "print(\"    ‚îÇ   ‚îú‚îÄ‚îÄ document_name_2_nanonets.md\")\n",
    "print(\"    ‚îÇ   ‚îî‚îÄ‚îÄ document_name_2_nanonets_detailed.json\")\n",
    "print(\"    ‚îî‚îÄ‚îÄ ...\")\n",
    "print(\"\")\n",
    "print(\"üöÄ Nanonets OCR Advantages Utilized:\")\n",
    "print(\"  ‚Ä¢ Superior accuracy on complex documents\")\n",
    "print(\"  ‚Ä¢ Native support for structured content\")\n",
    "print(\"  ‚Ä¢ Advanced AI understanding of document context\")\n",
    "print(\"  ‚Ä¢ Multi-GPU acceleration for faster processing\")\n",
    "print(\"  ‚Ä¢ Rich formatting with HTML and LaTeX support\")\n",
    "print(\"  ‚Ä¢ Intelligent element type recognition\")\n",
    "print(\"\")\n",
    "print(\"üîß Next Steps:\")\n",
    "print(\"  ‚Ä¢ Run all cells sequentially to process documents\")\n",
    "print(\"  ‚Ä¢ Review generated markdown files for quality\")\n",
    "print(\"  ‚Ä¢ Compare results with other OCR engines\")\n",
    "print(\"  ‚Ä¢ Fine-tune configuration for specific document types\")\n",
    "print(\"  ‚Ä¢ Use the zipping feature below for result archival\")\n",
    "print(\"\")\n",
    "\n",
    "# Display final statistics if available\n",
    "if 'processing_results' in locals() and processing_results:\n",
    "    print(\"üìà Final Processing Statistics:\")\n",
    "    print(f\"  ü§ñ OCR Engine: Nanonets OCR ({NANONETS_MODEL})\")\n",
    "    print(f\"  üìÑ Documents processed: {processing_results.get('successful_docs', 0)}\")\n",
    "    print(f\"  ‚ùå Processing failures: {processing_results.get('failed_docs', 0)}\")\n",
    "    print(f\"  üî§ Elements extracted: {processing_results.get('total_elements', 0)}\")\n",
    "    print(f\"  üéØ Average confidence: {processing_results.get('avg_confidence', 0):.3f}\")\n",
    "    print(f\"  ‚è±Ô∏è Processing time: {processing_results.get('processing_time', 0):.2f} seconds\")\n",
    "    print(f\"  üìà Success rate: {processing_results.get('success_rate', 0):.1f}%\")\n",
    "    print(f\"  üöÄ Processing speed: {processing_results.get('elements_per_second', 0):.2f} elements/second\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"‚ú® Nanonets OCR Pipeline Complete! ‚ú®\")\n",
    "print(\"üî• Your documents have been processed with state-of-the-art AI OCR!\")\n",
    "print(\"‚ö° Enjoy the advanced features and superior accuracy of Nanonets!\")\n",
    "print(\"\")\n",
    "print(\"üì¶ Proceed to the next section to create a compressed archive of results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13181b68",
   "metadata": {},
   "source": [
    "## 12. Archive Results - Create Compressed Package\n",
    "\n",
    "Create a compressed archive of all Nanonets OCR results for easy sharing, backup, and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "def create_results_archive():\n",
    "    \"\"\"\n",
    "    Create a comprehensive compressed archive of Nanonets OCR results\n",
    "    \"\"\"\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        print(\"‚ùå No results directory found to archive\")\n",
    "        print(f\"Expected directory: {OUTPUT_DIR}\")\n",
    "        return None\n",
    "    \n",
    "    # Check if there are any results to archive\n",
    "    result_dirs = [d for d in os.listdir(OUTPUT_DIR) \n",
    "                   if os.path.isdir(os.path.join(OUTPUT_DIR, d))]\n",
    "    \n",
    "    if not result_dirs:\n",
    "        print(\"‚ùå No processed documents found to archive\")\n",
    "        return None\n",
    "    \n",
    "    # Create archive filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    archive_name = f\"nanonets_ocr_results_{timestamp}.zip\"\n",
    "    archive_path = os.path.join(\".\", archive_name)\n",
    "    \n",
    "    print(\"üì¶ Creating Nanonets OCR Results Archive...\")\n",
    "    print(f\"üóÇÔ∏è Archive name: {archive_name}\")\n",
    "    print(f\"üìÅ Source directory: {OUTPUT_DIR}\")\n",
    "    \n",
    "    try:\n",
    "        # Calculate total size before compression\n",
    "        total_size = 0\n",
    "        total_files = 0\n",
    "        \n",
    "        for root, dirs, files in os.walk(OUTPUT_DIR):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                total_size += os.path.getsize(file_path)\n",
    "                total_files += 1\n",
    "        \n",
    "        print(f\"üìä Archiving {total_files} files ({total_size / 1024 / 1024:.2f} MB)\")\n",
    "        \n",
    "        # Create ZIP archive with compression\n",
    "        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:\n",
    "            \n",
    "            # Add all files from the results directory\n",
    "            for root, dirs, files in os.walk(OUTPUT_DIR):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    # Create relative path for archive\n",
    "                    arcname = os.path.relpath(file_path, \".\")\n",
    "                    zipf.write(file_path, arcname)\n",
    "            \n",
    "            # Create a summary file with metadata\n",
    "            summary_content = f\"\"\"# Nanonets OCR Results Archive\n",
    "            \n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "OCR Engine: Nanonets OCR ({NANONETS_MODEL})\n",
    "Performance Mode: {'Fast' if FAST_MODE else 'Quality'}\n",
    "Multi-GPU: {'Enabled' if USE_MULTI_GPU else 'Disabled'}\n",
    "Advanced Features: {'Enabled' if ENABLE_ADVANCED_FORMATTING else 'Disabled'}\n",
    "\n",
    "## Archive Contents:\n",
    "- Total Documents: {len(result_dirs)}\n",
    "- Total Files: {total_files}\n",
    "- Original Size: {total_size / 1024 / 1024:.2f} MB\n",
    "\n",
    "## Document Processing Results:\n",
    "\"\"\"\n",
    "            \n",
    "            # Add document statistics to summary\n",
    "            for doc_name in sorted(result_dirs):\n",
    "                doc_dir = os.path.join(OUTPUT_DIR, doc_name)\n",
    "                md_file = os.path.join(doc_dir, f\"{doc_name}_nanonets.md\")\n",
    "                json_file = os.path.join(doc_dir, f\"{doc_name}_nanonets_detailed.json\")\n",
    "                \n",
    "                md_size = os.path.getsize(md_file) if os.path.exists(md_file) else 0\n",
    "                json_size = os.path.getsize(json_file) if os.path.exists(json_file) else 0\n",
    "                \n",
    "                summary_content += f\"- {doc_name}: MD={md_size/1024:.1f}KB, JSON={json_size/1024:.1f}KB\\n\"\n",
    "            \n",
    "            summary_content += f\"\"\"\n",
    "## Features Utilized:\n",
    "- HTML Table Extraction: {'Yes' if ENABLE_ADVANCED_FORMATTING else 'No'}\n",
    "- LaTeX Equation Recognition: {'Yes' if ENABLE_ADVANCED_FORMATTING else 'No'}\n",
    "- Image Descriptions: {'Yes' if ENABLE_IMAGE_DESCRIPTIONS else 'No'}\n",
    "- Watermark Detection: {'Yes' if ENABLE_WATERMARK_DETECTION else 'No'}\n",
    "\n",
    "## Processing Configuration:\n",
    "- Page OCR Tokens: {PAGE_OCR_TOKENS}\n",
    "- Crop OCR Tokens: {CROP_OCR_TOKENS}\n",
    "- Table OCR Tokens: {TABLE_OCR_TOKENS}\n",
    "- Minimum Text Length: {MIN_TEXT_LENGTH}\n",
    "\n",
    "## File Structure:\n",
    "Each document folder contains:\n",
    "- document_name_nanonets.md: Rich markdown with advanced formatting\n",
    "- document_name_nanonets_detailed.json: Comprehensive processing metadata\n",
    "\n",
    "For questions or support, refer to the Nanonets OCR documentation.\n",
    "\"\"\"\n",
    "            \n",
    "            # Add summary to archive\n",
    "            zipf.writestr(\"README.txt\", summary_content)\n",
    "        \n",
    "        # Get final archive size\n",
    "        archive_size = os.path.getsize(archive_path)\n",
    "        compression_ratio = (1 - archive_size / total_size) * 100 if total_size > 0 else 0\n",
    "        \n",
    "        print(f\"‚úÖ Archive created successfully!\")\n",
    "        print(f\"üì¶ Archive file: {archive_path}\")\n",
    "        print(f\"üíæ Archive size: {archive_size / 1024 / 1024:.2f} MB\")\n",
    "        print(f\"üóúÔ∏è Compression ratio: {compression_ratio:.1f}%\")\n",
    "        \n",
    "        return archive_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating archive: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def create_selective_archive(document_names=None, include_json=True):\n",
    "    \"\"\"\n",
    "    Create a selective archive with specific documents or file types\n",
    "    \"\"\"\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        print(\"‚ùå No results directory found\")\n",
    "        return None\n",
    "    \n",
    "    # Get available documents\n",
    "    available_docs = [d for d in os.listdir(OUTPUT_DIR) \n",
    "                      if os.path.isdir(os.path.join(OUTPUT_DIR, d))]\n",
    "    \n",
    "    if not available_docs:\n",
    "        print(\"‚ùå No processed documents found\")\n",
    "        return None\n",
    "    \n",
    "    # Filter documents if specific names provided\n",
    "    if document_names:\n",
    "        docs_to_archive = [doc for doc in document_names if doc in available_docs]\n",
    "        if not docs_to_archive:\n",
    "            print(\"‚ùå None of the specified documents found\")\n",
    "            return None\n",
    "    else:\n",
    "        docs_to_archive = available_docs\n",
    "    \n",
    "    # Create selective archive\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    archive_name = f\"nanonets_ocr_selective_{timestamp}.zip\"\n",
    "    archive_path = os.path.join(\".\", archive_name)\n",
    "    \n",
    "    print(f\"üì¶ Creating selective archive: {archive_name}\")\n",
    "    print(f\"üìÑ Documents to include: {len(docs_to_archive)}\")\n",
    "    \n",
    "    try:\n",
    "        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:\n",
    "            total_files = 0\n",
    "            \n",
    "            for doc_name in docs_to_archive:\n",
    "                doc_dir = os.path.join(OUTPUT_DIR, doc_name)\n",
    "                \n",
    "                # Add markdown file\n",
    "                md_file = os.path.join(doc_dir, f\"{doc_name}_nanonets.md\")\n",
    "                if os.path.exists(md_file):\n",
    "                    arcname = f\"{doc_name}/{doc_name}_nanonets.md\"\n",
    "                    zipf.write(md_file, arcname)\n",
    "                    total_files += 1\n",
    "                \n",
    "                # Add JSON file if requested\n",
    "                if include_json:\n",
    "                    json_file = os.path.join(doc_dir, f\"{doc_name}_nanonets_detailed.json\")\n",
    "                    if os.path.exists(json_file):\n",
    "                        arcname = f\"{doc_name}/{doc_name}_nanonets_detailed.json\"\n",
    "                        zipf.write(json_file, arcname)\n",
    "                        total_files += 1\n",
    "            \n",
    "            # Add selective summary\n",
    "            summary = f\"\"\"# Selective Nanonets OCR Archive\n",
    "\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Documents included: {len(docs_to_archive)}\n",
    "Include JSON files: {'Yes' if include_json else 'No'}\n",
    "Total files: {total_files}\n",
    "\n",
    "Documents:\n",
    "{chr(10).join(f\"- {doc}\" for doc in docs_to_archive)}\n",
    "\"\"\"\n",
    "            zipf.writestr(\"README.txt\", summary)\n",
    "        \n",
    "        archive_size = os.path.getsize(archive_path)\n",
    "        print(f\"‚úÖ Selective archive created: {archive_size / 1024 / 1024:.2f} MB\")\n",
    "        return archive_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating selective archive: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create comprehensive results archive\n",
    "print(\"üöÄ Creating Comprehensive Results Archive...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "archive_path = create_results_archive()\n",
    "\n",
    "if archive_path:\n",
    "    print(f\"\"\"\n",
    "üìÅ Archive Details:\n",
    "  File: {archive_path}\n",
    "  Location: {os.path.abspath(archive_path)}\n",
    "  \n",
    "üìã Archive Contents:\n",
    "  ‚Ä¢ All markdown files with rich formatting\n",
    "  ‚Ä¢ Detailed JSON files with processing metadata\n",
    "  ‚Ä¢ README.txt with comprehensive documentation\n",
    "  ‚Ä¢ Complete processing statistics and configuration\n",
    "  \n",
    "üéØ Use Cases:\n",
    "  ‚Ä¢ Share results with colleagues or supervisors\n",
    "  ‚Ä¢ Backup processed documents\n",
    "  ‚Ä¢ Submit as part of research deliverables\n",
    "  ‚Ä¢ Archive for future reference\n",
    "  \n",
    "‚úÖ Archive ready for distribution!\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to create archive\")\n",
    "\n",
    "print(\"\\nüí° Additional Archive Options:\")\n",
    "print(\"You can also create selective archives by running:\")\n",
    "print(\"  ‚Ä¢ create_selective_archive(['doc1', 'doc2'])  # Specific documents\")\n",
    "print(\"  ‚Ä¢ create_selective_archive(include_json=False)  # Markdown only\")\n",
    "print(\"  ‚Ä¢ create_selective_archive()  # All documents, selective format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary and Next Steps\n",
    "print(\"üéâ Nanonets OCR Markdown Generator - Complete Summary\")\n",
    "print(\"=\" * 80)\n",
    "print(\"ü§ñ Features Implemented with Nanonets OCR:\")\n",
    "print(\"  ‚Ä¢ Advanced AI-powered text extraction with context understanding\")\n",
    "print(\"  ‚Ä¢ Multi-GPU acceleration for optimal performance\")\n",
    "print(\"  ‚Ä¢ HTML table extraction with proper formatting\")\n",
    "print(\"  ‚Ä¢ LaTeX equation recognition and rendering\")\n",
    "print(\"  ‚Ä¢ Intelligent image description generation\")\n",
    "print(\"  ‚Ä¢ Automatic watermark and page number detection\")\n",
    "print(\"  ‚Ä¢ Context-aware element processing\")\n",
    "print(\"  ‚Ä¢ Advanced confidence scoring and validation\")\n",
    "print(\"  ‚Ä¢ Comprehensive batch processing with statistics\")\n",
    "print(\"  ‚Ä¢ Memory optimization and error recovery\")\n",
    "print()\n",
    "print(\"üìÅ Output Structure:\")\n",
    "print(\"  nanonets_results/\")\n",
    "print(\"    ‚îú‚îÄ‚îÄ document_name_1/\")\n",
    "print(\"    ‚îÇ   ‚îú‚îÄ‚îÄ document_name_1_nanonets.md\")\n",
    "print(\"    ‚îÇ   ‚îî‚îÄ‚îÄ document_name_1_nanonets_detailed.json\")\n",
    "print(\"    ‚îú‚îÄ‚îÄ document_name_2/\")\n",
    "print(\"    ‚îÇ   ‚îú‚îÄ‚îÄ document_name_2_nanonets.md\")\n",
    "print(\"    ‚îÇ   ‚îî‚îÄ‚îÄ document_name_2_nanonets_detailed.json\")\n",
    "print(\"    ‚îî‚îÄ‚îÄ ...\")\n",
    "print()\n",
    "print(\"üöÄ Nanonets OCR Advantages Utilized:\")\n",
    "print(\"  ‚Ä¢ State-of-the-art AI models for superior accuracy\")\n",
    "print(\"  ‚Ä¢ Native support for complex document structures\")\n",
    "print(\"  ‚Ä¢ Advanced formatting with HTML and LaTeX\")\n",
    "print(\"  ‚Ä¢ Intelligent element type recognition\")\n",
    "print(\"  ‚Ä¢ Multi-GPU distributed processing\")\n",
    "print(\"  ‚Ä¢ Contextual understanding for better extraction\")\n",
    "print(\"  ‚Ä¢ Robust error handling and recovery\")\n",
    "print()\n",
    "print(\"üîß Next Steps:\")\n",
    "print(\"  ‚Ä¢ Compare results with other OCR engines (PaddleOCR, Tesseract)\")\n",
    "print(\"  ‚Ä¢ Fine-tune confidence thresholds for optimal quality\")\n",
    "print(\"  ‚Ä¢ Experiment with different token limits for speed vs quality\")\n",
    "print(\"  ‚Ä¢ Optimize GPU memory usage for larger documents\")\n",
    "print(\"  ‚Ä¢ Add post-processing enhancements for specific use cases\")\n",
    "print(\"  ‚Ä¢ Integrate with downstream document analysis pipelines\")\n",
    "print(\"  ‚Ä¢ Implement custom prompts for domain-specific documents\")\n",
    "print()\n",
    "print(\"üìä To view results:\")\n",
    "print(f\"  ‚Ä¢ Check the '{OUTPUT_DIR}' directory\")\n",
    "print(\"  ‚Ä¢ Review individual markdown files for human-readable content\")\n",
    "print(\"  ‚Ä¢ Analyze detailed JSON files for processing metadata\")\n",
    "print(\"  ‚Ä¢ Compare processing times and accuracy across documents\")\n",
    "print()\n",
    "\n",
    "# Display final statistics if available\n",
    "if 'processing_results' in locals() and processing_results:\n",
    "    print(\"üìà Final Processing Statistics:\")\n",
    "    print(f\"  ü§ñ OCR Engine: Nanonets OCR ({NANONETS_MODEL})\")\n",
    "    print(f\"  üìÑ Documents processed: {processing_results.get('successful_docs', 0)}\")\n",
    "    print(f\"  ‚ùå Processing failures: {processing_results.get('failed_docs', 0)}\")\n",
    "    print(f\"  üî§ Elements extracted: {processing_results.get('total_elements', 0)}\")\n",
    "    print(f\"  üéØ Average confidence: {processing_results.get('avg_confidence', 0):.3f}\")\n",
    "    print(f\"  ‚è±Ô∏è Processing time: {processing_results.get('processing_time', 0):.2f} seconds\")\n",
    "    print(f\"  üìà Success rate: {processing_results.get('success_rate', 0):.1f}%\")\n",
    "    \n",
    "    if processing_results.get('elements_per_second', 0) > 0:\n",
    "        print(f\"  üöÄ Processing speed: {processing_results['elements_per_second']:.1f} elements/second\")\n",
    "    \n",
    "    # Feature usage summary\n",
    "    if USE_MULTI_GPU:\n",
    "        print(f\"  ‚ö° Multi-GPU acceleration was utilized\")\n",
    "    if ENABLE_ADVANCED_FORMATTING:\n",
    "        print(f\"  üé® Advanced formatting features were enabled\")\n",
    "    if ENABLE_IMAGE_DESCRIPTIONS:\n",
    "        print(f\"  üñºÔ∏è Intelligent image descriptions were generated\")\n",
    "    if ENABLE_WATERMARK_DETECTION:\n",
    "        print(f\"  üè∑Ô∏è Watermark and special element detection was active\")\n",
    "    print()\n",
    "\n",
    "print(\"üéØ Comparison with Other OCR Engines:\")\n",
    "print(\"vs. Tesseract:\")\n",
    "print(\"  ‚úÖ Superior accuracy on complex documents\")\n",
    "print(\"  ‚úÖ Native support for tables and equations\")\n",
    "print(\"  ‚úÖ Better handling of varied fonts and layouts\")\n",
    "print(\"  ‚úÖ Advanced AI understanding of document context\")\n",
    "print()\n",
    "print(\"vs. PaddleOCR:\")\n",
    "print(\"  ‚úÖ More advanced formatting capabilities\")\n",
    "print(\"  ‚úÖ Better integration with modern ML pipelines\")\n",
    "print(\"  ‚úÖ Superior handling of complex document structures\")\n",
    "print(\"  ‚úÖ More intelligent content understanding\")\n",
    "print()\n",
    "print(\"vs. Cloud OCR Services:\")\n",
    "print(\"  ‚úÖ Full control over processing and data privacy\")\n",
    "print(\"  ‚úÖ No API rate limits or usage costs\")\n",
    "print(\"  ‚úÖ Customizable prompts and processing logic\")\n",
    "print(\"  ‚úÖ Integration with local GPU infrastructure\")\n",
    "\n",
    "print()\n",
    "print(\"‚ú® Nanonets OCR Pipeline Complete! ‚ú®\")\n",
    "print(\"ü§ñ Your documents have been processed with state-of-the-art AI OCR!\")\n",
    "print(\"‚ö° Enjoy the advanced formatting and superior accuracy!\")\n",
    "\n",
    "# Performance comparison note\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    if gpu_count > 1:\n",
    "        print(f\"üñ•Ô∏è Multi-GPU processing delivered optimal performance across {gpu_count} GPUs\")\n",
    "    else:\n",
    "        print(f\"üñ•Ô∏è Single GPU processing completed successfully\")\n",
    "        print(\"üí° Consider multi-GPU setup for even better performance on large document sets\")\n",
    "else:\n",
    "    print(\"üí° GPU acceleration would significantly improve processing speed\")\n",
    "\n",
    "print(f\"\\\\nüìÇ Complete Output Directory: {OUTPUT_DIR}\")\n",
    "print(\"üîç Explore the generated markdown files to see the advanced OCR results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3079a",
   "metadata": {},
   "source": [
    "# üöÄ Nanonets OCR Markdown Generator\n",
    "\n",
    "This notebook processes cropped images from layout detection results and performs OCR using **Nanonets OCR** to generate structured markdown files.\n",
    "\n",
    "**Features:**\n",
    "- üî• **Nanonets OCR** with multi-GPU acceleration support\n",
    "- üéØ **Advanced text recognition** with HTML tables and LaTeX equations\n",
    "- üìñ **Reading order detection** for logical text flow\n",
    "- üìù **Rich markdown generation** with comprehensive formatting\n",
    "- üìÅ **Organized output** in respective directories\n",
    "- üé® **Advanced element handling** (headers, text, tables, equations, images)\n",
    "- ‚ö° **GPU-optimized processing** for faster performance\n",
    "- üß† **Memory management** with automatic optimization\n",
    "\n",
    "**Input:** Layout detection results from `layout_results/` directory\n",
    "**Output:** Markdown files saved in `nanonets_results/` directory\n",
    "\n",
    "**Processing Pipeline:**\n",
    "1. Load cropped images and layout analysis\n",
    "2. Initialize Nanonets OCR with optimal settings\n",
    "3. Perform OCR with advanced prompting for rich content extraction\n",
    "4. Sort text elements by reading order\n",
    "5. Generate structured markdown content with HTML tables and LaTeX\n",
    "6. Save markdown files with comprehensive formatting\n",
    "\n",
    "**Advantages over Traditional OCR:**\n",
    "- Superior accuracy on complex documents\n",
    "- Native support for tables, equations, and images\n",
    "- Better handling of document structure\n",
    "- Advanced formatting capabilities\n",
    "- Multi-GPU acceleration support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0b08c",
   "metadata": {},
   "source": [
    "## Complete Cropped Files OCR Processing with Clean Output\n",
    "\n",
    "This section provides a comprehensive solution to process all cropped images using Nanonets OCR with optimized prompts and clean markdown output containing only extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick OCR Engine Initialization (if not already loaded)\n",
    "if 'ocr_engine' not in globals() or ocr_engine is None:\n",
    "    print(\"üîÑ Initializing Nanonets OCR Engine...\")\n",
    "    \n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n",
    "    \n",
    "    # Configuration\n",
    "    NANONETS_MODEL = \"nanonets/Nanonets-OCR-s\"\n",
    "    \n",
    "    try:\n",
    "        # Load tokenizer and processor\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NANONETS_MODEL, trust_remote_code=True)\n",
    "        processor = AutoProcessor.from_pretrained(NANONETS_MODEL, trust_remote_code=True)\n",
    "        \n",
    "        # Load model\n",
    "        model = AutoModelForImageTextToText.from_pretrained(\n",
    "            NANONETS_MODEL,\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None\n",
    "        )\n",
    "        \n",
    "        # Create engine class\n",
    "        class SimpleOCREngine:\n",
    "            def __init__(self, model, processor, tokenizer):\n",
    "                self.model = model\n",
    "                self.processor = processor\n",
    "                self.tokenizer = tokenizer\n",
    "        \n",
    "        ocr_engine = SimpleOCREngine(model, processor, tokenizer)\n",
    "        \n",
    "        print(\"‚úÖ Nanonets OCR Engine initialized successfully!\")\n",
    "        print(f\"ü§ñ Model: {NANONETS_MODEL}\")\n",
    "        print(f\"üñ•Ô∏è Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize OCR engine: {e}\")\n",
    "        ocr_engine = None\n",
    "else:\n",
    "    print(\"‚úÖ OCR Engine already loaded and ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "class OptimizedNanonetsProcessor:\n",
    "    \"\"\"\n",
    "    Optimized Nanonets OCR processor for all cropped images with clean output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ocr_engine):\n",
    "        self.ocr_engine = ocr_engine\n",
    "        self.processed_count = 0\n",
    "        self.success_count = 0\n",
    "        self.error_count = 0\n",
    "        self.total_confidence = 0.0\n",
    "        \n",
    "    def create_clean_prompt(self, element_type: str) -> str:\n",
    "        \"\"\"Create optimized prompts for clean text extraction only\"\"\"\n",
    "        \n",
    "        # Base prompt for clean extraction\n",
    "        base_prompt = (\n",
    "            \"Extract ONLY the text content from this image. \"\n",
    "            \"Do not add any explanations, metadata, or extra information. \"\n",
    "            \"Return only the actual text that appears in the image. \"\n",
    "        )\n",
    "        \n",
    "        # Element-specific optimization\n",
    "        element_prompts = {\n",
    "            \"table\": (\n",
    "                \"Extract the table data and format it as a clean HTML table. \"\n",
    "                \"Include only the actual cell content without any styling or extra markup. \"\n",
    "                \"Use simple <table>, <tr>, <td>, <th> tags only.\"\n",
    "            ),\n",
    "            \"title\": (\n",
    "                \"Extract only the title text. Return just the heading text without any formatting markers.\"\n",
    "            ),\n",
    "            \"section_header\": (\n",
    "                \"Extract only the header text. Return just the heading content without any formatting.\"\n",
    "            ),\n",
    "            \"text\": (\n",
    "                \"Extract only the text content. Preserve line breaks where they naturally occur. \"\n",
    "                \"Do not add any formatting or markup.\"\n",
    "            ),\n",
    "            \"paragraph\": (\n",
    "                \"Extract only the paragraph text. Maintain natural paragraph structure.\"\n",
    "            ),\n",
    "            \"key_value_region\": (\n",
    "                \"Extract the key-value pairs as simple text. Format as 'Key: Value' on separate lines.\"\n",
    "            ),\n",
    "            \"list\": (\n",
    "                \"Extract the list items. Use simple bullet points (-) or numbers (1., 2., etc.) as they appear.\"\n",
    "            ),\n",
    "            \"page_header\": (\n",
    "                \"Extract only the header text that appears at the top of the page.\"\n",
    "            ),\n",
    "            \"page_footer\": (\n",
    "                \"Extract only the footer text that appears at the bottom of the page.\"\n",
    "            ),\n",
    "            \"picture\": (\n",
    "                \"If there is any text visible in this image, extract it. \"\n",
    "                \"If no text is visible, return: [Image: brief description]\"\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Add element-specific prompt\n",
    "        if element_type in element_prompts:\n",
    "            return base_prompt + element_prompts[element_type]\n",
    "        \n",
    "        return base_prompt + \"Return only the visible text content.\"\n",
    "    \n",
    "    def preprocess_image(self, image_path: Path) -> Optional[Image.Image]:\n",
    "        \"\"\"Preprocess image to ensure compatibility with Nanonets\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            width, height = image.size\n",
    "            \n",
    "            # Minimum dimensions for Nanonets model\n",
    "            MIN_DIMENSION = 32\n",
    "            \n",
    "            # Resize small images\n",
    "            if width < MIN_DIMENSION or height < MIN_DIMENSION:\n",
    "                scale_factor = max(MIN_DIMENSION / width, MIN_DIMENSION / height)\n",
    "                new_width = max(MIN_DIMENSION, int(width * scale_factor))\n",
    "                new_height = max(MIN_DIMENSION, int(height * scale_factor))\n",
    "                \n",
    "                print(f\"    üìè Resizing from {width}x{height} to {new_width}x{new_height}\")\n",
    "                image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Ensure reasonable maximum size to avoid memory issues\n",
    "            MAX_DIMENSION = 2048\n",
    "            if width > MAX_DIMENSION or height > MAX_DIMENSION:\n",
    "                scale_factor = min(MAX_DIMENSION / width, MAX_DIMENSION / height)\n",
    "                new_width = int(width * scale_factor)\n",
    "                new_height = int(height * scale_factor)\n",
    "                \n",
    "                print(f\"    üìê Downscaling from {width}x{height} to {new_width}x{new_height}\")\n",
    "                image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            return image\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ùå Image preprocessing failed: {str(e)[:50]}...\")\n",
    "            return None\n",
    "    \n",
    "    def extract_clean_text(self, image_path: Path, element_type: str) -> Tuple[str, float]:\n",
    "        \"\"\"Extract clean text with optimized prompts\"\"\"\n",
    "        try:\n",
    "            # Preprocess image\n",
    "            image = self.preprocess_image(image_path)\n",
    "            if image is None:\n",
    "                return \"\", 0.0\n",
    "            \n",
    "            # Create optimized prompt\n",
    "            prompt = self.create_clean_prompt(element_type)\n",
    "            \n",
    "            # Prepare messages\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"You are a precise text extraction assistant. Extract only the visible text content without any additional commentary or formatting.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \"image\": f\"file://{image_path}\"},\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                    ]\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "            # Apply chat template\n",
    "            try:\n",
    "                text = self.ocr_engine.processor.apply_chat_template(\n",
    "                    messages, tokenize=False, add_generation_prompt=True\n",
    "                )\n",
    "            except AttributeError:\n",
    "                text = self.ocr_engine.tokenizer.apply_chat_template(\n",
    "                    messages, tokenize=False, add_generation_prompt=True\n",
    "                )\n",
    "            \n",
    "            # Process inputs\n",
    "            inputs = self.ocr_engine.processor(\n",
    "                text=[text], images=[image], padding=True, return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Move to GPU if available\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = {k: v.cuda(0) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "            \n",
    "            # Generate text with optimized parameters\n",
    "            with torch.inference_mode():\n",
    "                output = self.ocr_engine.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=1024,  # Reasonable limit for clean extraction\n",
    "                    do_sample=False,      # Deterministic output\n",
    "                    num_beams=1,          # Fast greedy decoding\n",
    "                    temperature=0.1,      # Low temperature for consistency\n",
    "                    repetition_penalty=1.05,\n",
    "                    length_penalty=1.0,\n",
    "                    early_stopping=True,\n",
    "                    pad_token_id=self.ocr_engine.model.generation_config.pad_token_id,\n",
    "                )\n",
    "            \n",
    "            # Extract generated text\n",
    "            generated_ids = [o[i.shape[-1]:] for i, o in zip(inputs[\"input_ids\"], output)]\n",
    "            result = self.ocr_engine.processor.batch_decode(\n",
    "                generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "            )[0]\n",
    "            \n",
    "            # Clean up result\n",
    "            result = result.strip()\n",
    "            \n",
    "            # Calculate confidence based on result quality\n",
    "            confidence = self.calculate_confidence(result, image.size)\n",
    "            \n",
    "            # Cleanup memory\n",
    "            del image, inputs, output\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "            return result, confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ùå OCR failed: {str(e)[:50]}...\")\n",
    "            return \"\", 0.0\n",
    "    \n",
    "    def calculate_confidence(self, text: str, image_size: Tuple[int, int]) -> float:\n",
    "        \"\"\"Calculate confidence score based on extraction quality\"\"\"\n",
    "        if not text or len(text.strip()) < 2:\n",
    "            return 0.0\n",
    "        \n",
    "        confidence = 1.0\n",
    "        \n",
    "        # Reduce confidence for very short text\n",
    "        if len(text) < 5:\n",
    "            confidence *= 0.6\n",
    "        \n",
    "        # Reduce confidence for special error indicators\n",
    "        if any(indicator in text.lower() for indicator in ['failed', 'error', 'unable', 'cannot']):\n",
    "            confidence *= 0.2\n",
    "        \n",
    "        # Reduce confidence for garbled text (too many special characters)\n",
    "        special_char_ratio = sum(1 for c in text if not c.isalnum() and c not in ' .,!?-:;()[]{}') / len(text)\n",
    "        if special_char_ratio > 0.3:\n",
    "            confidence *= 0.5\n",
    "        \n",
    "        # Boost confidence for structured content\n",
    "        if any(tag in text for tag in ['<table>', '<tr>', '<td>']):\n",
    "            confidence *= 1.1\n",
    "        \n",
    "        # Consider image size (very small images are less reliable)\n",
    "        width, height = image_size\n",
    "        if width < 50 or height < 20:\n",
    "            confidence *= 0.7\n",
    "        \n",
    "        return min(1.0, max(0.0, confidence))\n",
    "    \n",
    "    def process_single_image(self, image_path: Path, element_info: Dict) -> Dict:\n",
    "        \"\"\"Process a single cropped image\"\"\"\n",
    "        element_type = element_info.get('type', 'text')\n",
    "        element_id = element_info.get('id', 'unknown')\n",
    "        \n",
    "        print(f\"    üîç Processing {element_type} (ID: {element_id})\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        extracted_text, confidence = self.extract_clean_text(image_path, element_type)\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        # Update statistics\n",
    "        self.processed_count += 1\n",
    "        if confidence > 0.1:  # Consider as success if confidence > 0.1\n",
    "            self.success_count += 1\n",
    "            self.total_confidence += confidence\n",
    "        else:\n",
    "            self.error_count += 1\n",
    "        \n",
    "        result = {\n",
    "            'id': element_id,\n",
    "            'type': element_type,\n",
    "            'image_path': str(image_path),\n",
    "            'extracted_text': extracted_text,\n",
    "            'confidence': confidence,\n",
    "            'processing_time': processing_time,\n",
    "            'success': confidence > 0.1\n",
    "        }\n",
    "        \n",
    "        # Add original element info\n",
    "        result.update(element_info)\n",
    "        \n",
    "        if extracted_text and confidence > 0.1:\n",
    "            print(f\"    ‚úÖ Success: {len(extracted_text)} chars, confidence: {confidence:.2f}\")\n",
    "        else:\n",
    "            print(f\"    ‚ùå Failed: No text extracted\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize the optimized processor\n",
    "if 'ocr_engine' in globals() and ocr_engine:\n",
    "    optimized_processor = OptimizedNanonetsProcessor(ocr_engine)\n",
    "    print(\"‚úÖ Optimized Nanonets processor initialized\")\n",
    "else:\n",
    "    print(\"‚ùå OCR engine not available. Please initialize the OCR engine first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e917c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_all_cropped_files():\n",
    "    \"\"\"\n",
    "    Iterate through all cropped files in layout_results and process with Nanonets OCR\n",
    "    \"\"\"\n",
    "    layout_results_path = Path(\"layout_results\")\n",
    "    \n",
    "    if not layout_results_path.exists():\n",
    "        print(\"‚ùå layout_results directory not found!\")\n",
    "        return\n",
    "    \n",
    "    # Find all document directories\n",
    "    doc_dirs = [d for d in layout_results_path.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not doc_dirs:\n",
    "        print(\"‚ùå No document directories found in layout_results\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üöÄ Found {len(doc_dirs)} document directories\")\n",
    "    print(f\"ü§ñ Using Nanonets OCR for clean text extraction\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    all_results = {}\n",
    "    overall_stats = {\n",
    "        'total_documents': len(doc_dirs),\n",
    "        'processed_documents': 0,\n",
    "        'total_images': 0,\n",
    "        'successful_extractions': 0,\n",
    "        'failed_extractions': 0,\n",
    "        'average_confidence': 0.0,\n",
    "        'processing_time': 0.0\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for doc_dir in doc_dirs:\n",
    "        doc_name = doc_dir.name\n",
    "        print(f\"\\\\nüìÑ Processing document: {doc_name}\")\n",
    "        \n",
    "        # Look for cropped_images directory\n",
    "        cropped_dir = doc_dir / \"cropped_images\"\n",
    "        if not cropped_dir.exists():\n",
    "            print(f\"  ‚ö†Ô∏è No cropped_images directory found in {doc_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Look for layout results JSON\n",
    "        layout_json_path = doc_dir / f\"{doc_name}_layout_results.json\"\n",
    "        element_info_map = {}\n",
    "        \n",
    "        if layout_json_path.exists():\n",
    "            try:\n",
    "                with open(layout_json_path, 'r', encoding='utf-8') as f:\n",
    "                    layout_data = json.load(f)\n",
    "                    \n",
    "                # Create mapping of image names to element info\n",
    "                for page_data in layout_data.get('pages', []):\n",
    "                    for element in page_data.get('elements', []):\n",
    "                        if 'image_path' in element:\n",
    "                            image_name = Path(element['image_path']).name\n",
    "                            element_info_map[image_name] = element\n",
    "                            \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è Could not read layout JSON: {e}\")\n",
    "        \n",
    "        # Get all image files in cropped_images\n",
    "        image_files = []\n",
    "        for ext in ['*.png', '*.jpg', '*.jpeg']:\n",
    "            image_files.extend(cropped_dir.glob(ext))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"  ‚ö†Ô∏è No image files found in {cropped_dir}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  üñºÔ∏è Found {len(image_files)} cropped images\")\n",
    "        \n",
    "        # Process each image\n",
    "        doc_results = []\n",
    "        doc_success_count = 0\n",
    "        doc_total_confidence = 0.0\n",
    "        \n",
    "        for image_path in sorted(image_files):\n",
    "            image_name = image_path.name\n",
    "            \n",
    "            # Get element info from layout results\n",
    "            element_info = element_info_map.get(image_name, {})\n",
    "            if not element_info:\n",
    "                # Try to extract info from filename\n",
    "                element_info = extract_info_from_filename(image_name)\n",
    "            \n",
    "            # Process the image\n",
    "            result = optimized_processor.process_single_image(image_path, element_info)\n",
    "            doc_results.append(result)\n",
    "            \n",
    "            overall_stats['total_images'] += 1\n",
    "            \n",
    "            if result['success']:\n",
    "                doc_success_count += 1\n",
    "                doc_total_confidence += result['confidence']\n",
    "                overall_stats['successful_extractions'] += 1\n",
    "            else:\n",
    "                overall_stats['failed_extractions'] += 1\n",
    "        \n",
    "        # Store document results\n",
    "        all_results[doc_name] = {\n",
    "            'images_processed': len(image_files),\n",
    "            'successful_extractions': doc_success_count,\n",
    "            'average_confidence': doc_total_confidence / doc_success_count if doc_success_count > 0 else 0.0,\n",
    "            'results': doc_results\n",
    "        }\n",
    "        \n",
    "        overall_stats['processed_documents'] += 1\n",
    "        \n",
    "        print(f\"  üìä Document summary:\")\n",
    "        print(f\"    üñºÔ∏è Images processed: {len(image_files)}\")\n",
    "        print(f\"    ‚úÖ Successful: {doc_success_count}\")\n",
    "        print(f\"    ‚ùå Failed: {len(image_files) - doc_success_count}\")\n",
    "        print(f\"    üéØ Avg confidence: {doc_total_confidence / doc_success_count if doc_success_count > 0 else 0:.3f}\")\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    total_time = time.time() - start_time\n",
    "    overall_stats['processing_time'] = total_time\n",
    "    overall_stats['average_confidence'] = (\n",
    "        optimized_processor.total_confidence / optimized_processor.success_count \n",
    "        if optimized_processor.success_count > 0 else 0.0\n",
    "    )\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\" * 80)\n",
    "    print(\"üéâ PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üìä Overall Statistics:\")\n",
    "    print(f\"  üìÅ Documents processed: {overall_stats['processed_documents']}/{overall_stats['total_documents']}\")\n",
    "    print(f\"  üñºÔ∏è Total images: {overall_stats['total_images']}\")\n",
    "    print(f\"  ‚úÖ Successful extractions: {overall_stats['successful_extractions']}\")\n",
    "    print(f\"  ‚ùå Failed extractions: {overall_stats['failed_extractions']}\")\n",
    "    print(f\"  üéØ Overall success rate: {(overall_stats['successful_extractions']/overall_stats['total_images']*100):.1f}%\")\n",
    "    print(f\"  üéØ Average confidence: {overall_stats['average_confidence']:.3f}\")\n",
    "    print(f\"  ‚è±Ô∏è Total processing time: {total_time:.2f}s ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"  üöÄ Processing speed: {overall_stats['total_images']/total_time:.2f} images/second\")\n",
    "    \n",
    "    return all_results, overall_stats\n",
    "\n",
    "def extract_info_from_filename(filename: str) -> Dict:\n",
    "    \"\"\"Extract element information from filename pattern\"\"\"\n",
    "    # Pattern: p001_elem000_type_id.png\n",
    "    parts = filename.replace('.png', '').replace('.jpg', '').replace('.jpeg', '').split('_')\n",
    "    \n",
    "    info = {\n",
    "        'id': 'unknown',\n",
    "        'type': 'text',\n",
    "        'page': 1\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if len(parts) >= 3:\n",
    "            # Extract page number\n",
    "            if parts[0].startswith('p'):\n",
    "                info['page'] = int(parts[0][1:])\n",
    "            \n",
    "            # Extract element ID\n",
    "            if parts[1].startswith('elem'):\n",
    "                info['id'] = parts[1]\n",
    "            \n",
    "            # Extract element type\n",
    "            if len(parts) >= 4:\n",
    "                info['type'] = parts[2]\n",
    "            elif len(parts) == 3:\n",
    "                info['type'] = parts[2]\n",
    "                \n",
    "    except (ValueError, IndexError):\n",
    "        pass  # Use defaults\n",
    "    \n",
    "    return info\n",
    "\n",
    "def generate_clean_markdown_from_results(results: Dict, doc_name: str) -> str:\n",
    "    \"\"\"Generate clean markdown containing only extracted text data\"\"\"\n",
    "    \n",
    "    lines = [f\"# {doc_name}\\\\n\"]\n",
    "    \n",
    "    # Group results by page and sort by element order\n",
    "    pages = defaultdict(list)\n",
    "    \n",
    "    for result in results['results']:\n",
    "        if result['success'] and result['extracted_text'].strip():\n",
    "            page_num = result.get('page', 1)\n",
    "            pages[page_num].append(result)\n",
    "    \n",
    "    # Sort pages\n",
    "    for page_num in sorted(pages.keys()):\n",
    "        if len(pages) > 1:  # Only add page headers if multiple pages\n",
    "            lines.append(f\"\\\\n## Page {page_num}\\\\n\")\n",
    "        \n",
    "        # Sort elements by type priority and ID\n",
    "        type_priority = {\n",
    "            'title': 1,\n",
    "            'section_header': 2,\n",
    "            'paragraph': 3,\n",
    "            'text': 4,\n",
    "            'table': 5,\n",
    "            'list': 6,\n",
    "            'key_value_region': 7,\n",
    "            'page_header': 8,\n",
    "            'page_footer': 9,\n",
    "            'picture': 10\n",
    "        }\n",
    "        \n",
    "        page_elements = sorted(pages[page_num], \n",
    "                             key=lambda x: (type_priority.get(x['type'], 5), x.get('id', '')))\n",
    "        \n",
    "        for result in page_elements:\n",
    "            text = result['extracted_text'].strip()\n",
    "            element_type = result['type']\n",
    "            \n",
    "            if not text:\n",
    "                continue\n",
    "            \n",
    "            # Format based on element type\n",
    "            if element_type in ['title', 'section_header']:\n",
    "                # Determine heading level\n",
    "                if element_type == 'title':\n",
    "                    lines.append(f\"### {text}\\\\n\")\n",
    "                else:\n",
    "                    lines.append(f\"#### {text}\\\\n\")\n",
    "                    \n",
    "            elif element_type == 'table':\n",
    "                # Add table directly (should already be in HTML format)\n",
    "                if '<table>' in text:\n",
    "                    lines.append(f\"{text}\\\\n\")\n",
    "                else:\n",
    "                    # If not HTML, wrap in simple format\n",
    "                    lines.append(f\"**Table:**\\\\n{text}\\\\n\")\n",
    "                    \n",
    "            elif element_type == 'list':\n",
    "                # Ensure proper list formatting\n",
    "                lines.append(f\"{text}\\\\n\")\n",
    "                \n",
    "            elif element_type == 'key_value_region':\n",
    "                # Format key-value pairs\n",
    "                lines.append(f\"**{text}**\\\\n\")\n",
    "                \n",
    "            elif element_type in ['page_header', 'page_footer']:\n",
    "                # Format headers/footers distinctly\n",
    "                lines.append(f\"*{text}*\\\\n\")\n",
    "                \n",
    "            elif element_type == 'picture':\n",
    "                # Handle image descriptions\n",
    "                if text.startswith('[Image:'):\n",
    "                    lines.append(f\"{text}\\\\n\")\n",
    "                else:\n",
    "                    lines.append(f\"[Image: {text}]\\\\n\")\n",
    "            else:\n",
    "                # Regular text/paragraph\n",
    "                lines.append(f\"{text}\\\\n\")\n",
    "    \n",
    "    return \"\\\\n\".join(lines)\n",
    "\n",
    "def save_all_results(all_results: Dict, overall_stats: Dict):\n",
    "    \"\"\"Save all processing results to files\"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(\"nanonets_clean_results\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    saved_count = 0\n",
    "    \n",
    "    for doc_name, doc_results in all_results.items():\n",
    "        if doc_results['successful_extractions'] > 0:\n",
    "            \n",
    "            # Generate clean markdown\n",
    "            markdown_content = generate_clean_markdown_from_results(doc_results, doc_name)\n",
    "            \n",
    "            # Save markdown file\n",
    "            markdown_path = output_dir / f\"{doc_name}_clean.md\"\n",
    "            try:\n",
    "                with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(markdown_content)\n",
    "                print(f\"  ‚úÖ Saved: {markdown_path}\")\n",
    "                saved_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Failed to save {markdown_path}: {e}\")\n",
    "            \n",
    "            # Save detailed JSON\n",
    "            json_path = output_dir / f\"{doc_name}_results.json\"\n",
    "            try:\n",
    "                with open(json_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump({\n",
    "                        'document_name': doc_name,\n",
    "                        'processing_timestamp': time.time(),\n",
    "                        'summary': {\n",
    "                            'images_processed': doc_results['images_processed'],\n",
    "                            'successful_extractions': doc_results['successful_extractions'],\n",
    "                            'average_confidence': doc_results['average_confidence']\n",
    "                        },\n",
    "                        'detailed_results': doc_results['results']\n",
    "                    }, f, indent=2, ensure_ascii=False)\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è Could not save JSON for {doc_name}: {e}\")\n",
    "    \n",
    "    # Save overall statistics\n",
    "    stats_path = output_dir / \"processing_statistics.json\"\n",
    "    try:\n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(overall_stats, f, indent=2)\n",
    "        print(f\"  üìä Saved overall statistics: {stats_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Could not save statistics: {e}\")\n",
    "    \n",
    "    print(f\"\\\\nüíæ Total files saved: {saved_count} markdown files\")\n",
    "    print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "print(\"‚úÖ Complete cropped files processing functions defined\")\n",
    "print(\"üéØ Features: Clean text extraction, optimized prompts, structured output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59988738",
   "metadata": {},
   "source": [
    "### Execute Complete Processing\n",
    "\n",
    "Run the complete processing pipeline for all cropped images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the complete processing pipeline\n",
    "print(\"üöÄ Starting Complete Cropped Files OCR Processing\")\n",
    "print(\"=\" * 80)\n",
    "print(\"üéØ Features:\")\n",
    "print(\"  ‚Ä¢ Clean text extraction only\")\n",
    "print(\"  ‚Ä¢ Optimized prompts for each element type\")\n",
    "print(\"  ‚Ä¢ Automatic image resizing for compatibility\")\n",
    "print(\"  ‚Ä¢ Structured markdown output\")\n",
    "print(\"  ‚Ä¢ No extra commentary or metadata in output\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if OCR engine is available\n",
    "if 'optimized_processor' not in globals():\n",
    "    print(\"‚ùå Optimized processor not initialized!\")\n",
    "    print(\"Please run the previous cells first to set up the processor.\")\n",
    "else:\n",
    "    # Run the complete processing\n",
    "    try:\n",
    "        results, stats = iterate_all_cropped_files()\n",
    "        \n",
    "        if results:\n",
    "            print(\"\\\\nüíæ Saving results...\")\n",
    "            save_all_results(results, stats)\n",
    "            \n",
    "            print(\"\\\\nüéâ PROCESSING COMPLETE!\")\n",
    "            print(\"‚úÖ All cropped images have been processed with Nanonets OCR\")\n",
    "            print(\"‚úÖ Clean markdown files generated with extracted text only\")\n",
    "            print(\"‚úÖ Results saved to 'nanonets_clean_results' directory\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå No results generated\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during processing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
