{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c8ccf4",
   "metadata": {},
   "source": [
    "# PaddleOCR Pipeline with Intelligent Column Detection\n",
    "\n",
    "This notebook creates an advanced OCR pipeline using **PaddleOCR** that:\n",
    "- ‚úÖ Automatically detects number of columns (1, 2, 3, or more)\n",
    "- ‚úÖ Uses layout_data.json for proper reading order\n",
    "- ‚úÖ Maintains left-to-right, top-to-bottom reading order\n",
    "- ‚úÖ Generates clean markdown with intelligent column formatting\n",
    "- ‚úÖ Higher accuracy than Tesseract\n",
    "- ‚úÖ Handles multi-page documents\n",
    "- ‚úÖ Preserves document structure automatically\n",
    "\n",
    "**Column Detection Strategy:**\n",
    "- Analyzes horizontal positions of elements\n",
    "- Uses clustering to identify column boundaries\n",
    "- Detects full-width elements (headers, tables)\n",
    "- Groups related content by columns\n",
    "\n",
    "**Prerequisites:**\n",
    "- PaddleOCR installed\n",
    "- Cropped sections from layout detection\n",
    "- layout_data.json with bounding boxes and reading order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01821405",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7499b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PaddleOCR and PIL imported successfully\n",
      "‚úì All libraries imported\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# OCR and Image processing\n",
    "try:\n",
    "    from paddleocr import PaddleOCR\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    print(\"‚úì PaddleOCR and PIL imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Please install: pip install paddleocr paddlepaddle\")\n",
    "    raise\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úì All libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73fd3d6",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86e4985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  input_dir: output_results\n",
      "  output_dir: paddle_markdown_output\n",
      "  use_gpu: False\n",
      "  lang: en\n",
      "  use_angle_cls: True\n",
      "  show_log: False\n",
      "  column_gap_threshold: 0.15\n",
      "  full_width_threshold: 0.7\n",
      "  vertical_pairing_threshold: 100\n",
      "  use_layout_reading_order: True\n",
      "  sort_by_position: top_left\n",
      "  confidence_threshold: 0.0\n",
      "  add_spacing_between_elements: True\n",
      "  format_tables: True\n",
      "  include_confidence_comments: False\n",
      "  show_column_info: True\n",
      "  separate_pages: True\n",
      "  page_separator: \n",
      "---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'input_dir': 'output_results',\n",
    "    'output_dir': 'paddle_markdown_output',\n",
    "    \n",
    "    # PaddleOCR settings\n",
    "    'use_gpu': False,\n",
    "    'lang': 'en',\n",
    "    'use_angle_cls': True,\n",
    "    'show_log': False,\n",
    "    \n",
    "    # Column detection settings\n",
    "    'column_gap_threshold': 0.15,  # 15% of page width for column gaps\n",
    "    'full_width_threshold': 0.7,   # Elements wider than 70% are full-width\n",
    "    'vertical_pairing_threshold': 100,  # Pixels for vertical alignment\n",
    "    \n",
    "    # Reading order strategy\n",
    "    'use_layout_reading_order': True,\n",
    "    'sort_by_position': 'top_left',\n",
    "    \n",
    "    # Output settings\n",
    "    'confidence_threshold': 0.0,\n",
    "    'add_spacing_between_elements': True,\n",
    "    'format_tables': True,\n",
    "    'include_confidence_comments': False,\n",
    "    'show_column_info': True,  # Show column detection info in markdown\n",
    "    \n",
    "    # Document structure\n",
    "    'separate_pages': True,\n",
    "    'page_separator': '\\n---\\n\\n',\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0145bc",
   "metadata": {},
   "source": [
    "## 3. Initialize PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c182be55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PaddleOCR...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/abhishek-mishra/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/abhishek-mishra/.paddlex/official_models/UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/abhishek-mishra/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/abhishek-mishra/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/abhishek-mishra/.paddlex/official_models/en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PaddleOCR initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize PaddleOCR\n",
    "print(\"Initializing PaddleOCR...\\n\")\n",
    "\n",
    "try:\n",
    "    ocr = PaddleOCR(\n",
    "        use_angle_cls=CONFIG['use_angle_cls'],\n",
    "        lang=CONFIG['lang'],\n",
    "    )\n",
    "    print(\"‚úì PaddleOCR initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing PaddleOCR: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c97f6a",
   "metadata": {},
   "source": [
    "## 4. Helper Functions - File Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac35f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì File parsing functions defined\n"
     ]
    }
   ],
   "source": [
    "def parse_crop_filename(filename: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse crop filename to extract metadata.\n",
    "    Format: page_001_order_001_type_id_27.png\n",
    "    \"\"\"\n",
    "    parts = filename.replace('.png', '').split('_')\n",
    "    \n",
    "    metadata = {\n",
    "        'filename': filename,\n",
    "        'page': None,\n",
    "        'order': None,\n",
    "        'element_type': None,\n",
    "        'element_id': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if 'page' in parts:\n",
    "            page_idx = parts.index('page')\n",
    "            if page_idx + 1 < len(parts):\n",
    "                metadata['page'] = int(parts[page_idx + 1])\n",
    "        \n",
    "        if 'order' in parts:\n",
    "            order_idx = parts.index('order')\n",
    "            if order_idx + 1 < len(parts):\n",
    "                metadata['order'] = int(parts[order_idx + 1])\n",
    "        \n",
    "        if 'id' in parts:\n",
    "            id_idx = parts.index('id')\n",
    "            if id_idx + 1 < len(parts):\n",
    "                metadata['element_id'] = int(parts[id_idx + 1])\n",
    "        \n",
    "        if 'order' in parts and 'id' in parts:\n",
    "            order_idx = parts.index('order')\n",
    "            id_idx = parts.index('id')\n",
    "            if order_idx + 2 < id_idx:\n",
    "                metadata['element_type'] = '_'.join(parts[order_idx + 2:id_idx])\n",
    "    \n",
    "    except (ValueError, IndexError) as e:\n",
    "        logger.warning(f\"Error parsing filename {filename}: {e}\")\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "\n",
    "def load_layout_data(document_dir: Path) -> Optional[Dict]:\n",
    "    \"\"\"Load layout_data.json for a document.\"\"\"\n",
    "    layout_file = document_dir / \"layout_data.json\"\n",
    "    \n",
    "    if not layout_file.exists():\n",
    "        logger.warning(f\"No layout_data.json found in {document_dir}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(layout_file, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading layout data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"‚úì File parsing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b61f63",
   "metadata": {},
   "source": [
    "## 5. OCR Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3581565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PaddleOCR functions defined\n"
     ]
    }
   ],
   "source": [
    "def perform_paddle_ocr(image_path: Path, ocr_engine, config: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform OCR using PaddleOCR on a single image.\n",
    "    Returns text and confidence score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = ocr_engine.ocr(str(image_path))\n",
    "        \n",
    "        if not result or not result[0]:\n",
    "            return {\n",
    "                'success': True,\n",
    "                'text': '',\n",
    "                'confidence': 0.0,\n",
    "                'lines': []\n",
    "            }\n",
    "        \n",
    "        ocr_result = result[0]\n",
    "        rec_texts = ocr_result.get('rec_texts', [])\n",
    "        rec_scores = ocr_result.get('rec_scores', [])\n",
    "        \n",
    "        if not rec_texts:\n",
    "            return {\n",
    "                'success': True,\n",
    "                'text': '',\n",
    "                'confidence': 0.0,\n",
    "                'lines': []\n",
    "            }\n",
    "        \n",
    "        lines = []\n",
    "        confidences = []\n",
    "        \n",
    "        for text, score in zip(rec_texts, rec_scores):\n",
    "            if score >= config['confidence_threshold']:\n",
    "                lines.append(text)\n",
    "                confidences.append(score * 100)  # Convert to percentage\n",
    "        \n",
    "        full_text = ' '.join(lines)\n",
    "        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'text': full_text,\n",
    "            'confidence': avg_confidence,\n",
    "            'lines': lines\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"OCR error for {image_path.name}: {e}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'text': '',\n",
    "            'confidence': 0.0,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"‚úì PaddleOCR functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27264151",
   "metadata": {},
   "source": [
    "## 6. Reading Order & Layout Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656bd274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Reading order functions defined\n"
     ]
    }
   ],
   "source": [
    "def get_element_layout_info(element_id: int, layout_data: Dict, page_num: int) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Get layout information for a specific element from layout_data.json.\n",
    "    \"\"\"\n",
    "    if not layout_data or 'pages' not in layout_data:\n",
    "        return None\n",
    "    \n",
    "    page_idx = page_num - 1\n",
    "    if page_idx >= len(layout_data['pages']):\n",
    "        return None\n",
    "    \n",
    "    page = layout_data['pages'][page_idx]\n",
    "    \n",
    "    for elem in page.get('elements', []):\n",
    "        if elem.get('id') == element_id:\n",
    "            bbox = elem.get('bounding_box', {})\n",
    "            return {\n",
    "                'reading_order': elem.get('reading_order'),\n",
    "                'bbox': bbox,\n",
    "                'left': bbox.get('left', 0),\n",
    "                'top': bbox.get('top', 0),\n",
    "                'right': bbox.get('right', 0),\n",
    "                'bottom': bbox.get('bottom', 0),\n",
    "                'type': elem.get('type', 'unknown')\n",
    "            }\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def sort_elements_by_reading_order(elements: List[Dict], config: Dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Sort elements by reading order.\n",
    "    Priority: Page -> Reading order -> Top -> Left\n",
    "    \"\"\"\n",
    "    def sort_key(elem: Dict) -> Tuple:\n",
    "        page = elem.get('page', 0)\n",
    "        \n",
    "        if config['use_layout_reading_order'] and elem.get('layout_info'):\n",
    "            layout = elem['layout_info']\n",
    "            reading_order = layout.get('reading_order', 999)\n",
    "            return (page, reading_order, layout.get('top', 0), layout.get('left', 0))\n",
    "        else:\n",
    "            order = elem.get('order', 999)\n",
    "            return (page, order, 0, 0)\n",
    "    \n",
    "    return sorted(elements, key=sort_key)\n",
    "\n",
    "\n",
    "print(\"‚úì Reading order functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224cb11",
   "metadata": {},
   "source": [
    "## 7. Advanced Column Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a020ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Advanced column detection functions defined\n"
     ]
    }
   ],
   "source": [
    "def detect_document_columns(elements: List[Dict], page_num: int, config: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Automatically detect the number of columns in a document (1, 2, 3, or more).\n",
    "    Uses clustering on horizontal positions to identify columns.\n",
    "    \"\"\"\n",
    "    page_elements = [e for e in elements if e.get('page') == page_num]\n",
    "    \n",
    "    if not page_elements:\n",
    "        return {\n",
    "            'num_columns': 0,\n",
    "            'columns': [],\n",
    "            'top_elements': [],\n",
    "            'bottom_elements': [],\n",
    "            'column_boundaries': [],\n",
    "            'layout_type': 'empty'\n",
    "        }\n",
    "    \n",
    "    # Get page width\n",
    "    page_width = 1654.0\n",
    "    elements_with_layout = [e for e in page_elements if e.get('layout_info')]\n",
    "    \n",
    "    if elements_with_layout:\n",
    "        max_right = max([e['layout_info'].get('right', 0) for e in elements_with_layout])\n",
    "        if max_right > 0:\n",
    "            page_width = max_right\n",
    "    \n",
    "    # Collect center positions of all elements\n",
    "    element_centers = []\n",
    "    for elem in elements_with_layout:\n",
    "        layout = elem['layout_info']\n",
    "        left = layout.get('left', 0)\n",
    "        right = layout.get('right', 0)\n",
    "        width = right - left\n",
    "        center = left + (width / 2)\n",
    "        element_centers.append({\n",
    "            'element': elem,\n",
    "            'center': center,\n",
    "            'left': left,\n",
    "            'right': right,\n",
    "            'width': width,\n",
    "            'top': layout.get('top', 0),\n",
    "            'bottom': layout.get('bottom', 0)\n",
    "        })\n",
    "    \n",
    "    if not element_centers:\n",
    "        return {\n",
    "            'num_columns': 1,\n",
    "            'columns': [page_elements],\n",
    "            'top_elements': [],\n",
    "            'bottom_elements': [],\n",
    "            'column_boundaries': [0, page_width],\n",
    "            'layout_type': 'single_column'\n",
    "        }\n",
    "    \n",
    "    # Identify full-width elements\n",
    "    full_width_threshold = page_width * config['full_width_threshold']\n",
    "    full_width_elements = [ec for ec in element_centers if ec['width'] > full_width_threshold]\n",
    "    narrow_elements = [ec for ec in element_centers if ec['width'] <= full_width_threshold]\n",
    "    \n",
    "    if len(narrow_elements) < 2:\n",
    "        return {\n",
    "            'num_columns': 1,\n",
    "            'columns': [page_elements],\n",
    "            'top_elements': [],\n",
    "            'bottom_elements': [],\n",
    "            'column_boundaries': [0, page_width],\n",
    "            'layout_type': 'single_column'\n",
    "        }\n",
    "    \n",
    "    # Find gaps in horizontal distribution\n",
    "    sorted_centers = sorted([ec['center'] for ec in narrow_elements])\n",
    "    \n",
    "    gaps = []\n",
    "    for i in range(len(sorted_centers) - 1):\n",
    "        gap = sorted_centers[i + 1] - sorted_centers[i]\n",
    "        if gap > page_width * config['column_gap_threshold']:\n",
    "            gaps.append({\n",
    "                'position': (sorted_centers[i] + sorted_centers[i + 1]) / 2,\n",
    "                'size': gap\n",
    "            })\n",
    "    \n",
    "    # Determine number of columns\n",
    "    num_columns = len(gaps) + 1\n",
    "    \n",
    "    # Calculate column boundaries\n",
    "    if num_columns == 1:\n",
    "        column_boundaries = [0, page_width]\n",
    "    else:\n",
    "        column_boundaries = [0] + [gap['position'] for gap in gaps] + [page_width]\n",
    "    \n",
    "    # Assign elements to columns\n",
    "    columns = [[] for _ in range(num_columns)]\n",
    "    \n",
    "    for ec in narrow_elements:\n",
    "        center = ec['center']\n",
    "        for i in range(num_columns):\n",
    "            left_boundary = column_boundaries[i]\n",
    "            right_boundary = column_boundaries[i + 1]\n",
    "            \n",
    "            if left_boundary <= center < right_boundary:\n",
    "                columns[i].append(ec['element'])\n",
    "                break\n",
    "    \n",
    "    # Sort elements within each column by vertical position\n",
    "    for i in range(num_columns):\n",
    "        columns[i] = sorted(columns[i], key=lambda x: (\n",
    "            x.get('layout_info', {}).get('top', 0),\n",
    "            x.get('order', 0)\n",
    "        ))\n",
    "    \n",
    "    # Detect vertical range of multi-column section\n",
    "    column_start = None\n",
    "    column_end = None\n",
    "    \n",
    "    if num_columns > 1 and narrow_elements:\n",
    "        # Find paired elements (elements at similar heights in different columns)\n",
    "        paired_tops = []\n",
    "        paired_bottoms = []\n",
    "        vertical_threshold = config['vertical_pairing_threshold']\n",
    "        \n",
    "        for i in range(num_columns - 1):\n",
    "            for elem1 in columns[i]:\n",
    "                top1 = elem1.get('layout_info', {}).get('top', 999)\n",
    "                bottom1 = elem1.get('layout_info', {}).get('bottom', 0)\n",
    "                \n",
    "                for elem2 in columns[i + 1]:\n",
    "                    top2 = elem2.get('layout_info', {}).get('top', 999)\n",
    "                    bottom2 = elem2.get('layout_info', {}).get('bottom', 0)\n",
    "                    \n",
    "                    if abs(top1 - top2) < vertical_threshold:\n",
    "                        paired_tops.append(min(top1, top2))\n",
    "                        paired_bottoms.append(max(bottom1, bottom2))\n",
    "        \n",
    "        if paired_tops and paired_bottoms:\n",
    "            column_start = min(paired_tops)\n",
    "            column_end = max(paired_bottoms)\n",
    "    \n",
    "    # Categorize full-width elements\n",
    "    top_elements = []\n",
    "    bottom_elements = []\n",
    "    \n",
    "    for ec in full_width_elements:\n",
    "        if column_start and ec['top'] < column_start - 50:\n",
    "            top_elements.append(ec['element'])\n",
    "        elif column_end and ec['top'] > column_end + 50:\n",
    "            bottom_elements.append(ec['element'])\n",
    "        else:\n",
    "            bottom_elements.append(ec['element'])\n",
    "    \n",
    "    # Sort top and bottom elements\n",
    "    top_elements.sort(key=lambda x: (\n",
    "        x.get('layout_info', {}).get('top', 0),\n",
    "        x.get('order', 0)\n",
    "    ))\n",
    "    bottom_elements.sort(key=lambda x: (\n",
    "        x.get('layout_info', {}).get('top', 0),\n",
    "        x.get('order', 0)\n",
    "    ))\n",
    "    \n",
    "    # Determine layout type\n",
    "    if num_columns == 1:\n",
    "        layout_type = 'single_column'\n",
    "    elif num_columns == 2:\n",
    "        layout_type = 'two_column'\n",
    "    elif num_columns == 3:\n",
    "        layout_type = 'three_column'\n",
    "    else:\n",
    "        layout_type = f'{num_columns}_column'\n",
    "    \n",
    "    return {\n",
    "        'num_columns': num_columns,\n",
    "        'columns': columns,\n",
    "        'top_elements': top_elements,\n",
    "        'bottom_elements': bottom_elements,\n",
    "        'column_boundaries': column_boundaries,\n",
    "        'layout_type': layout_type,\n",
    "        'page_width': page_width\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úì Advanced column detection functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8c75f",
   "metadata": {},
   "source": [
    "## 8. Markdown Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc771869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Markdown generation functions defined\n"
     ]
    }
   ],
   "source": [
    "def format_element_for_markdown(element: Dict, config: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Format an element for markdown output based on its type.\n",
    "    \"\"\"\n",
    "    text = element.get('text', '').strip()\n",
    "    if not text:\n",
    "        return ''\n",
    "    \n",
    "    element_type = element.get('element_type', 'text')\n",
    "    markdown_lines = []\n",
    "    \n",
    "    if config['include_confidence_comments'] and 'confidence' in element:\n",
    "        confidence = element['confidence']\n",
    "        markdown_lines.append(f\"<!-- OCR Confidence: {confidence:.1f}% -->\")\n",
    "    \n",
    "    if element_type == 'title':\n",
    "        markdown_lines.append(f\"# {text}\")\n",
    "    elif element_type == 'section_header':\n",
    "        markdown_lines.append(f\"## {text}\")\n",
    "    elif element_type == 'page_header':\n",
    "        markdown_lines.append(f\"*{text}*\")\n",
    "    elif element_type == 'page_footer':\n",
    "        markdown_lines.append(f\"*{text}*\")\n",
    "    elif element_type == 'table':\n",
    "        if config['format_tables']:\n",
    "            markdown_lines.append(\"```\")\n",
    "            markdown_lines.append(text)\n",
    "            markdown_lines.append(\"```\")\n",
    "        else:\n",
    "            markdown_lines.append(text)\n",
    "    elif element_type == 'key_value_region':\n",
    "        markdown_lines.append(f\"**{text}**\")\n",
    "    else:\n",
    "        markdown_lines.append(text)\n",
    "    \n",
    "    return '\\n'.join(markdown_lines)\n",
    "\n",
    "\n",
    "def generate_markdown_with_columns(elements: List[Dict], config: Dict, doc_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate markdown document with automatic column detection and formatting.\n",
    "    \"\"\"\n",
    "    markdown_parts = []\n",
    "    \n",
    "    # Add document title\n",
    "   \n",
    "    \n",
    "    # Group elements by page\n",
    "    pages = {}\n",
    "    for elem in elements:\n",
    "        page_num = elem.get('page', 1)\n",
    "        if page_num not in pages:\n",
    "            pages[page_num] = []\n",
    "        pages[page_num].append(elem)\n",
    "    \n",
    "    # Process each page\n",
    "    for page_num in sorted(pages.keys()):\n",
    "        if config['separate_pages']:\n",
    "            markdown_parts.append(f\"## Page {page_num}\\n\")\n",
    "        \n",
    "        # Detect columns\n",
    "        column_info = detect_document_columns(elements, page_num, config)\n",
    "        \n",
    "        # Add layout info comment\n",
    "        if config['show_column_info']:\n",
    "            markdown_parts.append(f\"<!-- Layout: {column_info['layout_type']} ({column_info['num_columns']} column(s)) -->\")\n",
    "            markdown_parts.append('')\n",
    "        \n",
    "        # Process top elements\n",
    "        for elem in column_info['top_elements']:\n",
    "            formatted = format_element_for_markdown(elem, config)\n",
    "            if formatted:\n",
    "                markdown_parts.append(formatted)\n",
    "                if config['add_spacing_between_elements']:\n",
    "                    markdown_parts.append('')\n",
    "        \n",
    "        # Process columns\n",
    "        if column_info['num_columns'] > 1:\n",
    "            markdown_parts.append(f'<div style=\"display: flex; gap: 20px;\">')\n",
    "            markdown_parts.append('')\n",
    "            \n",
    "            for col_idx, column in enumerate(column_info['columns']):\n",
    "                markdown_parts.append(f'<div style=\"flex: 1;\">  <!-- Column {col_idx + 1} -->')\n",
    "                markdown_parts.append('')\n",
    "                \n",
    "                for elem in column:\n",
    "                    formatted = format_element_for_markdown(elem, config)\n",
    "                    if formatted:\n",
    "                        markdown_parts.append(formatted)\n",
    "                        if config['add_spacing_between_elements']:\n",
    "                            markdown_parts.append('')\n",
    "                \n",
    "                markdown_parts.append('</div>')\n",
    "                markdown_parts.append('')\n",
    "            \n",
    "            markdown_parts.append('</div>')\n",
    "            markdown_parts.append('')\n",
    "        else:\n",
    "            for column in column_info['columns']:\n",
    "                for elem in column:\n",
    "                    formatted = format_element_for_markdown(elem, config)\n",
    "                    if formatted:\n",
    "                        markdown_parts.append(formatted)\n",
    "                        if config['add_spacing_between_elements']:\n",
    "                            markdown_parts.append('')\n",
    "        \n",
    "        # Process bottom elements\n",
    "        for elem in column_info['bottom_elements']:\n",
    "            formatted = format_element_for_markdown(elem, config)\n",
    "            if formatted:\n",
    "                markdown_parts.append(formatted)\n",
    "                if config['add_spacing_between_elements']:\n",
    "                    markdown_parts.append('')\n",
    "        \n",
    "        # Add page separator\n",
    "        if config['separate_pages'] and page_num < max(pages.keys()):\n",
    "            markdown_parts.append(config['page_separator'])\n",
    "    \n",
    "    return '\\n'.join(markdown_parts)\n",
    "\n",
    "\n",
    "print(\"‚úì Markdown generation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b237454f",
   "metadata": {},
   "source": [
    "## 9. Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed321e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Main processing function defined\n"
     ]
    }
   ],
   "source": [
    "def process_document_with_column_detection(document_dir: Path, ocr_engine, config: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process a single document with PaddleOCR and automatic column detection.\n",
    "    \"\"\"\n",
    "    doc_name = document_dir.name\n",
    "    logger.info(f\"Processing document: {doc_name}\")\n",
    "    \n",
    "    # Load layout data\n",
    "    layout_data = load_layout_data(document_dir)\n",
    "    \n",
    "    # Find cropped sections\n",
    "    crops_dir = document_dir / \"cropped_sections\"\n",
    "    if not crops_dir.exists():\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': f\"No cropped_sections directory found in {document_dir}\"\n",
    "        }\n",
    "    \n",
    "    crop_files = sorted([f for f in crops_dir.glob('*.png') if f.name.startswith('page_')])\n",
    "    \n",
    "    if not crop_files:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': f\"No crop files found in {crops_dir}\"\n",
    "        }\n",
    "    \n",
    "    # Process each crop\n",
    "    elements = []\n",
    "    \n",
    "    for crop_file in tqdm(crop_files, desc=f\"OCR {doc_name}\", leave=False):\n",
    "        metadata = parse_crop_filename(crop_file.name)\n",
    "        ocr_result = perform_paddle_ocr(crop_file, ocr_engine, config)\n",
    "        \n",
    "        if not ocr_result['success'] or not ocr_result['text'].strip():\n",
    "            continue\n",
    "        \n",
    "        # Get layout information\n",
    "        layout_info = None\n",
    "        if layout_data and metadata['page'] and metadata['element_id'] is not None:\n",
    "            layout_info = get_element_layout_info(\n",
    "                metadata['element_id'],\n",
    "                layout_data,\n",
    "                metadata['page']\n",
    "            )\n",
    "        \n",
    "        element = {\n",
    "            'page': metadata['page'],\n",
    "            'order': metadata['order'],\n",
    "            'element_type': metadata['element_type'],\n",
    "            'element_id': metadata['element_id'],\n",
    "            'text': ocr_result['text'],\n",
    "            'confidence': ocr_result['confidence'],\n",
    "            'layout_info': layout_info\n",
    "        }\n",
    "        \n",
    "        elements.append(element)\n",
    "    \n",
    "    # Sort elements by reading order\n",
    "    sorted_elements = sort_elements_by_reading_order(elements, config)\n",
    "    \n",
    "    # Detect columns for each page\n",
    "    pages = list(set([e.get('page', 1) for e in sorted_elements]))\n",
    "    column_info = {}\n",
    "    for page_num in pages:\n",
    "        col_info = detect_document_columns(sorted_elements, page_num, config)\n",
    "        column_info[page_num] = col_info\n",
    "        logger.info(f\"  Page {page_num}: {col_info['layout_type']} ({col_info['num_columns']} columns)\")\n",
    "    \n",
    "    # Generate markdown\n",
    "    markdown_content = generate_markdown_with_columns(sorted_elements, config, doc_name)\n",
    "    \n",
    "    # Calculate average confidence\n",
    "    confidences = [e['confidence'] for e in sorted_elements if e.get('confidence', 0) > 0]\n",
    "    avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0\n",
    "    \n",
    "    return {\n",
    "        'success': True,\n",
    "        'document_name': doc_name,\n",
    "        'total_elements': len(sorted_elements),\n",
    "        'markdown': markdown_content,\n",
    "        'elements': sorted_elements,\n",
    "        'column_info': column_info,\n",
    "        'avg_confidence': avg_confidence\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úì Main processing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a0d28",
   "metadata": {},
   "source": [
    "## 10. Test Single Document with Column Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94222360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PaddleOCR with Column Detection: batch1-0287\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Successfully processed: batch1-0287\n",
      "   Total elements: 13\n",
      "   Average OCR confidence: 99.1%\n",
      "\n",
      "üìä Column Detection Results:\n",
      "\n",
      "   Page 1:\n",
      "     - Layout Type: two_column\n",
      "     - Number of Columns: 2\n",
      "     - Page Width: 1520.1px\n",
      "     - Column Boundaries: ['0.0', '722.5', '1520.1']'\n",
      "     - Column 1: 7 elements\n",
      "     - Column 2: 4 elements\n",
      "     - Top Elements: 0\n",
      "     - Bottom Elements: 2\n",
      "\n",
      "‚úì Markdown saved to: paddle_markdown_output/batch1-0287.md\n",
      "\n",
      "üìÑ Markdown preview (first 600 chars):\n",
      "======================================================================\n",
      "## Page 1\n",
      "\n",
      "<!-- Layout: two_column (2 column(s)) -->\n",
      "\n",
      "<div style=\"display: flex; gap: 20px;\">\n",
      "\n",
      "<div style=\"flex: 1;\">  <!-- Column 1 -->\n",
      "\n",
      "**Invoice no: 51335214 Date of issue: 03/27/201**\n",
      "\n",
      "## Seller:\n",
      "\n",
      "Rivera Group 90443 lan Inlet Suite 58e Lake Abigail, WV 40743\n",
      "\n",
      "**Tax Id: 988-71-1654**\n",
      "\n",
      "BAN: GB10XNTM3891843789666\n",
      "\n",
      "## ITEMS\n",
      "\n",
      "## SUMMARY\n",
      "\n",
      "</div>\n",
      "\n",
      "<div style=\"flex: 1;\">  <!-- Column 2 -->\n",
      "\n",
      "## Client:\n",
      "\n",
      "Malone, Wilson and Carson 01909 Kyle Port South Joyce, VA 45070\n",
      "\n",
      "Tax Id: 928-86-3224\n",
      "\n",
      "**Tax Id: 928-86-322**\n",
      "\n",
      "</div>\n",
      "\n",
      "</div>\n",
      "\n",
      "```\n",
      "No. Description Qty UM Net price Net worth VAT [%] Gross worth 1. 2 \n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Test with automatic column detection\n",
    "input_dir = Path(CONFIG['input_dir'])\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "\n",
    "document_dirs = [d for d in input_dir.iterdir() if d.is_dir()]\n",
    "if document_dirs:\n",
    "    test_doc = document_dirs[0]\n",
    "    print(f\"Testing PaddleOCR with Column Detection: {test_doc.name}\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Process document\n",
    "    result = process_document_with_column_detection(test_doc, ocr, CONFIG)\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"\\n‚úÖ Successfully processed: {result['document_name']}\")\n",
    "        print(f\"   Total elements: {result['total_elements']}\")\n",
    "        print(f\"   Average OCR confidence: {result['avg_confidence']:.1f}%\")\n",
    "        \n",
    "        # Display column information\n",
    "        print(f\"\\nüìä Column Detection Results:\")\n",
    "        for page_num, col_info in result['column_info'].items():\n",
    "            print(f\"\\n   Page {page_num}:\")\n",
    "            print(f\"     - Layout Type: {col_info['layout_type']}\")\n",
    "            print(f\"     - Number of Columns: {col_info['num_columns']}\")\n",
    "            print(f\"     - Page Width: {col_info.get('page_width', 0):.1f}px\")\n",
    "            if col_info['num_columns'] > 1:\n",
    "                print(f\"     - Column Boundaries: {[f'{b:.1f}' for b in col_info['column_boundaries']]}'\")\n",
    "                for i, col in enumerate(col_info['columns']):\n",
    "                    print(f\"     - Column {i+1}: {len(col)} elements\")\n",
    "            print(f\"     - Top Elements: {len(col_info['top_elements'])}\")\n",
    "            print(f\"     - Bottom Elements: {len(col_info['bottom_elements'])}\")\n",
    "        \n",
    "        # Save markdown\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_file = output_dir / f\"{result['document_name']}.md\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(result['markdown'])\n",
    "        \n",
    "        print(f\"\\n‚úì Markdown saved to: {output_file}\")\n",
    "        print(f\"\\nüìÑ Markdown preview (first 600 chars):\")\n",
    "        print(\"=\"*70)\n",
    "        print(result['markdown'][:600])\n",
    "        if len(result['markdown']) > 600:\n",
    "            print(\"...\")\n",
    "    else:\n",
    "        print(f\"‚úó Error: {result.get('error')}\")\n",
    "else:\n",
    "    print(\"No documents found for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012e04e",
   "metadata": {},
   "source": [
    "## 11. Batch Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c889eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Batch processing function defined\n"
     ]
    }
   ],
   "source": [
    "def batch_process_documents(input_dir: Path, output_dir: Path, ocr_engine, config: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process all documents in the input directory.\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    document_dirs = [d for d in input_dir.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not document_dirs:\n",
    "        logger.warning(f\"No document directories found in {input_dir}\")\n",
    "        return {'success': False, 'error': 'No documents found'}\n",
    "    \n",
    "    logger.info(f\"Found {len(document_dirs)} documents to process\")\n",
    "    \n",
    "    results = {\n",
    "        'total_documents': len(document_dirs),\n",
    "        'successful': 0,\n",
    "        'failed': 0,\n",
    "        'details': [],\n",
    "        'total_columns_detected': {}\n",
    "    }\n",
    "    \n",
    "    for doc_dir in tqdm(document_dirs, desc=\"Processing documents\"):\n",
    "        try:\n",
    "            result = process_document_with_column_detection(doc_dir, ocr_engine, config)\n",
    "            \n",
    "            if result['success']:\n",
    "                # Save markdown\n",
    "                output_file = output_dir / f\"{result['document_name']}.md\"\n",
    "                with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                    f.write(result['markdown'])\n",
    "                \n",
    "                results['successful'] += 1\n",
    "                \n",
    "                # Track column statistics\n",
    "                for page_num, col_info in result['column_info'].items():\n",
    "                    layout_type = col_info['layout_type']\n",
    "                    results['total_columns_detected'][layout_type] = \\\n",
    "                        results['total_columns_detected'].get(layout_type, 0) + 1\n",
    "                \n",
    "                results['details'].append({\n",
    "                    'document': result['document_name'],\n",
    "                    'status': 'success',\n",
    "                    'elements': result['total_elements'],\n",
    "                    'confidence': result['avg_confidence'],\n",
    "                    'output_file': str(output_file)\n",
    "                })\n",
    "                \n",
    "                logger.info(f\"‚úì {result['document_name']}: {result['total_elements']} elements, \"\n",
    "                          f\"{result['avg_confidence']:.1f}% confidence\")\n",
    "            else:\n",
    "                results['failed'] += 1\n",
    "                results['details'].append({\n",
    "                    'document': doc_dir.name,\n",
    "                    'status': 'failed',\n",
    "                    'error': result.get('error', 'Unknown error')\n",
    "                })\n",
    "                logger.error(f\"‚úó {doc_dir.name}: {result.get('error')}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            results['failed'] += 1\n",
    "            results['details'].append({\n",
    "                'document': doc_dir.name,\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            })\n",
    "            logger.error(f\"‚úó {doc_dir.name}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úì Batch processing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389364ef",
   "metadata": {},
   "source": [
    "## 12. Batch Process All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c055c897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing with PaddleOCR...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61/61 [23:05<00:00, 22.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BATCH PROCESSING SUMMARY\n",
      "======================================================================\n",
      "Total documents: 61\n",
      "Successful: 61\n",
      "Failed: 0\n",
      "\n",
      "Output directory: paddle_markdown_output\n",
      "\n",
      "üìä Column Layout Statistics:\n",
      "  two_column: 49 pages\n",
      "  single_column: 7 pages\n",
      "  three_column: 7 pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all documents\n",
    "print(\"Starting batch processing with PaddleOCR...\\n\")\n",
    "\n",
    "input_dir = Path(CONFIG['input_dir'])\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "\n",
    "results = batch_process_documents(input_dir, output_dir, ocr, CONFIG)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BATCH PROCESSING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total documents: {results['total_documents']}\")\n",
    "print(f\"Successful: {results['successful']}\")\n",
    "print(f\"Failed: {results['failed']}\")\n",
    "print(f\"\\nOutput directory: {output_dir}\")\n",
    "\n",
    "if results.get('total_columns_detected'):\n",
    "    print(\"\\nüìä Column Layout Statistics:\")\n",
    "    for layout_type, count in results['total_columns_detected'].items():\n",
    "        print(f\"  {layout_type}: {count} pages\")\n",
    "\n",
    "if results['failed'] > 0:\n",
    "    print(\"\\n‚ùå Failed documents:\")\n",
    "    for detail in results['details']:\n",
    "        if detail['status'] == 'failed':\n",
    "            print(f\"  - {detail['document']}: {detail['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82927e",
   "metadata": {},
   "source": [
    "## 13. View Generated Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33b038ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing: 00921466.md\n",
      "\n",
      "======================================================================\n",
      "# 00921466\n",
      "\n",
      "*Generated with PaddleOCR - 2025-10-23 01:59:35*\n",
      "\n",
      "## Page 1\n",
      "\n",
      "<!-- Layout: three_column (3 column(s)) -->\n",
      "\n",
      "<div style=\"display: flex; gap: 20px;\">\n",
      "\n",
      "<div style=\"flex: 1;\">  <!-- Column 1 -->\n",
      "\n",
      "BORRISTON RESEARCH LABORATORIES, INC.\n",
      "\n",
      "August 20, 1981\n",
      "\n",
      "Greensboro, N.C. 27420 420 English St. LORILLARD, INC.\n",
      "\n",
      "**Attention: Dr. Harry Minnemeyer Reference: Purchase Order # 312-A BRL Ref.: 2-22-222-J Invoice No.: 5-J**\n",
      "\n",
      "## DESCRIPTION\n",
      "\n",
      "For submission of Final Report \"Cardiovascular Testing of Compound A-11 in the Beagle Dog\" at $2,700.00 per compound.\n",
      "\n",
      "</div>\n",
      "\n",
      "<div style=\"flex: 1;\">  <!-- Column 2 -->\n",
      "\n",
      "## * * * *INVOICE* * * *\n",
      "\n",
      "**Remittance Address: ENVIRO CONTROL INC. 11140 Rockville Pike Rockville, Md. 20852 Attn: B. Belford, Accountin**\n",
      "\n",
      "* * * *INVOICE* * *\n",
      "\n",
      "*5050 Beech Place ‚Ä¢ Temple Hills, Maryland 20031 ‚Ä¢ 301899-353*\n",
      "\n",
      "</div>\n",
      "\n",
      "<div style=\"flex: 1;\">  <!-- Column 3 -->\n",
      "\n",
      "**AMOUNT $2,700.00**\n",
      "\n",
      "*00921466*\n",
      "\n",
      "</div>\n",
      "\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View a generated markdown file\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "markdown_files = list(output_dir.glob('*.md'))\n",
    "\n",
    "if markdown_files:\n",
    "    sample_file = markdown_files[0]\n",
    "    print(f\"Viewing: {sample_file.name}\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        print(content[:1500])\n",
    "        if len(content) > 1500:\n",
    "            print(\"\\n... (truncated)\")\n",
    "            print(f\"\\nTotal length: {len(content)} characters\")\n",
    "else:\n",
    "    print(\"No markdown files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d3b4a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### ‚úÖ Features Implemented:\n",
    "\n",
    "1. **PaddleOCR Integration**\n",
    "   - Higher accuracy than Tesseract (typically 98-100% confidence)\n",
    "   - Better multi-language support\n",
    "   - Robust text detection and recognition\n",
    "\n",
    "2. **Intelligent Column Detection**\n",
    "   - Automatically identifies 1, 2, 3, or more columns\n",
    "   - Uses clustering algorithm on horizontal positions\n",
    "   - Detects full-width elements (headers, tables, footers)\n",
    "   - Groups paired elements across columns\n",
    "\n",
    "3. **Layout-Aware Processing**\n",
    "   - Reads layout_data.json for structure\n",
    "   - Maintains proper reading order\n",
    "   - Preserves spatial relationships\n",
    "\n",
    "4. **Smart Markdown Generation**\n",
    "   - Multi-column formatting with HTML flexbox\n",
    "   - Proper grouping of related content\n",
    "   - Clean, readable output\n",
    "   - Column information in comments\n",
    "\n",
    "5. **Batch Processing**\n",
    "   - Process multiple documents\n",
    "   - Progress tracking\n",
    "   - Error handling\n",
    "   - Statistics reporting\n",
    "\n",
    "### üìä Processing Flow:\n",
    "```\n",
    "Input: Cropped images + layout_data.json\n",
    "  ‚Üì\n",
    "PaddleOCR ‚Üí Extract text with high confidence\n",
    "  ‚Üì\n",
    "Layout Analysis ‚Üí Get reading order & bounding boxes\n",
    "  ‚Üì\n",
    "Column Detection ‚Üí Identify layout structure\n",
    "  ‚Üì\n",
    "Markdown Generation ‚Üí Format with proper columns\n",
    "  ‚Üì\n",
    "Output: Structured markdown files\n",
    "```\n",
    "\n",
    "### üéØ Next Steps:\n",
    "1. Run cell 10 to test single document\n",
    "2. Run cell 12 to batch process all documents\n",
    "3. Run cell 13 to view generated markdown\n",
    "4. Check output in `paddle_markdown_output/` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51dd1f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
