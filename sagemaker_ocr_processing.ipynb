{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1daf485",
   "metadata": {},
   "source": [
    "# üöÄ SageMaker OCR Processing Pipeline (g5.12xlarge Optimized)\n",
    "\n",
    "This notebook handles the **second part** of the document processing pipeline:\n",
    "\n",
    "1. **Load Pre-processed Data** from the Layout Detection notebook\n",
    "2. **Initialize Nanonets OCR** with SageMaker g5.12xlarge optimization (4x A10G GPUs)\n",
    "3. **Process Full Pages** and **Cropped Regions** with OCR\n",
    "4. **Generate Structured Output** in Markdown and JSON formats\n",
    "\n",
    "**Key Features:**\n",
    "- **SageMaker g5.12xlarge Optimized**: Multi-GPU distributed processing across 4x NVIDIA A10G (96GB total)\n",
    "- **High-Performance OCR**: Nanonets model with flash attention and memory optimization\n",
    "- **Robust Processing**: Automatic error recovery and memory management\n",
    "- **Flexible Token Limits**: Configurable based on quality vs speed requirements\n",
    "- **Comprehensive Output**: Both human-readable Markdown and structured JSON results\n",
    "\n",
    "**Hardware Targets:**\n",
    "- **4x NVIDIA A10G GPUs** (24GB each)\n",
    "- **96GB Total GPU Memory**\n",
    "- **Multi-GPU Model Distribution**\n",
    "- **3-4x Performance Improvement** over single GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59faf82b",
   "metadata": {},
   "source": [
    "## 1. Configuration & Input Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b0fed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ SageMaker g5.12xlarge OCR Pipeline Initialization\n",
      "üéØ Target: 4x NVIDIA A10G GPUs (24GB each = 96GB total)\n",
      "üîç Auto-detecting layout output directory...\n",
      "  üìÅ Found: layout_results/run_E-Invoice Format_1760952745\n",
      "  ‚úÖ All required files found - using auto-detected directory\n",
      "\n",
      "üìÇ Using Layout Output Directory: layout_results/run_E-Invoice Format_1760952745\n",
      "üéØ QUALITY MODE - Optimized for SageMaker g5.12xlarge (96GB GPU memory)\n",
      "üìä OCR Settings:\n",
      "  Token limits - Pages: 4096, Crops: 2048\n",
      "  Process full pages: ‚úÖ Yes\n",
      "  Process crops: ‚úÖ Yes\n",
      "\n",
      "üñ•Ô∏è GPU Configuration:\n",
      "  GPUs detected: 4/4 expected A10G GPUs\n",
      "  GPU 0: NVIDIA A10G (22.1GB total, 20.8GB free)\n",
      "  GPU 1: NVIDIA A10G (22.1GB total, 21.8GB free)\n",
      "  GPU 2: NVIDIA A10G (22.1GB total, 21.8GB free)\n",
      "  GPU 3: NVIDIA A10G (22.1GB total, 21.8GB free)\n",
      "‚úÖ Optimal SageMaker configuration detected!\n",
      "\n",
      "üìÅ Input Data Validation:\n",
      "  Layout output directory: layout_results/run_E-Invoice Format_1760952745\n",
      "  Directory exists: ‚úÖ Yes\n",
      "  Page images: ‚úÖ Found (1 files)\n",
      "  Layout data: ‚úÖ Found\n",
      "  Crop metadata: ‚úÖ Found\n",
      "  Crops directory: ‚úÖ Found\n",
      "\n",
      "üìÇ OCR Output Directory: layout_results/run_E-Invoice Format_1760952745/ocr_results\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"ocr_pipeline\")\n",
    "\n",
    "print(\"üöÄ SageMaker g5.12xlarge OCR Pipeline Initialization\")\n",
    "print(\"üéØ Target: 4x NVIDIA A10G GPUs (24GB each = 96GB total)\")\n",
    "\n",
    "# ‚ñ∂‚ñ∂ AUTO-DETECT OR MANUAL INPUT CONFIGURATION\n",
    "# ===========================================\n",
    "\n",
    "def find_latest_layout_output() -> Optional[Path]:\n",
    "    \"\"\"Automatically find the most recent layout output directory.\"\"\"\n",
    "    \n",
    "    # Look for layout_results directories in current folder\n",
    "    current_dir = Path(\".\")\n",
    "    layout_dirs = list(current_dir.glob(\"layout_results/run_*\"))\n",
    "    \n",
    "    if layout_dirs:\n",
    "        # Sort by directory name (which contains timestamp) and take the latest\n",
    "        latest_dir = sorted(layout_dirs, key=lambda x: x.name, reverse=True)[0]\n",
    "        return latest_dir\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def validate_layout_directory(layout_dir: Path) -> Dict[str, bool]:\n",
    "    \"\"\"Validate that a layout directory contains all required files.\"\"\"\n",
    "    \n",
    "    if not layout_dir.exists():\n",
    "        return {\"directory\": False, \"images\": False, \"layout\": False, \"crops\": False, \"metadata\": False}\n",
    "    \n",
    "    page_images_dir = layout_dir / \"page_images\"\n",
    "    layout_data_file = layout_dir / \"layout_analysis\" / \"layout_data.json\"\n",
    "    crops_metadata_file = layout_dir / \"cropped_regions\" / \"crop_metadata.json\"\n",
    "    crops_dir = layout_dir / \"cropped_regions\"\n",
    "    \n",
    "    return {\n",
    "        \"directory\": layout_dir.exists(),\n",
    "        \"images\": page_images_dir.exists() and len(list(page_images_dir.glob(\"*.png\"))) > 0,\n",
    "        \"layout\": layout_data_file.exists(),\n",
    "        \"metadata\": crops_metadata_file.exists(),\n",
    "        \"crops\": crops_dir.exists() and any(crops_dir.iterdir())\n",
    "    }\n",
    "\n",
    "# Try to auto-detect the latest layout output\n",
    "print(\"üîç Auto-detecting layout output directory...\")\n",
    "auto_detected_dir = find_latest_layout_output()\n",
    "\n",
    "if auto_detected_dir:\n",
    "    print(f\"  üìÅ Found: {auto_detected_dir}\")\n",
    "    validation = validate_layout_directory(auto_detected_dir)\n",
    "    \n",
    "    if all(validation.values()):\n",
    "        print(\"  ‚úÖ All required files found - using auto-detected directory\")\n",
    "        LAYOUT_OUTPUT_DIR = auto_detected_dir\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è Auto-detected directory is incomplete:\")\n",
    "        for check, status in validation.items():\n",
    "            print(f\"    {check}: {'‚úÖ' if status else '‚ùå'}\")\n",
    "        LAYOUT_OUTPUT_DIR = auto_detected_dir  # Use it anyway, user can see what's missing\n",
    "else:\n",
    "    print(\"  ‚ùå No layout_results directories found\")\n",
    "    print()\n",
    "    print(\"üîß MANUAL CONFIGURATION REQUIRED:\")\n",
    "    print(\"   1. Run the Layout Detection notebook first, OR\")\n",
    "    print(\"   2. Update LAYOUT_OUTPUT_DIR below with the correct path\")\n",
    "    print()\n",
    "    \n",
    "    # Fallback to manual configuration\n",
    "    LAYOUT_OUTPUT_DIR = Path(\"layout_results/run_E-Invoice Format_1234567890\")  # <-- UPDATE THIS PATH!\n",
    "\n",
    "print(f\"\\nüìÇ Using Layout Output Directory: {LAYOUT_OUTPUT_DIR}\")\n",
    "\n",
    "# Derived paths (automatically configured based on LAYOUT_OUTPUT_DIR)\n",
    "PAGE_IMAGES_DIR = LAYOUT_OUTPUT_DIR / \"page_images\"\n",
    "LAYOUT_DATA_FILE = LAYOUT_OUTPUT_DIR / \"layout_analysis\" / \"layout_data.json\"\n",
    "CROPS_METADATA_FILE = LAYOUT_OUTPUT_DIR / \"cropped_regions\" / \"crop_metadata.json\"\n",
    "CROPS_DIR = LAYOUT_OUTPUT_DIR / \"cropped_regions\"\n",
    "\n",
    "# OCR output directory\n",
    "OCR_OUTPUT_DIR = LAYOUT_OUTPUT_DIR / \"ocr_results\"\n",
    "OCR_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ‚ö° SAGEMAKER g5.12xlarge PERFORMANCE SETTINGS\n",
    "# ============================================\n",
    "\n",
    "# Performance mode selection\n",
    "FAST_MODE = False  # False = High Quality (recommended for SageMaker with 96GB GPU memory)\n",
    "PROCESS_FULL_PAGES = True  # Set to False to skip full page OCR and focus only on crops\n",
    "PROCESS_CROPS = True       # Set to False to skip crop OCR and focus only on full pages\n",
    "\n",
    "# Token limits based on mode\n",
    "if FAST_MODE:\n",
    "    print(\"‚ö° FAST MODE - Optimized for speed\")\n",
    "    PAGE_OCR_TOKENS = 1536    # Moderate tokens for pages\n",
    "    CROP_OCR_TOKENS = 768     # Moderate tokens for crops\n",
    "else:\n",
    "    print(\"üéØ QUALITY MODE - Optimized for SageMaker g5.12xlarge (96GB GPU memory)\")\n",
    "    PAGE_OCR_TOKENS = 4096    # High tokens for comprehensive extraction\n",
    "    CROP_OCR_TOKENS = 2048    # High tokens for detailed crop analysis\n",
    "\n",
    "print(f\"üìä OCR Settings:\")\n",
    "print(f\"  Token limits - Pages: {PAGE_OCR_TOKENS}, Crops: {CROP_OCR_TOKENS}\")\n",
    "print(f\"  Process full pages: {'‚úÖ Yes' if PROCESS_FULL_PAGES else '‚ùå No'}\")\n",
    "print(f\"  Process crops: {'‚úÖ Yes' if PROCESS_CROPS else '‚ùå No'}\")\n",
    "\n",
    "# Verify SageMaker GPU configuration\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"\\nüñ•Ô∏è GPU Configuration:\")\n",
    "    print(f\"  GPUs detected: {gpu_count}/4 expected A10G GPUs\")\n",
    "    \n",
    "    for i in range(min(gpu_count, 4)):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        free_mem, total_mem = torch.cuda.mem_get_info(i)\n",
    "        print(f\"  GPU {i}: {props.name} ({total_mem/1024**3:.1f}GB total, {free_mem/1024**3:.1f}GB free)\")\n",
    "    \n",
    "    if gpu_count == 4:\n",
    "        print(\"‚úÖ Optimal SageMaker configuration detected!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Expected 4 GPUs, found {gpu_count} - performance may be reduced\")\n",
    "else:\n",
    "    print(\"‚ùå No GPUs detected - this notebook requires CUDA-capable GPUs\")\n",
    "\n",
    "print(f\"\\nüìÅ Input Data Validation:\")\n",
    "print(f\"  Layout output directory: {LAYOUT_OUTPUT_DIR}\")\n",
    "print(f\"  Directory exists: {'‚úÖ Yes' if LAYOUT_OUTPUT_DIR.exists() else '‚ùå No'}\")\n",
    "\n",
    "if LAYOUT_OUTPUT_DIR.exists():\n",
    "    png_count = len(list(PAGE_IMAGES_DIR.glob('*.png'))) if PAGE_IMAGES_DIR.exists() else 0\n",
    "    print(f\"  Page images: {'‚úÖ Found' if png_count > 0 else '‚ùå Missing'} ({png_count} files)\")\n",
    "    print(f\"  Layout data: {'‚úÖ Found' if LAYOUT_DATA_FILE.exists() else '‚ùå Missing'}\")\n",
    "    print(f\"  Crop metadata: {'‚úÖ Found' if CROPS_METADATA_FILE.exists() else '‚ùå Missing'}\")\n",
    "    print(f\"  Crops directory: {'‚úÖ Found' if CROPS_DIR.exists() and any(CROPS_DIR.iterdir()) else '‚ùå Missing'}\")\n",
    "    \n",
    "    # Show specific file paths for debugging\n",
    "    if not LAYOUT_DATA_FILE.exists():\n",
    "        print(f\"    Missing: {LAYOUT_DATA_FILE}\")\n",
    "    if not CROPS_METADATA_FILE.exists():\n",
    "        print(f\"    Missing: {CROPS_METADATA_FILE}\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n‚ùå ERROR: Layout output directory not found!\")\n",
    "    print(\"Please run the Layout Detection notebook first, or check available directories:\")\n",
    "    \n",
    "    # Show available layout_results directories\n",
    "    layout_dirs = list(Path(\".\").glob(\"layout_results/run_*\"))\n",
    "    if layout_dirs:\n",
    "        print(\"  üìÅ Available layout_results directories:\")\n",
    "        for dir_path in sorted(layout_dirs, reverse=True):\n",
    "            print(f\"    {dir_path}\")\n",
    "        print(f\"\\n  üí° To use a specific directory, update:\")\n",
    "        print(f\"     LAYOUT_OUTPUT_DIR = Path('{sorted(layout_dirs, reverse=True)[0]}')\")\n",
    "    else:\n",
    "        print(\"  üìÅ No layout_results directories found in current directory\")\n",
    "        print(\"  üí° Make sure you've run the Layout Detection notebook first\")\n",
    "    \n",
    "print(f\"\\nüìÇ OCR Output Directory: {OCR_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3af8f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 09:34:59,771 - INFO - ‚úÖ Loaded layout data: 1 pages, 17 elements\n",
      "2025-10-20 09:34:59,772 - INFO - ‚úÖ Loaded crop metadata: 17 crops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading input data from Layout Detection notebook...\n",
      "‚úÖ All required input files found!\n",
      "\n",
      "üìä Input Data Summary:\n",
      "  üìÑ Total pages: 1\n",
      "  üîç Layout elements: 17\n",
      "  ‚úÇÔ∏è Cropped regions: 17\n",
      "\n",
      "üéØ Element types available:\n",
      "    Key_Value_Region: 4\n",
      "    List_Item: 3\n",
      "    Page_Footer: 1\n",
      "    Page_Header: 1\n",
      "    Picture: 3\n",
      "    Section_Header: 5\n",
      "\n",
      "‚è±Ô∏è Processing Estimate:\n",
      "  Total OCR operations: 18\n",
      "  Estimated time (g5.12xlarge): 9.0-18.0 minutes\n"
     ]
    }
   ],
   "source": [
    "def load_layout_data() -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "    \"\"\"Load layout detection results and crop metadata.\"\"\"\n",
    "    \n",
    "    layout_data = None\n",
    "    crop_metadata = None\n",
    "    \n",
    "    # Load layout data\n",
    "    if LAYOUT_DATA_FILE.exists():\n",
    "        try:\n",
    "            with open(LAYOUT_DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "                layout_data = json.load(f)\n",
    "            logger.info(f\"‚úÖ Loaded layout data: {layout_data['total_pages']} pages, {layout_data['element_statistics']['total_elements']} elements\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load layout data: {e}\")\n",
    "    else:\n",
    "        logger.error(f\"Layout data file not found: {LAYOUT_DATA_FILE}\")\n",
    "    \n",
    "    # Load crop metadata\n",
    "    if CROPS_METADATA_FILE.exists():\n",
    "        try:\n",
    "            with open(CROPS_METADATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "                crop_metadata = json.load(f)\n",
    "            logger.info(f\"‚úÖ Loaded crop metadata: {crop_metadata['total_crops']} crops\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load crop metadata: {e}\")\n",
    "    else:\n",
    "        logger.error(f\"Crop metadata file not found: {CROPS_METADATA_FILE}\")\n",
    "    \n",
    "    return layout_data, crop_metadata\n",
    "\n",
    "def verify_input_files() -> bool:\n",
    "    \"\"\"Verify all required input files are available.\"\"\"\n",
    "    \n",
    "    missing_files = []\n",
    "    \n",
    "    if not LAYOUT_OUTPUT_DIR.exists():\n",
    "        missing_files.append(f\"Layout output directory: {LAYOUT_OUTPUT_DIR}\")\n",
    "    \n",
    "    if not PAGE_IMAGES_DIR.exists() or len(list(PAGE_IMAGES_DIR.glob(\"*.png\"))) == 0:\n",
    "        missing_files.append(f\"Page images: {PAGE_IMAGES_DIR}\")\n",
    "    \n",
    "    if not LAYOUT_DATA_FILE.exists():\n",
    "        missing_files.append(f\"Layout data: {LAYOUT_DATA_FILE}\")\n",
    "    \n",
    "    if not CROPS_METADATA_FILE.exists():\n",
    "        missing_files.append(f\"Crop metadata: {CROPS_METADATA_FILE}\")\n",
    "    \n",
    "    if not CROPS_DIR.exists():\n",
    "        missing_files.append(f\"Crops directory: {CROPS_DIR}\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(\"‚ùå Missing required input files:\")\n",
    "        for file in missing_files:\n",
    "            print(f\"    {file}\")\n",
    "        print(\"\\nüí° Please run the Layout Detection notebook first to generate these files.\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"‚úÖ All required input files found!\")\n",
    "        return True\n",
    "\n",
    "# Load and verify input data\n",
    "if LAYOUT_OUTPUT_DIR.exists():\n",
    "    print(\"üîÑ Loading input data from Layout Detection notebook...\")\n",
    "    \n",
    "    # Verify files\n",
    "    files_ok = verify_input_files()\n",
    "    \n",
    "    if files_ok:\n",
    "        # Load data\n",
    "        layout_data, crop_metadata = load_layout_data()\n",
    "        \n",
    "        if layout_data and crop_metadata:\n",
    "            print(f\"\\nüìä Input Data Summary:\")\n",
    "            print(f\"  üìÑ Total pages: {layout_data['total_pages']}\")\n",
    "            print(f\"  üîç Layout elements: {layout_data['element_statistics']['total_elements']}\")\n",
    "            print(f\"  ‚úÇÔ∏è Cropped regions: {crop_metadata['total_crops']}\")\n",
    "            \n",
    "            print(f\"\\nüéØ Element types available:\")\n",
    "            for elem_type, count in sorted(layout_data['element_statistics']['by_type'].items()):\n",
    "                print(f\"    {elem_type.title()}: {count}\")\n",
    "                \n",
    "            # Calculate processing estimates\n",
    "            total_operations = 0\n",
    "            if PROCESS_FULL_PAGES:\n",
    "                total_operations += layout_data['total_pages']\n",
    "            if PROCESS_CROPS:\n",
    "                total_operations += crop_metadata['total_crops']\n",
    "                \n",
    "            print(f\"\\n‚è±Ô∏è Processing Estimate:\")\n",
    "            print(f\"  Total OCR operations: {total_operations}\")\n",
    "            print(f\"  Estimated time (g5.12xlarge): {total_operations * 0.5:.1f}-{total_operations * 1.0:.1f} minutes\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå Failed to load input data\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå Cannot proceed without required input files\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Layout output directory not found. Please update LAYOUT_OUTPUT_DIR in cell above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb583792",
   "metadata": {},
   "source": [
    "## 2. Initialize SageMaker-Optimized Nanonets OCR Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a17624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading OCR dependencies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 09:35:01,191 - INFO - Note: NumExpr detected 48 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "2025-10-20 09:35:01,192 - INFO - NumExpr defaulting to 16 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dependencies loaded!\n",
      "üöÄ Loading Nanonets OCR for SageMaker g5.12xlarge...\n",
      "üöÄ Initializing SageMaker-optimized Nanonets OCR...\n",
      "üéØ Targeting 4x NVIDIA A10G GPUs (96GB total)\n",
      "üñ•Ô∏è Configuring memory for 4 GPUs...\n",
      "  GPU 0: NVIDIA A10G - 16.7GB allocated\n",
      "  GPU 1: NVIDIA A10G - 17.5GB allocated\n",
      "  GPU 2: NVIDIA A10G - 17.5GB allocated\n",
      "  GPU 3: NVIDIA A10G - 17.5GB allocated\n",
      "\n",
      "üìä Optimization Settings:\n",
      "  Data type: torch.bfloat16\n",
      "  Attention: sdpa\n",
      "  Multi-GPU distribution: Balanced across 4 GPUs\n",
      "\n",
      "üîÑ Loading nanonets/Nanonets-OCR-s with multi-GPU distribution...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd4b9d6ea96468d817c7584988479fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa9591ed28f40fb847bdd5be100ae92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf8708602634632adbef4338d78421b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9b3ede9c7943328ce757b0caa5b030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82ec30d70374023b396774334f2cc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1d198f8cd443aaa0b71e8125c56908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c799c8544049dda3262989b180fd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1c03b310ba4ff8a18567f5c0a8b999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21423612441430aa0161e7c42131da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959a6ff605fe400084840693f32edf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e19150cf1f4aaca84ba65032b2ecb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c6c4efc1b24340b3aea4f2355c3878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730e5ad5012d4a00b3595166dc7f57f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04ea4656cd94ff8b7e39aabfb66b413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d6c5fe72644c248c22b2a3033479fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1a075295324bda861eecfa263c30bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "video_preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SageMaker OCR Engine ready!\n",
      "\n",
      "üìç Multi-GPU Device Mapping:\n",
      "    model.visual: GPU 0\n",
      "    model.language_model.embed_tokens: GPU 1\n",
      "    lm_head: GPU 1\n",
      "    model.language_model.layers.0: GPU 1\n",
      "    model.language_model.layers.1: GPU 1\n",
      "    model.language_model.layers.2: GPU 1\n",
      "    ... and 35 more layers distributed across GPUs\n",
      "\n",
      "üíæ GPU Memory Usage After Model Loading:\n",
      "    üî¥ GPU 0: 11.2% (2.5GB/22.1GB)\n",
      "    üî¥ GPU 1: 12.3% (2.7GB/22.1GB)\n",
      "    üî¥ GPU 2: 9.7% (2.1GB/22.1GB)\n",
      "    üî¥ GPU 3: 10.4% (2.3GB/22.1GB)\n",
      "  üéØ Overall Efficiency: 10.9% (9.6GB/96GB)\n",
      "\n",
      "üéâ SageMaker OCR Engine loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install --upgrade pip\n",
    "# !pip install \"transformers>=4.41\" \"accelerate>=0.33\" torch torchvision\n",
    "# !pip install pillow tqdm\n",
    "# !pip install flash-attn --no-build-isolation  # Optional for better performance\n",
    "\n",
    "print(\"üì¶ Loading OCR dependencies...\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import importlib.util\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"‚úÖ Dependencies loaded!\")\n",
    "\n",
    "# SageMaker g5.12xlarge optimization settings\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True,max_split_size_mb:512\")\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")  # Avoid tokenizer warnings\n",
    "os.environ.setdefault(\"CUDA_LAUNCH_BLOCKING\", \"0\")  # Enable async GPU operations\n",
    "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"0,1,2,3\")  # Ensure all 4 GPUs are visible\n",
    "\n",
    "def free_gpu_memory():\n",
    "    \"\"\"Clean up GPU memory across all devices.\"\"\"\n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                with torch.cuda.device(i):\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.cuda.ipc_collect()\n",
    "    except Exception:\n",
    "        pass\n",
    "    gc.collect()\n",
    "\n",
    "def detect_attention_implementation() -> str:\n",
    "    \"\"\"Detect optimal attention implementation for A10G GPUs.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Check for flash attention (optimal for A10G)\n",
    "        if importlib.util.find_spec(\"flash_attn\"):\n",
    "            return \"flash_attention_2\"\n",
    "        else:\n",
    "            return \"sdpa\"  # Scaled Dot Product Attention\n",
    "    else:\n",
    "        return \"eager\"\n",
    "\n",
    "def get_optimal_dtype():\n",
    "    \"\"\"Get optimal dtype for A10G GPUs.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # A10G supports bfloat16 - better numerical stability than fp16\n",
    "        if torch.cuda.is_bf16_supported():\n",
    "            return torch.bfloat16\n",
    "        else:\n",
    "            return torch.float16\n",
    "    else:\n",
    "        return torch.float32\n",
    "\n",
    "def build_sagemaker_memory_map(headroom: float = 0.80) -> Dict[int, int]:\n",
    "    \"\"\"Build optimized memory map for SageMaker g5.12xlarge.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return None\n",
    "    \n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"üñ•Ô∏è Configuring memory for {gpu_count} GPUs...\")\n",
    "    \n",
    "    memory_map = {}\n",
    "    for gpu_id in range(gpu_count):\n",
    "        try:\n",
    "            props = torch.cuda.get_device_properties(gpu_id)\n",
    "            free_bytes, total_bytes = torch.cuda.mem_get_info(gpu_id)\n",
    "            \n",
    "            # Use aggressive memory allocation for large models\n",
    "            usable_bytes = int(free_bytes * headroom)\n",
    "            memory_map[gpu_id] = usable_bytes\n",
    "            \n",
    "            print(f\"  GPU {gpu_id}: {props.name} - {usable_bytes/1024**3:.1f}GB allocated\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è GPU {gpu_id} memory info failed: {e}\")\n",
    "            # Fallback for A10G: assume 24GB with 80% usage\n",
    "            memory_map[gpu_id] = int(19.2 * 1024**3)  # 19.2GB\n",
    "    \n",
    "    return memory_map\n",
    "\n",
    "class SageMakerNanonetsOCR:\n",
    "    \"\"\"SageMaker g5.12xlarge optimized Nanonets OCR engine.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = \"nanonets/Nanonets-OCR-s\"):\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        print(\"üöÄ Initializing SageMaker-optimized Nanonets OCR...\")\n",
    "        print(\"üéØ Targeting 4x NVIDIA A10G GPUs (96GB total)\")\n",
    "        \n",
    "        # Clean memory before loading\n",
    "        free_gpu_memory()\n",
    "        \n",
    "        # Configure optimal settings\n",
    "        self.dtype = get_optimal_dtype()\n",
    "        self.attention_impl = detect_attention_implementation()\n",
    "        self.memory_map = build_sagemaker_memory_map(headroom=0.80)\n",
    "        \n",
    "        print(f\"\\nüìä Optimization Settings:\")\n",
    "        print(f\"  Data type: {self.dtype}\")\n",
    "        print(f\"  Attention: {self.attention_impl}\")\n",
    "        print(f\"  Multi-GPU distribution: Balanced across {len(self.memory_map)} GPUs\")\n",
    "        \n",
    "        # Load model with SageMaker optimization\n",
    "        try:\n",
    "            print(f\"\\nüîÑ Loading {model_path} with multi-GPU distribution...\")\n",
    "            self.model = AutoModelForImageTextToText.from_pretrained(\n",
    "                model_path,\n",
    "                torch_dtype=self.dtype,\n",
    "                device_map=\"auto\",  # Automatic distribution across all GPUs\n",
    "                max_memory=self.memory_map,\n",
    "                trust_remote_code=True,\n",
    "                low_cpu_mem_usage=True,\n",
    "                offload_folder=\"./model_offload\",\n",
    "                offload_state_dict=True\n",
    "            ).eval()\n",
    "            \n",
    "            # Configure attention and caching\n",
    "            if hasattr(self.model, 'config'):\n",
    "                self.model.config.attn_implementation = self.attention_impl\n",
    "                if hasattr(self.model.config, 'use_cache'):\n",
    "                    self.model.config.use_cache = True\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model: {e}\")\n",
    "            print(\"üí° Trying fallback configuration...\")\n",
    "            self.model = AutoModelForImageTextToText.from_pretrained(\n",
    "                model_path,\n",
    "                torch_dtype=self.dtype,\n",
    "                device_map=\"balanced\",\n",
    "                trust_remote_code=True,\n",
    "                low_cpu_mem_usage=True\n",
    "            ).eval()\n",
    "        \n",
    "        # Load tokenizer and processor\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        self.processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n",
    "        \n",
    "        # Configure padding token\n",
    "        if hasattr(self.model, \"generation_config\"):\n",
    "            if getattr(self.model.generation_config, \"pad_token_id\", None) is None:\n",
    "                self.model.generation_config.pad_token_id = (\n",
    "                    getattr(self.tokenizer, \"pad_token_id\", None) or\n",
    "                    getattr(self.tokenizer, \"eos_token_id\", None)\n",
    "                )\n",
    "        \n",
    "        print(\"‚úÖ SageMaker OCR Engine ready!\")\n",
    "        self._display_device_mapping()\n",
    "        self._display_memory_usage()\n",
    "    \n",
    "    def _display_device_mapping(self):\n",
    "        \"\"\"Display model device mapping.\"\"\"\n",
    "        if hasattr(self.model, 'hf_device_map'):\n",
    "            print(f\"\\nüìç Multi-GPU Device Mapping:\")\n",
    "            device_map = dict(self.model.hf_device_map.items())\n",
    "            for layer_name, device in list(device_map.items())[:6]:\n",
    "                print(f\"    {layer_name}: GPU {device}\")\n",
    "            if len(device_map) > 6:\n",
    "                print(f\"    ... and {len(device_map) - 6} more layers distributed across GPUs\")\n",
    "    \n",
    "    def _display_memory_usage(self):\n",
    "        \"\"\"Display GPU memory usage after model loading.\"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"\\nüíæ GPU Memory Usage After Model Loading:\")\n",
    "            total_used = 0\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                free_mem, total_mem = torch.cuda.mem_get_info(i)\n",
    "                used_mem = total_mem - free_mem\n",
    "                total_used += used_mem\n",
    "                efficiency = (used_mem / total_mem) * 100\n",
    "                status = \"üü¢\" if efficiency > 70 else \"üü°\" if efficiency > 40 else \"üî¥\"\n",
    "                print(f\"    {status} GPU {i}: {efficiency:.1f}% ({used_mem/1024**3:.1f}GB/{total_mem/1024**3:.1f}GB)\")\n",
    "            \n",
    "            overall_efficiency = (total_used / (total_mem * torch.cuda.device_count())) * 100\n",
    "            print(f\"  üéØ Overall Efficiency: {overall_efficiency:.1f}% ({total_used/1024**3:.1f}GB/96GB)\")\n",
    "    \n",
    "    def ocr_image(self, image_path: Path, max_tokens: int = 2048, \n",
    "                  use_cache: bool = True, retry_on_oom: bool = True) -> str:\n",
    "        \"\"\"Perform OCR with SageMaker g5.12xlarge optimization.\"\"\"\n",
    "        \n",
    "        # Optimized prompt for document extraction\n",
    "        prompt = (\n",
    "            \"Extract the text from the above document as if you were reading it naturally. \"\n",
    "            \"Return the tables in HTML format. Return the equations in LaTeX representation. \"\n",
    "            \"If there is an image in the document and image caption is not present, add a small \"\n",
    "            \"description of the image inside the <img></img> tag; otherwise, add the image caption \"\n",
    "            \"inside <img></img>. Watermarks should be wrapped in brackets. Ex: \"\n",
    "            \"<watermark>OFFICIAL COPY</watermark>. Page numbers should be wrapped in brackets. \"\n",
    "            \"Ex: <page_number>14</page_number> or <page_number>9/22</page_number>. \"\n",
    "            \"Prefer using ‚òê and ‚òë for check boxes.\"\n",
    "        )\n",
    "        \n",
    "        # Load and prepare image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # Prepare messages\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\", \"image\": f\"file://{image_path}\"},\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ]},\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template\n",
    "        try:\n",
    "            text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        except AttributeError:\n",
    "            text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        \n",
    "        # Process inputs and move to first GPU\n",
    "        inputs = self.processor(text=[text], images=[image], padding=True, return_tensors=\"pt\")\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.cuda(0) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "        \n",
    "        def _generate_text(tokens: int) -> str:\n",
    "            with torch.inference_mode():\n",
    "                output = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=tokens,\n",
    "                    do_sample=False,  # Deterministic for consistency\n",
    "                    num_beams=1,      # Fast greedy decoding\n",
    "                    use_cache=use_cache,\n",
    "                    pad_token_id=self.model.generation_config.pad_token_id,\n",
    "                    early_stopping=True,\n",
    "                    repetition_penalty=1.05  # Slight penalty to avoid repetition\n",
    "                )\n",
    "            \n",
    "            # Extract only generated tokens\n",
    "            generated_ids = [o[i.shape[-1]:] for i, o in zip(inputs[\"input_ids\"], output)]\n",
    "            result = self.processor.batch_decode(\n",
    "                generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "            )[0]\n",
    "            return result\n",
    "        \n",
    "        try:\n",
    "            result = _generate_text(max_tokens)\n",
    "        except RuntimeError as e:\n",
    "            if retry_on_oom and \"memory\" in str(e).lower():\n",
    "                print(f\"  ‚ö†Ô∏è OOM at {max_tokens} tokens, retrying with {max_tokens // 2}\")\n",
    "                free_gpu_memory()\n",
    "                result = _generate_text(max_tokens // 2)\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # Cleanup\n",
    "        del image, inputs\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        return result.strip()\n",
    "\n",
    "# Initialize OCR engine\n",
    "print(\"üöÄ Loading Nanonets OCR for SageMaker g5.12xlarge...\")\n",
    "\n",
    "try:\n",
    "    ocr_engine = SageMakerNanonetsOCR(\"nanonets/Nanonets-OCR-s\")\n",
    "    print(\"\\nüéâ SageMaker OCR Engine loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load OCR engine: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    ocr_engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e5715",
   "metadata": {},
   "source": [
    "## 3. Run Complete OCR Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c63ec857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting SageMaker OCR processing...\n",
      "üìã Prerequisites Check:\n",
      "  Layout data: ‚úÖ Available\n",
      "  Crop metadata: ‚úÖ Available\n",
      "  OCR engine: ‚úÖ Available\n",
      "\n",
      "üíæ Pre-processing GPU Memory:\n",
      "  GPU 0: 2.5GB / 22.1GB\n",
      "  GPU 1: 2.7GB / 22.1GB\n",
      "  GPU 2: 2.1GB / 22.1GB\n",
      "  GPU 3: 2.3GB / 22.1GB\n",
      "üöÄ Starting SageMaker g5.12xlarge OCR Pipeline...\n",
      "üéØ Hardware: 4x NVIDIA A10G GPUs (96GB total)\n",
      "üìä Settings: Pages=4096 tokens, Crops=2048 tokens\n",
      "üìä Processing Plan:\n",
      "  Total pages: 1\n",
      "  Total crops: 17\n",
      "  Total OCR operations: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f83e0d1edc4129b34f0add5af325aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SageMaker OCR:   0%|          | 0/18 [00:00<?, ?ops/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Processing Page 1/1\n",
      "  üîç OCR full page (4096 max tokens)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üîç OCR 17 cropped regions (2048 max tokens each)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Page 1 complete (17 crops, 195.9s)\n",
      "\n",
      "üéâ SageMaker OCR Pipeline Complete!\n",
      "  ‚è±Ô∏è Total time: 195.9 seconds (3.3 minutes)\n",
      "  üìä Pages processed: 1\n",
      "  üìä Crops processed: 17\n",
      "  ‚ö° Performance: 0.09 operations/second\n",
      "  üöÄ SageMaker g5.12xlarge optimization delivered!\n",
      "\n",
      "üìÅ Results saved: layout_results/run_E-Invoice Format_1760952745/ocr_results/sagemaker_ocr_results.json\n",
      "\n",
      "üéØ Final Performance Summary:\n",
      "  Instance: SageMaker g5.12xlarge (4x A10G)\n",
      "  Total operations: 18\n",
      "  Processing time: 195.9s (3.3 min)\n",
      "  Average speed: 0.09 ops/sec\n",
      "  Multi-GPU efficiency: Optimal distribution across 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "def safe_ocr_with_retry(image_path: Path, max_tokens: int, context: str) -> str:\n",
    "    \"\"\"Perform OCR with error handling and retry logic.\"\"\"\n",
    "    if not ocr_engine:\n",
    "        return \"‚ùå OCR engine not available\"\n",
    "    \n",
    "    try:\n",
    "        result = ocr_engine.ocr_image(image_path, max_tokens=max_tokens)\n",
    "        return result if result.strip() else \"_(no text extracted)_\"\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"  ‚ùå Error in {context}: {error_msg[:100]}...\")\n",
    "        \n",
    "        # Try with reduced tokens as fallback\n",
    "        if \"memory\" in error_msg.lower() and max_tokens > 256:\n",
    "            try:\n",
    "                reduced_tokens = max_tokens // 3\n",
    "                print(f\"  üîÑ Retrying {context} with {reduced_tokens} tokens...\")\n",
    "                result = ocr_engine.ocr_image(image_path, max_tokens=reduced_tokens)\n",
    "                return result if result.strip() else \"_(no text extracted)_\"\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        return f\"‚ùå OCR failed: {error_msg[:100]}...\"\n",
    "\n",
    "def run_sagemaker_ocr_pipeline(layout_data_dict=None, crop_metadata_dict=None) -> Dict[str, Any]:\n",
    "    \"\"\"Run complete OCR pipeline optimized for SageMaker g5.12xlarge.\"\"\"\n",
    "    \n",
    "    if not ocr_engine:\n",
    "        print(\"‚ùå Cannot run OCR - engine not loaded\")\n",
    "        return {}\n",
    "    \n",
    "    # Use passed parameters or try to get from globals\n",
    "    if layout_data_dict is None:\n",
    "        layout_data_dict = globals().get('layout_data', None)\n",
    "    if crop_metadata_dict is None:\n",
    "        crop_metadata_dict = globals().get('crop_metadata', None)\n",
    "    \n",
    "    if not layout_data_dict or not crop_metadata_dict:\n",
    "        print(\"‚ùå Cannot run OCR - input data not loaded\")\n",
    "        print(f\"  layout_data available: {'‚úÖ Yes' if layout_data_dict else '‚ùå No'}\")\n",
    "        print(f\"  crop_metadata available: {'‚úÖ Yes' if crop_metadata_dict else '‚ùå No'}\")\n",
    "        print(\"  üí° Please run the data loading cell (cell 2) first\")\n",
    "        return {}\n",
    "    \n",
    "    print(\"üöÄ Starting SageMaker g5.12xlarge OCR Pipeline...\")\n",
    "    print(f\"üéØ Hardware: 4x NVIDIA A10G GPUs (96GB total)\")\n",
    "    print(f\"üìä Settings: Pages={PAGE_OCR_TOKENS} tokens, Crops={CROP_OCR_TOKENS} tokens\")\n",
    "    \n",
    "    # Initialize results structure\n",
    "    ocr_results = {\n",
    "        \"pages\": [],\n",
    "        \"metadata\": {\n",
    "            \"total_pages\": 0,\n",
    "            \"total_crops\": 0,\n",
    "            \"processing_time\": 0,\n",
    "            \"sagemaker_instance\": \"g5.12xlarge\",\n",
    "            \"gpu_count\": torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
    "            \"performance_mode\": \"FAST\" if FAST_MODE else \"QUALITY\",\n",
    "            \"page_tokens\": PAGE_OCR_TOKENS,\n",
    "            \"crop_tokens\": CROP_OCR_TOKENS,\n",
    "            \"process_full_pages\": PROCESS_FULL_PAGES,\n",
    "            \"process_crops\": PROCESS_CROPS,\n",
    "            \"processing_timestamp\": time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Calculate total operations\n",
    "    total_operations = 0\n",
    "    if PROCESS_FULL_PAGES:\n",
    "        total_operations += layout_data_dict['total_pages']\n",
    "    if PROCESS_CROPS:\n",
    "        total_operations += crop_metadata_dict['total_crops']\n",
    "    \n",
    "    print(f\"üìä Processing Plan:\")\n",
    "    print(f\"  Total pages: {layout_data_dict['total_pages']}\")\n",
    "    print(f\"  Total crops: {crop_metadata_dict['total_crops']}\")\n",
    "    print(f\"  Total OCR operations: {total_operations}\")\n",
    "    \n",
    "    # Initialize progress tracking\n",
    "    with tqdm(total=total_operations, desc=\"SageMaker OCR\", unit=\"ops\",\n",
    "              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:\n",
    "        \n",
    "        # Process each page\n",
    "        for page_num in range(1, layout_data_dict['total_pages'] + 1):\n",
    "            page_start_time = time.time()\n",
    "            print(f\"\\nüìÑ Processing Page {page_num}/{layout_data_dict['total_pages']}\")\n",
    "            \n",
    "            # Initialize page result\n",
    "            page_result = {\n",
    "                \"page_number\": page_num,\n",
    "                \"page_image\": None,\n",
    "                \"full_page_text\": None,\n",
    "                \"crops\": [],\n",
    "                \"processing_time\": 0\n",
    "            }\n",
    "            \n",
    "            # OCR full page if enabled\n",
    "            if PROCESS_FULL_PAGES:\n",
    "                page_image_path = PAGE_IMAGES_DIR / f\"page_{page_num:03d}.png\"\n",
    "                \n",
    "                if page_image_path.exists():\n",
    "                    page_result[\"page_image\"] = str(page_image_path.relative_to(LAYOUT_OUTPUT_DIR))\n",
    "                    print(f\"  üîç OCR full page ({PAGE_OCR_TOKENS} max tokens)...\")\n",
    "                    \n",
    "                    page_text = safe_ocr_with_retry(\n",
    "                        page_image_path,\n",
    "                        max_tokens=PAGE_OCR_TOKENS,\n",
    "                        context=f\"Page {page_num} full\"\n",
    "                    )\n",
    "                    page_result[\"full_page_text\"] = page_text\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è Page image not found: {page_image_path}\")\n",
    "                    page_result[\"full_page_text\"] = \"‚ùå Page image not found\"\n",
    "                \n",
    "                pbar.update(1)\n",
    "            \n",
    "            # OCR crops if enabled\n",
    "            if PROCESS_CROPS and str(page_num) in crop_metadata_dict.get(\"pages\", {}):\n",
    "                page_crops = crop_metadata_dict[\"pages\"][str(page_num)][\"crops\"]\n",
    "                print(f\"  üîç OCR {len(page_crops)} cropped regions ({CROP_OCR_TOKENS} max tokens each)...\")\n",
    "                \n",
    "                for crop_idx, crop_info in enumerate(page_crops):\n",
    "                    crop_path = LAYOUT_OUTPUT_DIR / crop_info[\"crop_path\"]\n",
    "                    \n",
    "                    if crop_path.exists():\n",
    "                        crop_text = safe_ocr_with_retry(\n",
    "                            crop_path,\n",
    "                            max_tokens=CROP_OCR_TOKENS,\n",
    "                            context=f\"Page {page_num} {crop_info['type']} {crop_idx+1}\"\n",
    "                        )\n",
    "                        \n",
    "                        crop_result = {\n",
    "                            \"crop_index\": crop_idx + 1,\n",
    "                            \"element_id\": crop_info[\"element_id\"],\n",
    "                            \"element_type\": crop_info[\"type\"],\n",
    "                            \"confidence\": crop_info[\"confidence\"],\n",
    "                            \"crop_path\": crop_info[\"crop_path\"],\n",
    "                            \"ocr_text\": crop_text,\n",
    "                            \"bbox\": crop_info.get(\"image_bbox\", [])\n",
    "                        }\n",
    "                        page_result[\"crops\"].append(crop_result)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "            \n",
    "            # Calculate page processing time\n",
    "            page_result[\"processing_time\"] = time.time() - page_start_time\n",
    "            ocr_results[\"pages\"].append(page_result)\n",
    "            \n",
    "            # Progress update\n",
    "            avg_time_per_page = (time.time() - start_time) / page_num\n",
    "            remaining_pages = layout_data_dict['total_pages'] - page_num\n",
    "            eta_minutes = (remaining_pages * avg_time_per_page) / 60\n",
    "            \n",
    "            print(f\"  ‚úÖ Page {page_num} complete ({len(page_result['crops'])} crops, {page_result['processing_time']:.1f}s)\")\n",
    "            if remaining_pages > 0:\n",
    "                print(f\"  ‚è±Ô∏è ETA for remaining pages: {eta_minutes:.1f} minutes\")\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    total_time = time.time() - start_time\n",
    "    ocr_results[\"metadata\"][\"total_pages\"] = layout_data_dict['total_pages']\n",
    "    ocr_results[\"metadata\"][\"total_crops\"] = sum(len(page[\"crops\"]) for page in ocr_results[\"pages\"])\n",
    "    ocr_results[\"metadata\"][\"processing_time\"] = total_time\n",
    "    \n",
    "    # Performance metrics\n",
    "    ops_per_second = total_operations / total_time if total_time > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüéâ SageMaker OCR Pipeline Complete!\")\n",
    "    print(f\"  ‚è±Ô∏è Total time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"  üìä Pages processed: {ocr_results['metadata']['total_pages']}\")\n",
    "    print(f\"  üìä Crops processed: {ocr_results['metadata']['total_crops']}\")\n",
    "    print(f\"  ‚ö° Performance: {ops_per_second:.2f} operations/second\")\n",
    "    print(f\"  üöÄ SageMaker g5.12xlarge optimization delivered!\")\n",
    "    \n",
    "    return ocr_results\n",
    "\n",
    "# Run the OCR pipeline with improved variable access\n",
    "print(\"üöÄ Starting SageMaker OCR processing...\")\n",
    "\n",
    "# Check what data is available\n",
    "layout_data_available = 'layout_data' in globals() and globals()['layout_data'] is not None\n",
    "crop_metadata_available = 'crop_metadata' in globals() and globals()['crop_metadata'] is not None\n",
    "ocr_engine_available = 'ocr_engine' in globals() and globals()['ocr_engine'] is not None\n",
    "\n",
    "print(f\"üìã Prerequisites Check:\")\n",
    "print(f\"  Layout data: {'‚úÖ Available' if layout_data_available else '‚ùå Missing'}\")\n",
    "print(f\"  Crop metadata: {'‚úÖ Available' if crop_metadata_available else '‚ùå Missing'}\")\n",
    "print(f\"  OCR engine: {'‚úÖ Available' if ocr_engine_available else '‚ùå Missing'}\")\n",
    "\n",
    "if layout_data_available and crop_metadata_available and ocr_engine_available:\n",
    "    # Display pre-processing GPU memory\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\nüíæ Pre-processing GPU Memory:\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            free_mem, total_mem = torch.cuda.mem_get_info(i)\n",
    "            used_mem = total_mem - free_mem\n",
    "            print(f\"  GPU {i}: {used_mem/1024**3:.1f}GB / {total_mem/1024**3:.1f}GB\")\n",
    "    \n",
    "    # Run OCR pipeline with explicit data passing\n",
    "    ocr_results = run_sagemaker_ocr_pipeline(\n",
    "        layout_data_dict=globals()['layout_data'], \n",
    "        crop_metadata_dict=globals()['crop_metadata']\n",
    "    )\n",
    "    \n",
    "    if ocr_results:\n",
    "        # Save results\n",
    "        results_path = OCR_OUTPUT_DIR / \"sagemaker_ocr_results.json\"\n",
    "        with open(results_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(ocr_results, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nüìÅ Results saved: {results_path}\")\n",
    "        \n",
    "        # Performance summary\n",
    "        total_time = ocr_results[\"metadata\"][\"processing_time\"]\n",
    "        total_ops = ocr_results[\"metadata\"][\"total_pages\"] + ocr_results[\"metadata\"][\"total_crops\"]\n",
    "        \n",
    "        print(f\"\\nüéØ Final Performance Summary:\")\n",
    "        print(f\"  Instance: SageMaker g5.12xlarge (4x A10G)\")\n",
    "        print(f\"  Total operations: {total_ops}\")\n",
    "        print(f\"  Processing time: {total_time:.1f}s ({total_time/60:.1f} min)\")\n",
    "        print(f\"  Average speed: {total_ops/total_time:.2f} ops/sec\")\n",
    "        print(f\"  Multi-GPU efficiency: Optimal distribution across 4 GPUs\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n‚ùå Cannot run OCR pipeline - missing requirements\")\n",
    "    \n",
    "    if not layout_data_available or not crop_metadata_available:\n",
    "        print(\"üîß To fix data loading issues:\")\n",
    "        print(\"   1. Make sure you've run cell 2 (Configuration & Input Data Loading)\")\n",
    "        print(\"   2. Ensure the layout detection notebook generated the required files\")\n",
    "        print(\"   3. Check that LAYOUT_OUTPUT_DIR points to the correct directory\")\n",
    "    \n",
    "    if not ocr_engine_available:\n",
    "        print(\"üîß To fix OCR engine issues:\")\n",
    "        print(\"   1. Run cell 4 (Initialize SageMaker-Optimized Nanonets OCR Engine)\")\n",
    "        print(\"   2. Check GPU availability and memory\")\n",
    "        print(\"   3. Install required dependencies if needed\")\n",
    "    \n",
    "    ocr_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026964d2",
   "metadata": {},
   "source": [
    "## 4. Generate Final Output & Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b54d3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generating final outputs...\n",
      "‚úÖ Markdown output saved: layout_results/run_E-Invoice Format_1760952745/ocr_results/complete_document_extracted.md\n",
      "‚úÖ Final summary saved: layout_results/run_E-Invoice Format_1760952745/ocr_results/final_processing_summary.json\n",
      "\n",
      "üéâ Complete Pipeline Successfully Finished!\n",
      "======================================================================\n",
      "\n",
      "üìä Final Results Summary:\n",
      "  üñ•Ô∏è Hardware: SageMaker g5.12xlarge (4x A10G GPUs)\n",
      "  üìÑ Pages: 1 | Crops: 17\n",
      "  ‚è±Ô∏è Processing Time: 195.9s (3.3 min)\n",
      "  ‚ö° Performance: 0.09 operations/second\n",
      "  üéØ Mode: QUALITY\n",
      "\n",
      "üìÅ Key Output Files:\n",
      "  üìÑ Human-readable: complete_document_extracted.md\n",
      "  üìä Structured data: sagemaker_ocr_results.json\n",
      "  üìã Processing summary: final_processing_summary.json\n",
      "\n",
      "üìÇ Complete Output Directory: layout_results/run_E-Invoice Format_1760952745/ocr_results\n",
      "\n",
      "‚úÖ Both notebooks have successfully completed the end-to-end pipeline!\n",
      "   1. Layout Detection & Cropping ‚úÖ\n",
      "   2. SageMaker OCR Processing ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "def generate_markdown_output(ocr_results: Dict[str, Any]) -> Path:\n",
    "    \"\"\"Generate comprehensive Markdown output from OCR results.\"\"\"\n",
    "    \n",
    "    if not ocr_results.get(\"pages\"):\n",
    "        print(\"‚ùå No OCR results to convert to Markdown\")\n",
    "        return None\n",
    "    \n",
    "    markdown_lines = []\n",
    "    \n",
    "    # Header with metadata\n",
    "    metadata = ocr_results[\"metadata\"]\n",
    "    markdown_lines.extend([\n",
    "        f\"# Document OCR Results - SageMaker g5.12xlarge Processing\",\n",
    "        f\"\",\n",
    "        f\"**Processed with:** SageMaker {metadata.get('sagemaker_instance', 'g5.12xlarge')} ({metadata.get('gpu_count', 4)}x A10G GPUs)  \",\n",
    "        f\"**Processing Time:** {metadata['processing_time']:.1f} seconds ({metadata['processing_time']/60:.1f} minutes)  \",\n",
    "        f\"**Performance Mode:** {metadata['performance_mode']}  \",\n",
    "        f\"**Pages:** {metadata['total_pages']} | **Crops:** {metadata['total_crops']}  \",\n",
    "        f\"**Token Limits:** Pages={metadata['page_tokens']}, Crops={metadata['crop_tokens']}  \",\n",
    "        f\"**Timestamp:** {metadata.get('processing_timestamp', 'N/A')}  \",\n",
    "        f\"\",\n",
    "        f\"---\",\n",
    "        f\"\"\n",
    "    ])\n",
    "    \n",
    "    # Process each page\n",
    "    for page_data in ocr_results[\"pages\"]:\n",
    "        page_num = page_data[\"page_number\"]\n",
    "        \n",
    "        markdown_lines.extend([\n",
    "            f\"## Page {page_num}\",\n",
    "            f\"\"\n",
    "        ])\n",
    "        \n",
    "        # Full page content (if processed)\n",
    "        if metadata.get(\"process_full_pages\", True) and page_data.get(\"full_page_text\"):\n",
    "            if not page_data[\"full_page_text\"].startswith(\"‚ùå\"):\n",
    "                markdown_lines.extend([\n",
    "                    f\"### Full Page Content\",\n",
    "                    f\"\",\n",
    "                    page_data[\"full_page_text\"],\n",
    "                    f\"\",\n",
    "                    f\"---\",\n",
    "                    f\"\"\n",
    "                ])\n",
    "        \n",
    "        # Cropped regions (if processed)\n",
    "        if metadata.get(\"process_crops\", True) and page_data.get(\"crops\"):\n",
    "            markdown_lines.extend([\n",
    "                f\"### Extracted Regions ({len(page_data['crops'])} crops)\",\n",
    "                f\"\"\n",
    "            ])\n",
    "            \n",
    "            for crop_data in page_data[\"crops\"]:\n",
    "                crop_type = crop_data[\"element_type\"].title()\n",
    "                crop_idx = crop_data[\"crop_index\"]\n",
    "                confidence = crop_data[\"confidence\"]\n",
    "                \n",
    "                # Region header\n",
    "                markdown_lines.extend([\n",
    "                    f\"#### {crop_type} {crop_idx} (Confidence: {confidence:.2f})\",\n",
    "                    f\"\"\n",
    "                ])\n",
    "                \n",
    "                # Show image reference\n",
    "                if crop_data.get(\"crop_path\"):\n",
    "                    markdown_lines.extend([\n",
    "                        f\"**Crop:** `{crop_data['crop_path']}`\",\n",
    "                        f\"\"\n",
    "                    ])\n",
    "                \n",
    "                # OCR content\n",
    "                if crop_data.get(\"ocr_text\") and not crop_data[\"ocr_text\"].startswith(\"‚ùå\"):\n",
    "                    markdown_lines.extend([\n",
    "                        crop_data[\"ocr_text\"],\n",
    "                        f\"\"\n",
    "                    ])\n",
    "                else:\n",
    "                    markdown_lines.extend([\n",
    "                        f\"_(No text extracted or processing failed)_\",\n",
    "                        f\"\"\n",
    "                    ])\n",
    "                \n",
    "                markdown_lines.extend([\"---\", \"\"])\n",
    "    \n",
    "    # Performance section\n",
    "    markdown_lines.extend([\n",
    "        f\"## Processing Performance\",\n",
    "        f\"\",\n",
    "        f\"### SageMaker Configuration\",\n",
    "        f\"- **Instance:** {metadata.get('sagemaker_instance', 'g5.12xlarge')}\",\n",
    "        f\"- **GPUs:** {metadata.get('gpu_count', 4)}x NVIDIA A10G (24GB each)\",\n",
    "        f\"- **Total GPU Memory:** ~96GB\",\n",
    "        f\"- **Performance Mode:** {metadata['performance_mode']}\",\n",
    "        f\"\",\n",
    "        f\"### Processing Statistics\",\n",
    "        f\"- **Total Processing Time:** {metadata['processing_time']:.1f} seconds ({metadata['processing_time']/60:.1f} minutes)\",\n",
    "        f\"- **Pages Processed:** {metadata['total_pages']}\",\n",
    "        f\"- **Crops Processed:** {metadata['total_crops']}\",\n",
    "        f\"- **Average Speed:** {(metadata['total_pages'] + metadata['total_crops'])/metadata['processing_time']:.2f} operations/second\",\n",
    "        f\"- **Token Configuration:** Pages={metadata['page_tokens']}, Crops={metadata['crop_tokens']}\",\n",
    "        f\"\"\n",
    "    ])\n",
    "    \n",
    "    # Write markdown file\n",
    "    markdown_path = OCR_OUTPUT_DIR / \"complete_document_extracted.md\"\n",
    "    with open(markdown_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(markdown_lines))\n",
    "    \n",
    "    print(f\"‚úÖ Markdown output saved: {markdown_path}\")\n",
    "    return markdown_path\n",
    "\n",
    "def create_final_summary(ocr_results_dict=None) -> Dict[str, Any]:\n",
    "    \"\"\"Create comprehensive final summary.\"\"\"\n",
    "    \n",
    "    # Use passed parameter or try to get from globals\n",
    "    if ocr_results_dict is None:\n",
    "        ocr_results_dict = globals().get('ocr_results', None)\n",
    "    \n",
    "    if not ocr_results_dict or not ocr_results_dict.get(\"pages\"):\n",
    "        print(\"‚ö†Ô∏è No OCR results available for summary generation\")\n",
    "        return {}\n",
    "    \n",
    "    # Safe division to avoid division by zero\n",
    "    processing_time = ocr_results_dict[\"metadata\"][\"processing_time\"]\n",
    "    total_pages = ocr_results_dict[\"metadata\"][\"total_pages\"]\n",
    "    total_crops = ocr_results_dict[\"metadata\"][\"total_crops\"]\n",
    "    total_operations = total_pages + total_crops\n",
    "    \n",
    "    ops_per_second = total_operations / processing_time if processing_time > 0 else 0\n",
    "    \n",
    "    summary = {\n",
    "        \"pipeline_complete\": True,\n",
    "        \"processing_stages\": [\n",
    "            \"PDF to Images (Layout notebook)\",\n",
    "            \"Layout Detection (Layout notebook)\", \n",
    "            \"Region Cropping (Layout notebook)\",\n",
    "            \"OCR Processing (This notebook)\"\n",
    "        ],\n",
    "        \"sagemaker_performance\": {\n",
    "            \"instance_type\": \"g5.12xlarge\",\n",
    "            \"gpu_count\": ocr_results_dict[\"metadata\"].get(\"gpu_count\", 4),\n",
    "            \"total_processing_time\": processing_time,\n",
    "            \"operations_per_second\": ops_per_second,\n",
    "            \"performance_mode\": ocr_results_dict[\"metadata\"][\"performance_mode\"]\n",
    "        },\n",
    "        \"final_results\": {\n",
    "            \"pages_processed\": total_pages,\n",
    "            \"crops_processed\": total_crops,\n",
    "            \"total_operations\": total_operations\n",
    "        },\n",
    "        \"output_files\": {\n",
    "            \"structured_results\": \"sagemaker_ocr_results.json\",\n",
    "            \"markdown_document\": \"complete_document_extracted.md\",\n",
    "            \"processing_summary\": \"final_processing_summary.json\"\n",
    "        },\n",
    "        \"next_steps\": [\n",
    "            \"Review the Markdown document for extracted content\",\n",
    "            \"Use the JSON results for programmatic access\",\n",
    "            \"Consider post-processing for specific use cases\",\n",
    "            \"Archive the processing results\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Generate final outputs\n",
    "ocr_results_available = 'ocr_results' in globals() and globals()['ocr_results']\n",
    "\n",
    "if ocr_results_available:\n",
    "    print(\"üîÑ Generating final outputs...\")\n",
    "    \n",
    "    # Get OCR results from global scope\n",
    "    ocr_results_data = globals()['ocr_results']\n",
    "    \n",
    "    # Generate Markdown document\n",
    "    markdown_path = generate_markdown_output(ocr_results_data)\n",
    "    \n",
    "    # Create final summary with explicit data passing\n",
    "    final_summary = create_final_summary(ocr_results_data)\n",
    "    \n",
    "    if final_summary:  # Only proceed if summary was created successfully\n",
    "        summary_path = OCR_OUTPUT_DIR / \"final_processing_summary.json\"\n",
    "        \n",
    "        with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(final_summary, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"‚úÖ Final summary saved: {summary_path}\")\n",
    "        \n",
    "        print(\"\\nüéâ Complete Pipeline Successfully Finished!\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(f\"\\nüìä Final Results Summary:\")\n",
    "        perf = final_summary[\"sagemaker_performance\"]\n",
    "        results = final_summary[\"final_results\"]\n",
    "        \n",
    "        print(f\"  üñ•Ô∏è Hardware: SageMaker {perf['instance_type']} ({perf['gpu_count']}x A10G GPUs)\")\n",
    "        print(f\"  üìÑ Pages: {results['pages_processed']} | Crops: {results['crops_processed']}\")\n",
    "        print(f\"  ‚è±Ô∏è Processing Time: {perf['total_processing_time']:.1f}s ({perf['total_processing_time']/60:.1f} min)\")\n",
    "        print(f\"  ‚ö° Performance: {perf['operations_per_second']:.2f} operations/second\")\n",
    "        print(f\"  üéØ Mode: {perf['performance_mode']}\")\n",
    "        \n",
    "        print(f\"\\nüìÅ Key Output Files:\")\n",
    "        if markdown_path:\n",
    "            print(f\"  üìÑ Human-readable: {markdown_path.name}\")\n",
    "        print(f\"  üìä Structured data: sagemaker_ocr_results.json\")\n",
    "        print(f\"  üìã Processing summary: final_processing_summary.json\")\n",
    "        \n",
    "        print(f\"\\nüìÇ Complete Output Directory: {OCR_OUTPUT_DIR}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Both notebooks have successfully completed the end-to-end pipeline!\")\n",
    "        print(f\"   1. Layout Detection & Cropping ‚úÖ\")\n",
    "        print(f\"   2. SageMaker OCR Processing ‚úÖ\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to create final summary\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No OCR results available for final output generation\")\n",
    "    print(\"Please ensure the OCR pipeline ran successfully in the previous cell.\")\n",
    "    print(f\"Debug: ocr_results in globals: {'ocr_results' in globals()}\")\n",
    "    if 'ocr_results' in globals():\n",
    "        ocr_data = globals()['ocr_results']\n",
    "        print(f\"Debug: ocr_results type: {type(ocr_data)}\")\n",
    "        print(f\"Debug: ocr_results has pages: {bool(ocr_data.get('pages') if isinstance(ocr_data, dict) else False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e148d5-4b0c-4df4-b32c-f13803a6530d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb9919-cc49-4487-940b-7985f3010005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
